---
title: "ã‚¢ãƒªãƒãƒé€šç¾©ã‚·ãƒªãƒ¼ã‚º"
icon: "a"
---

## Qwen 3 ã‚·ãƒªãƒ¼ã‚º

Qwen3ã‚·ãƒªãƒ¼ã‚ºã¯ã€ã‚¢ãƒªãƒãƒãŒãƒªãƒªãƒ¼ã‚¹ã—ãŸæ–°ä¸–ä»£ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã€ãã®èƒ½åŠ›ã¯å¤§å¹…ã«å‘ä¸Šã—ã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ç†è§£ã€æ•°å­¦çš„æ¨è«–ã€å¤šè¨€èªè¡¨ç¾ã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ç¾åœ¨ã®å¸‚å ´ã®ãƒˆãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«ï¼ˆo1ã€DeepSeek-R1ãªã©ï¼‰ã«åŒ¹æ•µã™ã‚‹ã‹ã€ãã‚Œã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚**ãã®æ ¸å¿ƒçš„ãªãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã¯ã€ã€Œæ€è€ƒãƒ¢ãƒ¼ãƒ‰ã€ã¨ã€Œéæ€è€ƒãƒ¢ãƒ¼ãƒ‰ã€ã®åˆ‡ã‚Šæ›¿ãˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã—ãŸã“ã¨ã«ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒç•°ãªã‚‹é›£æ˜“åº¦ã®ã‚¿ã‚¹ã‚¯ã«ç›´é¢ã—ãŸéš›ã«ã€æ¨è«–ã®æ·±ã•ã‚’è‡ªå¾‹çš„ã«èª¿æ•´ã—ã€é€Ÿåº¦ã¨ç²¾åº¦ã®ä¸¡æ–¹ã§å„ªã‚ŒãŸãƒãƒ©ãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚** ãƒ•ãƒ©ãƒƒã‚°ã‚·ãƒƒãƒ—ç‰ˆã®Qwen3-235Bã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€ã‚ãšã‹22Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æ¨è«–ã‚’è¡Œã„ã€ã‚³ã‚¹ãƒˆã¨å“è¶Šã—ãŸèƒ½åŠ›ã‚’ä¸¡ç«‹ã—ã¦ã„ã¾ã™ã€‚å…¨ã‚·ãƒªãƒ¼ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¯å®Œå…¨ã«ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã¦ãŠã‚Šã€è»½é‡ã‹ã‚‰è¶…å¤§è¦æ¨¡ãªãƒ‹ãƒ¼ã‚ºã¾ã§ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã¾ã™ã€‚

**1. åŸºæœ¬çš„ãªä½¿ç”¨æ³•ï¼š** OpenAIäº’æ›å½¢å¼ã§è»¢é€ã—ã¾ã™ã€‚
**2. ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼š** é€šå¸¸ã®Toolså‘¼ã³å‡ºã—ã¯OpenAIäº’æ›å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ï¼ˆV2.5ã€V3ã«é©ç”¨ï¼‰ã€‚MCP Toolsã¯`qwen-agent`ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€ã¾ãš`pip install -U qwen-agent mcp`ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ã‚¢ãƒªãƒãƒå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://huggingface.co/Qwen/Qwen3-235B-A22B)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

<CodeGroup>

```py åŸºæœ¬çš„ãªä½¿ç”¨æ³•
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="Qwen/Qwen3-30B-A3B",
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ],
    stream=True
)

# ä¸€éƒ¨ã®ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯choiceså±æ€§ãŒãªã„ã‹ã€choicesãŒç©ºã®ãƒªã‚¹ãƒˆã§ã‚ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚å‡¦ç†æ–¹æ³•ï¼š
for chunk in completion:
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```

```py Tools
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)

# ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "æŒ‡å®šã•ã‚ŒãŸå ´æ‰€ã®ç¾åœ¨ã®å¤©æ°—ã‚’å–å¾—",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "éƒ½å¸‚åã€ä¾‹ï¼šæ±äº¬ã€å¤§é˜ªãªã©"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "æ¸©åº¦å˜ä½"
                    }
                },
                "required": ["location"]
            }
        }
    }
]

# ãƒ„ãƒ¼ãƒ«å®šç¾©ã‚’å«ã‚€ãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
completion = client.chat.completions.create(
    model="Qwen/Qwen3-30B-A3B", # 2.5ã¨3ã¯ã‚µãƒãƒ¼ãƒˆã€QwQã¯ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“
    messages=[
        {
            "role": "user",
            "content": "æ±äº¬ã®ä»Šæ—¥ã®å¤©æ°—ã¯ã©ã†ã§ã™ã‹ï¼Ÿ"
        }
    ],
    tools=tools,
    tool_choice="auto",  # ãƒ¢ãƒ‡ãƒ«ãŒãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ã‚’è‡ªå‹•çš„ã«æ±ºå®š
    stream=True
)

# ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æƒ…å ±ã‚’åé›†ã™ã‚‹ãŸã‚ã®è¾æ›¸
tool_calls = {}

# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å‡¦ç†
for chunk in completion:
    if not hasattr(chunk.choices, '__len__') or len(chunk.choices) == 0:
        continue
        
    delta = chunk.choices[0].delta
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å‡¦ç†
    if hasattr(delta, 'content') and delta.content:
        print(delta.content, end="")
    
    # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å‡¦ç†
    if hasattr(delta, 'tool_calls') and delta.tool_calls:
        for tool_call in delta.tool_calls:
            if not hasattr(tool_call, 'index'):
                continue
                
            idx = tool_call.index
            if idx not in tool_calls:
                tool_calls[idx] = {"name": "", "arguments": ""}
                
            if hasattr(tool_call, 'function'):
                if hasattr(tool_call.function, 'name') and tool_call.function.name:
                    tool_calls[idx]["name"] = tool_call.function.name
                if hasattr(tool_call.function, 'arguments') and tool_call.function.arguments:
                    tool_calls[idx]["arguments"] += tool_call.function.arguments

# å®Œäº†å¾Œã€åé›†ã—ãŸãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æƒ…å ±ã‚’å‡ºåŠ›
for idx, info in tool_calls.items():
    if info["name"]:
        print(f"\nãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼š{info['name']}")
    if info["arguments"]:
        print(f"å¼•æ•°ï¼š{info['arguments']}")

```

```py MCP Tools
from qwen_agent.agents import Assistant
import os

# LLMã‚’å®šç¾©
llm_cfg = {
    'model': 'Qwen/Qwen3-30B-A3B',

    # OpenAI APIã¨äº’æ›æ€§ã®ã‚ã‚‹ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼š
    'model_server': 'https://aihubmix.com/v1',
    'api_key': os.getenv('AIHUBMIX_API_KEY'),

    # ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
    # 'generate_cfg': {
    #         # è¿½åŠ ï¼šå¿œç­”ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒ`<think>this is the thought</think>this is the answer`ã®å ´åˆ
    #         # è¿½åŠ ã—ãªã„ï¼šå¿œç­”ãŒreasoning_contentã¨contentã§åˆ†é›¢ã•ã‚Œã¦ã„ã‚‹å ´åˆ
    #         'thought_in_content': True,
    #     },
}

# ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©
tools = [
    {'mcpServers': {  # MCPè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã§ãã¾ã™
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            "fetch": {
                "command": "uvx",
                "args": ["mcp-server-fetch"]
            }
        }
    },
  'code_interpreter',  # çµ„ã¿è¾¼ã¿ãƒ„ãƒ¼ãƒ«
]

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®šç¾©
bot = Assistant(llm=llm_cfg, function_list=tools)

# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ
messages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Qwenã®æœ€æ–°ã®é–‹ç™ºçŠ¶æ³ã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„'}]
for responses in bot.run(messages=messages):
    pass
print(responses)
```

</CodeGroup>

## QvQã€Qwen 2.5ã€ãŠã‚ˆã³ QwQ ã‚·ãƒªãƒ¼ã‚º

OpenAIäº’æ›å½¢å¼ã§è»¢é€ã™ã‚‹ã ã‘ã§ã€é•ã„ã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‘¼ã³å‡ºã—ã®æŠ½å‡ºã«ã‚ã‚Šã€ç©ºã®`chunk.choices[0].delta.content`ã‚’å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

**1. QvQã€Qwen 2.5 VLï¼š** ç”»åƒèªè­˜  
**2. QwQï¼š** ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¹ã‚¯  

<Info>
  `Qwen/QVQ-72B-Preview`ã¯ã€`Qwen2-VL-72B`ã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚ŒãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã€è¦–è¦šæ¨è«–ã¨ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚
</Info>

<CodeGroup>

```py Qwen 2.5 VL
from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)

image_path = "yourpath/file.png"

# ç”»åƒã‚’èª­ã¿è¾¼ã¿ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
def encode_image(image_path):
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼š{image_path}")
    
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# ç”»åƒã®base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
base64_image = encode_image(image_path)

# ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
completion = client.chat.completions.create(
    model="qwen2.5-vl-72b-instruct", # qwen2.5-vl-72b-instruct ã¾ãŸã¯ Qwen/QVQ-72B-Preview
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "ã“ã®ç”»åƒã‚’è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ç”»åƒã®å†…å®¹ã€ã‚¹ã‚¿ã‚¤ãƒ«ã€ãŠã‚ˆã³å¯èƒ½æ€§ã®ã‚ã‚‹æ„å‘³ã‚’å«ã‚ã¦ãã ã•ã„ã€‚"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{base64_image}"
                    }
                }
            ]
        }
    ],
    stream=True
)

for chunk in completion:
    # å®‰å…¨ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚ã‚‹ã‹ã‚’ç¢ºèª
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```


```py QwQ
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="Qwen/QwQ-32B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "å®‡å®™ã‚’æ”¯é…ã™ã‚‹å…ƒã€…ã®ãƒ«ãƒ¼ãƒ«ã¯ä½•ã§ã™ã‹ï¼Ÿ"}
            ]
        }
    ],
    stream=True
)

for chunk in completion:
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```

</CodeGroup>
