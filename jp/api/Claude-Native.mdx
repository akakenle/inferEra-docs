---
title: "Claudeネイティブインターフェース呼び出し"
description: " "
icon: "c"
---

## 説明

Claudeシリーズモデルは、公式のネイティブインターフェースを介した呼び出しをサポートしています。使用する前に、anthropicの依存関係をインストールまたはアップグレードしてください。

```bash
pip install -U anthropic
```

<Info>
  Claude以外のモデルは、OpenAIのインターフェース形式で呼び出してください。
</Info>

## モデル情報

| モデル名     | Claude Opus 4 | Claude Sonnet 4 | Claude Sonnet 3.7 | Claude Sonnet 3.5 | Claude Haiku 3.5 | Claude Opus 3 | Claude Haiku 3 |
| -------- | ------------- | --------------- | ----------------- | ----------------- | ---------------- | ------------- | -------------- |
| 拡張思考のサポート | はい             | はい               | はい                 | いいえ                 | いいえ                | いいえ             | いいえ              |
| コンテキストウィンドウサイズ  | 200K          | 200K            | 200K              | 200K              | 200K             | 200K          | 200K           |
| 最大出力長   | 32000トークン  | 64000トークン    | 64000トークン      | 8192トークン       | 8192トークン      | 4096トークン   | 4096トークン    |
| トレーニングデータカットオフ | 2025年3月       | 2025年3月         | 2024年11月          | 2024年4月           | 2024年7月          | 2023年8月       | 2023年8月        |

<Tip>
  1. 3.5以上のモデルの場合、4096トークンを超える出力を必要とする場合は、上記の表の「最長出力長」を参照して、明確な「max_tokens」値を渡してください。
  2. Sonnet 3.7の場合、リクエストボディに`extra_headers={"anthropic-beta": "output-128k-2025-02-19"}`を渡すことで、最大出力を64Kから128Kに拡張できます。以下の「ストリーミング128K」呼び出しを参照するか、Claude公式の[ベータヘッダーの説明](https://docs.anthropic.com/en/api/beta-headers)を参照してください。
</Tip>

## Claude 4 新機能

### 新しい拒否停止理由 (Refusal Stop Reason)

Claude 4モデルは、安全上の理由でモデルがコンテンツの生成を拒否した場合に、新しい`refusal`停止理由を導入しました。

```json
{
  "id": "msg_014XEDjypDjFzgKVWdFUXxZP",
  "type": "message",
  "role": "assistant",
  "model": "claude-sonnet-4-20250514",
  "content": [{"type": "text", "text": "喜んでお手伝いさせていただきます。"}],
  "stop_reason": "refusal",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 564,
    "cache_creation_input_tokens": 0,
    "cache_read_input_tokens": 0,
    "output_tokens": 22
  }
}
```

Claude 4に移行する際は、`refusal`停止理由を処理するようにアプリケーションを更新する必要があります。

### 拡張思考 (Extended Thinking)

拡張思考を有効にすると、Claude 4モデルのMessages APIは、Claudeの完全な思考プロセスの要約を返します。要約思考は、拡張思考のすべてのインテリジェントな利点を提供しながら、悪用を防ぎます。

APIはClaude 3.7と4モデル間で一貫していますが、拡張思考のストリーミング応答は「チャンク」伝送モードで返される可能性があり、ストリーミングイベント間に遅延が発生する可能性があります。

要約は、リクエストで指定したモデルとは異なるモデルによって処理されます。思考モデルは要約出力を表示しません。

### 交互思考 (Interleaved Thinking)

Claude 4モデルは、ツール使用と拡張思考を交互に行うことをサポートしており、ツール使用と応答が通常のメッセージと混在する、より自然な会話を可能にします。

交互思考は現在ベータ段階です。交互思考を有効にするには、APIリクエストにテストヘッダー`interleaved-thinking-2025-05-14`を追加します。

```python
extra_headers={
    "anthropic-beta": "interleaved-thinking-2025-05-14"
}
```

**エンドポイント（Endpoint）：** `POST` /v1/messages

## 呼び出し

<CodeGroup>

```shell Curl
curl https://aihubmix.com/v1/messages \
     --header "x-api-key: $ANTHROPIC_API_KEY" \ # AiHubMixで生成したキーに置き換えてください
     --header "anthropic-version: 2023-06-01" \
     --header "content-type: application/json" \
     --data \
'{
    "model": "claude-3-5-sonnet-20241022",
    "max_tokens": 1024,
    "messages": [
        {"role": "user", "content": "Hello, world"}
    ]
}'
```


```py Python 非ストリーミング
import anthropic

client = anthropic.Anthropic(
    api_key="sk-***", # AiHubMixで生成したキーに置き換えてください
    base_url="https://aihubmix.com"
)
message = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Hello, Claude"}
    ]
)
print(message.content)
```

```py Python ストリーミング 128K
import anthropic

client = anthropic.Anthropic(
    api_key="sk-***", # AiHubMixで生成したキーに置き換えてください
    base_url="https://aihubmix.com"
)

with client.messages.stream(
    model="claude-3-7-sonnet-20250219",  # claude-opus-4-20250514, claude-sonnet-4-20250514
    max_tokens=128000,
    messages=[
        {"role": "user", "content": "チャールズ・マンガーの100の思考モデルを詳細な段落でそれぞれ説明する（各モデル約1000トークン）、各モジュールにはモデルの紹介段落、多次元思考、適用方法、実践上の盲点、具体的な事例を含める、10万トークンの記事を生成してください。分かりやすく、魅力的な内容が重要です。必要な場合にのみ箇条書きにしてください。"}
    ],
    extra_headers={
        "anthropic-beta": "output-128k-2025-02-19"
    }
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
```

```py Python 交互思考
import anthropic

client = anthropic.Anthropic(
    api_key="sk-***", # AiHubMixで生成したキーに置き換えてください
    base_url="https://aihubmix.com"
)

response = client.messages.create(
    model="claude-sonnet-4-20250514",  # または claude-opus-4-20250514
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "このデータを分析してグラフを生成してください"}
    ],
    tools=[
        {
            "type": "computer_20241022",
            "name": "computer"
        }
    ],
    extra_headers={
        "anthropic-beta": "interleaved-thinking-2025-05-14"
    }
)
print(response.content)
```

</CodeGroup>

### Body リクエスト構造

```json
{
  "model": "claude-3-5-sonnet-20241022",
  "max_tokens": 1024,
  "messages": [
    {
      "role": "user",
      "content": "What is the meaning of life?"
    }
  ]
}
```

### リクエストパラメータ

| 名前           | 位置     | タイプ       | 必須 | 説明                      |
| ------------ | ------ | -------- | --- | ----------------------- |
| x-api-key    | header | string   | いいえ  | Bearer AIHUBMIX_API_KEY |
| Content-Type | header | string   | いいえ  | なし                    |
| body         | body   | object   | いいえ  | なし                    |
| » model      | body   | string   | はい  | なし                    |
| » messages   | body   | [object] | はい  | なし                    |
| »» role      | body   | string   | いいえ  | なし                    |
| »» content   | body   | string   | はい  | なし                    |
| » max_tokens | body   | number   | はい  | なし                    |

### 戻り値の例

```json
200 Response
```

```json
{
  "id": "msg_013Uf6CwwyjSe35n3yVaPbLM",
  "type": "message",
  "role": "assistant",
  "model": "claude-3-5-sonnet-20241022",
  "content": [
    {
      "type": "text",
      "text": "それは人類の最も永続的で複雑な哲学的問いの一つです！普遍的な答えはありませんが、私はその複雑さを認識しながら、そのような問いを思慮深く探求することを目指しています。私は意味のある会話をし、できる限り助けることに集中しようとします。あなたにとって人生の意味とは何ですか？"
    }
  ],
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 14,
    "cache_creation_input_tokens": 0,
    "cache_read_input_tokens": 0,
    "output_tokens": 61
  }
}
```

### 戻り値の結果

| 状態码 | 状態码含义 | 説明   | データモデル   |
| --- | ----- | ---- | ------ |
| 200 | OK    | なし | インライン |

## Claude 4への移行

Claude 3.7からClaude 4モデルに移行する場合は、以下の変更点に注意してください。

### モデル名の更新

```python
# Claude 3.7から
model="claude-3-7-sonnet-20250219"

# Claude 4へ移行
model="claude-sonnet-4-20250514"  # または "claude-opus-4-20250514"
```

### 新しい停止理由の処理

新しい`refusal`停止理由を処理するようにアプリケーションを更新してください。

```python
if response.stop_reason == "refusal":
    print("Claudeはコンテンツの生成を拒否しました")
elif response.stop_reason == "end_turn":
    print("正常に完了しました")
```

### サポートされていない機能の削除

- **トークン効率の良いツール使用**：Claude Sonnet 3.7でのみ利用可能で、Claude 4ではサポートされていません。
- **拡張出力**：`output-128k-2025-02-19`テストヘッダーはClaude Sonnet 3.7でのみ利用可能です。

Claude Sonnet 3.7から移行する場合は、これらのテストヘッダーをリクエストから削除することをお勧めします。

```python
# これらのヘッダーを削除（存在する場合）
# "token-efficient-tools-2025-02-19"
# "output-128k-2025-02-19"
```

## アプリケーションでの使用（Lobe-Chatを例に）

- 設定ページに入り、モデルプロバイダーClaudeを選択します。
- APIキーには[当サイトのキー](https://aihubmix.com/token)を入力します。
- インターフェースプロキシアドレスには、以下のURLを直接入力します。

```
https://aihubmix.com
```

- 「クライアントリクエストモードを使用」をオンにすることをお勧めします。
- 最後に、モデルリストに自分で使用したいモデルを追加します（当サイトの設定ページからモデル名をコピー＆ペーストすることをお勧めします）。
  ![画像](../../public/en/cla1.png)

  ![画像](../../public/en/cla2.png)