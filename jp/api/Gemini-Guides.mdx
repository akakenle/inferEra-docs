---
title: "Gemini ã‚¬ã‚¤ãƒ‰"
description: "Geminiã®æç”»ã¨ãƒ“ãƒ‡ã‚ªç”Ÿæˆã‚¬ã‚¤ãƒ‰"
icon: "google"
---

## Gemini å‘¼ã³å‡ºã—æ–¹æ³•

Geminiã‚·ãƒªãƒ¼ã‚ºã§ã¯ã€ãƒã‚¤ãƒ†ã‚£ãƒ–å‘¼ã³å‡ºã—ã¨OpenAIäº’æ›ã®2ç¨®é¡ã®å‘¼ã³å‡ºã—æ–¹æ³•ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚
ä½¿ç”¨ã™ã‚‹å‰ã«ã€`pip install google-genai`ã¾ãŸã¯`pip install -U google-genai`ã‚’å®Ÿè¡Œã—ã¦ã€ãƒã‚¤ãƒ†ã‚£ãƒ–ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæ›´æ–°ï¼‰ã—ã¦ãã ã•ã„ã€‚

1ï¸âƒ£ ãƒã‚¤ãƒ†ã‚£ãƒ–å‘¼ã³å‡ºã—ã®å ´åˆã€ä¸»ã«AiHubMixã‚­ãƒ¼ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒªãƒ³ã‚¯ã‚’å†…éƒ¨ã«æ¸¡ã—ã¾ã™ã€‚ã“ã®ãƒªãƒ³ã‚¯ã¯é€šå¸¸ã®`base_url`ã®æ›¸ãæ–¹ã¨ã¯ç•°ãªã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ä¾‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

```py
client = genai.Client(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    http_options={"base_url": "https://aihubmix.com/gemini"},
)
```

2ï¸âƒ£ OpenAIäº’æ›å½¢å¼ã®å ´åˆã€æ±ç”¨`v1`ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ç¶­æŒã—ã¾ã™ã€‚

```py
client = OpenAI(
    api_key="sk-***", # AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)
```

3ï¸âƒ£ 2.5ã‚·ãƒªãƒ¼ã‚ºã®å ´åˆã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡¨ç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®2ã¤ã®æ–¹æ³•ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚

1. ãƒã‚¤ãƒ†ã‚£ãƒ–å‘¼ã³å‡ºã—ï¼š`include_thoughts=True`ã‚’æ¸¡ã™
2. OpenAIäº’æ›æ–¹å¼ï¼š`reasoning_effort`ã‚’æ¸¡ã™

é–¢é€£ã™ã‚‹è©³ç´°ãªå‘¼ã³å‡ºã—ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### Gemini 2.5 ã‚·ãƒªãƒ¼ã‚ºã®ã€Œæ¨è«–ã€ã®èª¬æ˜

1. 2.5ã‚·ãƒªãƒ¼ã‚ºã¯ã™ã¹ã¦æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
2. 2.5 Flashã¯ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã§ã€Claude Sonnet 3.7ã«ä¼¼ã¦ãŠã‚Šã€`thinking_budget`ã‚’ä½¿ç”¨ã—ã¦æ¨è«–äºˆç®—ã‚’åˆ¶å¾¡ã™ã‚‹ã“ã¨ã§æœ€é©ãªåŠ¹æœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
3. 2.5 Proã¯ç´”ç²‹ãªæ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ãŸã‚ã€æ€è€ƒã‚’ã‚ªãƒ•ã«ã—ãŸã‚Šã€æ¨è«–äºˆç®—ã‚’æ˜ç¤ºçš„ã«æ¸¡ã—ãŸã‚Šã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚

**Pythonå‘¼ã³å‡ºã—ã®ä¾‹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚**

<CodeGroup>

```py é€šå¸¸ã®éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.0-flash"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ä¸€èˆ¬ã®æ ªå¼æŠ•è³‡å®¶ã«ã¨ã£ã¦ï¼šè²¡å‹™è«¸è¡¨åˆ†æãŒå½¹ç«‹ã¤ãªã‚‰ã€é‹ã¯å¿…è¦ãªã„ã®ã‹ï¼Ÿ"""),
            ],
        ),
    ]

    print(client.models.generate_content(
        model=model,
        contents=contents,
    ))

if __name__ == "__main__":
    generate()
```


```py 2.0 ã‚·ãƒªãƒ¼ã‚º - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.0-flash"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ä¸€èˆ¬ã®æ ªå¼æŠ•è³‡å®¶ã«ã¨ã£ã¦ï¼šè²¡å‹™è«¸è¡¨åˆ†æãŒå½¹ç«‹ã¤ãªã‚‰ã€é‹ã¯å¿…è¦ãªã„ã®ã‹ï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```


```py 2.5 Flash - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-flash-preview-04-17" #gemini-2.5-pro-preview-03-25ã€gemini-2.5-flash-preview-04-17
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ä¸€èˆ¬ã®æ ªå¼æŠ•è³‡å®¶ã«ã¨ã£ã¦ï¼šè²¡å‹™è«¸è¡¨åˆ†æãŒå½¹ç«‹ã¤ãªã‚‰ã€é‹ã¯å¿…è¦ãªã„ã®ã‹ï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        thinking_config = types.ThinkingConfig(
            thinking_budget=2048, #ç¯„å›² 0-16384ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 1024ã€æœ€é©ãªé™ç•ŒåŠ¹æœ 16000
        ),
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```


```py 2.5 Pro - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-03-25"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ã©ã†ã™ã‚Œã°æ™‚é–“ã‚’ç„¡é§„ã«ã—ã¦ã„ãªã„ã¨ã‚ã‹ã‚‹ã®ã‹"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```


```py æ¨è«–å†…å®¹ã®è¡¨ç¤º
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-05-06"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""é‡‘èåˆ†é‡ã®ã€Œ72ã®æ³•å‰‡ã€ã¯ã©ã®ã‚ˆã†ã«å°ãå‡ºã•ã‚ŒãŸã®ã§ã™ã‹ï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
        thinking_config=types.ThinkingConfig(
            include_thoughts=True  # ğŸ§  æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®å‡ºåŠ›ã‚’æœ‰åŠ¹ã«ã™ã‚‹
        ),
    )

    # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã®usage_metadataã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®å¤‰æ•°
    final_usage_metadata = None
    
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„éƒ¨åˆ†ãŒã‚ã‚‹ã‹ç¢ºèª
        if chunk.candidates and len(chunk.candidates) > 0:
            for part in chunk.candidates[0].content.parts:
                if part.text:
                    if part.thought:
                        # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
                        print(part.text, end="")
                    else:
                        # æœ€çµ‚å›ç­”ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
                        print(part.text, end="")
        
        # æœ€æ–°ã®usage_metadataã‚’ä¿å­˜ã€‚æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã®ã¿å®Œå…¨ãªæƒ…å ±ã‚’å«ã‚€
        if chunk.usage_metadata:
            final_usage_metadata = chunk.usage_metadata
    
    # ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†ãŒå®Œäº†ã—ãŸå¾Œã€å®Œå…¨ãªãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³ã‚’å‡ºåŠ›
    if final_usage_metadata:
        print(f"\n\nğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³:")
        print(f"æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³: {getattr(final_usage_metadata, 'thoughts_token_count', 'åˆ©ç”¨ä¸å¯')}")
        print(f"å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {getattr(final_usage_metadata, 'candidates_token_count', 'åˆ©ç”¨ä¸å¯')}")
        print(f"åˆè¨ˆ: {final_usage_metadata}")

if __name__ == "__main__":
    generate()
```

</CodeGroup>

## Gemini 2.5 Flash ã‚µãƒãƒ¼ãƒˆ

OpenAIäº’æ›æ–¹å¼ã®å‘¼ã³å‡ºã—ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

<CodeGroup>

```py Python é«˜é€Ÿã‚¿ã‚¹ã‚¯ã®å ´åˆã€æ€è€ƒã‚’ã‚ªãƒ•ã«ã™ã‚‹
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17-nothink",
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ]
)

print(completion.choices[0].message.content)
```


```py Python äºˆç®—ã‚’åˆ¶å¾¡ã™ã‚‹
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17",
    reasoning_effort="low", # "low", "medium", "high"ã‹ã‚‰é¸æŠå¯èƒ½ã§ã€ãã‚Œãã‚Œ1Kã€8Kã€24Kã®æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³äºˆç®—ã«å¯¾å¿œã—ã¾ã™ã€‚æ€è€ƒã‚’ç„¡åŠ¹ã«ã—ãŸã„å ´åˆã¯ã€reasoning_effortã‚’"none"ã«è¨­å®šã§ãã¾ã™ã€‚
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ]
)

print(completion.choices[0].message.content)
```


```shell Curl-åŸºæœ¬å‘¼ã³å‡ºã—
curl -X POST https://aihubmix.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-***" \
  -d '{
    "model": "gemini-2.5-flash-preview-04-17-nothink",
    "messages": [
      {
        "role": "user",
        "content": "Explain the Occam'\''s Razor concept and provide an everyday example of it."
      }
    ]
  }'
```


```shell Curl-æ€è€ƒè¡¨ç¤º
curl https://aihubmix.com/v1/chat/completions \
-H "Content-Type: application/json" \
-H "Authorization: Bearer sk-***" \
-d '{
  "model": "gemini-2.5-pro-preview-05-06",
  "messages": [
    {
      "role": "user",
      "content": "Explain the Occam'\''s Razor concept and provide an everyday example of it."
    }
  ],
  "reasoning_effort": "low"
}'
```

</CodeGroup>

<Tip>
  1. è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®å ´åˆã€ãƒ¢ãƒ‡ãƒ«IDã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ€è€ƒãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹`gemini-2.5-flash-preview-04-17`ã«è¨­å®šã™ã‚‹ã ã‘ã§æ¸ˆã¿ã¾ã™ã€‚
  2. Gemini 2.5 Flashã¯`budget`ï¼ˆæ€è€ƒäºˆç®—ï¼‰ã«ã‚ˆã£ã¦æ€è€ƒã®æ·±ã•ã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚ç¯„å›²ã¯0ã€œ16Kã§ã€ç¾åœ¨ã®è»¢é€ã§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®äºˆç®—1024ãŒä½¿ç”¨ã•ã‚Œã¦ãŠã‚Šã€æœ€é©ãªé™ç•ŒåŠ¹æœã¯16Kã§ã™ã€‚
</Tip>

## ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«

Aihubmixã¯ç¾åœ¨ã€`inline_data`ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ**20MBæœªæº€**ã®ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç”»åƒã€éŸ³å£°ã€ãƒ“ãƒ‡ã‚ªï¼‰ã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚
20MBã‚’è¶…ãˆã‚‹ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢ã¯File APIï¼ˆæœªã‚µãƒãƒ¼ãƒˆï¼‰ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚`upload_url`ã‚’è¿”ã™ãŸã‚ã«ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®è¿½è·¡ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã£ã¦ã„ã¾ã™ã€‚

<CodeGroup>

```py ç”»åƒ
from google import genai
from google.genai import types

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦èª­ã¿è¾¼ã‚€
file_path = "yourpath/file.jpeg"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="image/jpeg"
                )
            ),
            types.Part(
                text="ç”»åƒã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
            )
        ]
    )
)

print(response.text)
```


```py éŸ³å£°
from google import genai
from google.genai import types

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦èª­ã¿è¾¼ã‚€
file_path = "yourpath/file.m4a"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="audio/m4a"
                )
            ),
            types.Part(
                text="éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ã€‚"
            )
        ]
    )
)

print(response.text)
```


```py ãƒ“ãƒ‡ã‚ª
from google import genai
from google.genai import types

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦èª­ã¿è¾¼ã‚€
file_path = "yourpath/file.mp4"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="video/mp4"
                )
            ),
            types.Part(
                text="ã“ã®ãƒ“ãƒ‡ã‚ªã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚æ¬¡ã«ã€ã“ã®ãƒ“ãƒ‡ã‚ªã®æƒ…å ±ã«åŸºã¥ã„ã¦ã€è§£ç­”ä»˜ãã®ã‚¯ã‚¤ã‚ºã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            )
        ]
    )
)

print(response.text)
```


```py Youtube ãƒªãƒ³ã‚¯
from google import genai
from google.genai import types

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                file_data=types.FileData(
                    file_uri="https://www.youtube.com/watch?v=OoU7PwNyYUw"
                )
            ),
            types.Part(
                text="ã“ã®ãƒ“ãƒ‡ã‚ªã‚’3æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
            )
        ]
    )
)

print(response.text)
```

</CodeGroup>

## ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ

è‡ªå‹•ã‚³ãƒ¼ãƒ‰è§£æå™¨ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®ä¾‹ï¼š

```py Python
from google import genai
from google.genai import types

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦èª­ã¿è¾¼ã‚€
file_path = "yourpath/file.csv"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="text/csv"
                )
            ),
            types.Part(
                text="ã“ã®CSVã‚’åˆ†æã—ã€ä¸»è¦ãªçµ±è¨ˆæƒ…å ±ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚å¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
            )
        ]
    ),
    config=types.GenerateContentConfig(
        tools=[types.Tool(
            code_execution=types.ToolCodeExecution
        )]
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    if getattr(part, "executable_code", None) is not None:
        print("ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰:\n", part.executable_code.code)
    if getattr(part, "code_execution_result", None) is not None:
        print("å®Ÿè¡Œçµæœ:\n", part.code_execution_result.output)
```

## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥

Geminiã¯ã€ãƒã‚¤ãƒ†ã‚£ãƒ–APIã®ä¸‹ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§**æš—é»™çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥**ã‚’æœ‰åŠ¹ã«ã—ã¦ãŠã‚Šã€é–‹ç™ºè€…ãŒæ‰‹å‹•ã§æ“ä½œã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚`generate_content`ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«ã€ã‚·ã‚¹ãƒ†ãƒ ã¯è‡ªå‹•çš„ã«å…¥åŠ›ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½œæˆã—ã¾ã™ã€‚å¾Œç¶šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒä»¥å‰ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨å®Œå…¨ã«ä¸€è‡´ã™ã‚‹å ´åˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç›´æ¥ãƒ’ãƒƒãƒˆã—ã€å‰å›ã®æ¨è«–çµæœãŒè¿”ã•ã‚Œã€å¿œç­”é€Ÿåº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ã‚’ç¯€ç´„ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯è‡ªå‹•çš„ã«æœ‰åŠ¹ã«ãªã‚Šã€æ‰‹å‹•è¨­å®šã¯ä¸è¦ã§ã™ã€‚**
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå®Œå…¨ã«ä¸€è‡´ã™ã‚‹å ´åˆã«ã®ã¿æœ‰åŠ¹ã«ãªã‚Šã¾ã™ã€‚ã„ãšã‚Œã‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç•°ãªã‚‹å ´åˆã€æ–°ã—ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ã—ã¦æ‰±ã‚ã‚Œã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒ’ãƒƒãƒˆã—ã¾ã›ã‚“ã€‚
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æœŸé™ï¼ˆTTLï¼‰ã¯é–‹ç™ºè€…ãŒè¨­å®šã§ãã¾ã™ã€‚è¨­å®šã—ãªã„ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚æŒ‡å®šã—ãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1æ™‚é–“ã§ã™ã€‚æœ€å°ã¾ãŸã¯æœ€å¤§æœŸé–“ã®åˆ¶é™ã¯ãªãã€è²»ç”¨ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ™‚é–“ã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã™ã€‚
  - Googleå…¬å¼ã¯TTLã«ä¸Šé™ã‚’è¨­å®šã—ã¦ã„ã¾ã›ã‚“ãŒã€å½“ç¤¾ã¯è»¢é€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã‚ã‚‹ãŸã‚ã€**é™ã‚‰ã‚ŒãŸTTLè¨­å®šç¯„å›²ã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€æ°¸ç¶šçš„ãªæœ‰åŠ¹æ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“**ã€‚

### æ³¨æ„äº‹é …

- **ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ä¿è¨¼ãªã—**ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã®èª²é‡‘ã¯å…¥åŠ›å…ƒã®ä¾¡æ ¼ã®25%ã§ã‚ã‚Šã€ç†è«–çš„ã«ã¯å…¥åŠ›éƒ¨åˆ†ã§æœ€å¤§75%ã®ã‚³ã‚¹ãƒˆã‚’ç¯€ç´„ã§ãã¾ã™ãŒã€[**Googleå…¬å¼ã¯å¿…ãšã—ã‚‚ç¯€ç´„ã‚’ä¿è¨¼ã—ã¦ã„ã¾ã›ã‚“**](https://ai.google.dev/gemini-api/docs/caching?lang=python)ã€‚å®Ÿéš›ã®è«‹æ±‚ã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ—ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æœŸé–“ã‚’ç·åˆçš„ã«è©•ä¾¡ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ¡ä»¶**ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€é‡è¤‡ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å…ˆé ­ã«é…ç½®ã—ã€å¤‰å‹•ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãªã©ï¼‰ã‚’å¾Œéƒ¨ã«é…ç½®ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**ï¼šå¿œç­”çµæœãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ’ãƒƒãƒˆã—ãŸå ´åˆã€`response.usage_metadata`ã«`cache_tokens_details`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå«ã¾ã‚Œã€`cached_content_token_count`ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚é–‹ç™ºè€…ã¯ã“ã‚Œã«åŸºã¥ã„ã¦ã€ä»Šå›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ’ãƒƒãƒˆã—ãŸã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã§ãã¾ã™ã€‚
  å¿œç­”ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ä¾‹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ï¼‰ï¼š

  ```
  cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=2003)]
  cached_content_token_count=2003
  ```

**ã‚³ãƒ¼ãƒ‰ä¾‹ï¼š**

```python
from google import genai

client = genai.Client(
    http_options={"base_url": "https://aihubmix.com/gemini"},
    api_key="sk-***", # AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
)

prompt = """
ã€Œä¸‰å›½å¿—æ¼”ç¾©ã€ã®è©©ï¼šè¾æ›¸ã‚’é–‹ã æ»”ã€…ãŸã‚‹é•·æ±Ÿã¯æ±ã¸æµã‚Œã€æ³¢ã¯è‹±é›„ã‚’æ´—ã„æµã™ã€‚æ˜¯ã‹éã‹ã€æˆåŠŸã‹å¤±æ•—ã‹ã€ä¸€ç¬ã«ã—ã¦ç©ºã¨ãªã‚‹ï¼šé’å±±ã¯ä¾ç„¶ã¨ã—ã¦ãã“ã«ã‚ã‚Šã€å¤•æ—¥ã¯ä½•åº¦ã‹èµ¤ãæŸ“ã¾ã‚‹ã€‚ç™½é«ªã®æ¼å¸«ã¨æ¨µã¯æ±Ÿã®ã»ã¨ã‚Šã§ã€ç§‹ã®æœˆã¨æ˜¥ã®é¢¨ã‚’æ…£ã‚Œè¦ªã—ã‚€ã€‚ä¸€æ¯ã®æ¿é…’ã§å†ä¼šã‚’å–œã³åˆã†ï¼šå¤ä»Šæ±è¥¿ã®å¤šãã®å‡ºæ¥äº‹ã¯ã€ç¬‘ã„è©±ã®ä¸­ã«æ¶ˆãˆã‚‹ã€‚2 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šå¤©ä¸‹ã®æƒ…å‹¢ã‚’èªã‚Œã°ã€åˆ†ã‹ã‚Œã¦ã¯å¿…ãšåˆã—ã€åˆã—ã¦ã¯å¿…ãšåˆ†ã‹ã‚Œã‚‹ï¼šå‘¨ã®æœ«æœŸã€ä¸ƒå›½ãŒäº‰ã„ã€ç§¦ã«çµ±ä¸€ã•ã‚ŒãŸã€‚ç§¦ãŒæ»…ã³ãŸå¾Œã€æ¥šã¨æ¼¢ãŒäº‰ã„ã€å†ã³æ¼¢ã«çµ±ä¸€ã•ã‚ŒãŸã€‚æ¼¢ç‹æœã¯é«˜ç¥–ãŒç™½è›‡ã‚’æ–¬ã£ã¦èœ‚èµ·ã—ã€å¤©ä¸‹ã‚’çµ±ä¸€ã—ãŸã€‚ãã®å¾Œã€å…‰æ­¦å¸ãŒä¸­èˆˆã—ã€çŒ®å¸ã«ä¼ã‚ã‚Šã€ã¤ã„ã«ä¸‰å›½ã«åˆ†ã‹ã‚ŒãŸã€‚ãã®ä¹±ã®åŸå› ã‚’æ¨æ¸¬ã™ã‚Œã°ã€ãŠãã‚‰ãæ¡“å¸ã¨éœŠå¸ã®äºŒå¸ã«å§‹ã¾ã‚‹ã€‚æ¡“å¸ã¯å–„äººã‚’ç¦å›ºã—ã€å®¦å®˜ã‚’å´‡æ‹ã—ãŸã€‚æ¡“å¸ãŒå´©å¾¡ã—ã€éœŠå¸ãŒå³ä½ã™ã‚‹ã¨ã€å¤§å°†è»ã®ç«‡æ­¦ã¨å¤ªå‚…ã®é™³è•ƒãŒå…±ã«è£œä½ã—ãŸã€‚å½“æ™‚ã€å®¦å®˜ã®æ›¹ç¯€ã‚‰ãŒæ¨©åŠ›ã‚’å¼„ã³ã€ç«‡æ­¦ã¨é™³è•ƒã¯å½¼ã‚‰ã‚’èª…æ®ºã—ã‚ˆã†ã¨è¬€ã£ãŸãŒã€äº‹ãŒå¯†ã§ãªãã€ã‹ãˆã£ã¦å®³ã•ã‚ŒãŸã€‚ä¸­æ¶“ã¯ã“ã‚Œä»¥æ¥ã¾ã™ã¾ã™æ¨ªæš´ã«ãªã£ãŸã€‚3 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šå»ºå¯§äºŒå¹´å››æœˆæœ›æ—¥ã€å¸ã¯æ¸©å¾³æ®¿ã«å¾¡ã—ãŸã€‚åº§ã«ç€ãã¨ã€æ®¿ã®è§’ã‹ã‚‰ç‹‚é¢¨ãŒçªç„¶å¹ãè’ã‚Œã€æ¢ã‹ã‚‰ä¸€æ¡ã®å¤§ããªé’è›‡ãŒé£›æ¥ã—ã€æ¤…å­ã«å·»ãä»˜ã„ãŸã€‚å¸ã¯é©šãå€’ã‚Œã€å·¦å³ã¯æ€¥ã„ã§å®®ä¸­ã«æ•‘ã„å…¥ã‚ŒãŸãŒã€ç™¾å®˜ã¯çš†é€ƒã’æƒ‘ã£ãŸã€‚ã—ã°ã‚‰ãã™ã‚‹ã¨ã€è›‡ã¯è¦‹ãˆãªããªã£ãŸã€‚çªç„¶ã€å¤§é›·é›¨ã¨é›¹ãŒé™ã‚Šå§‹ã‚ã€å¤œåŠã¾ã§æ­¢ã¾ãšã€ç„¡æ•°ã®å®¶å±‹ã‚’ç ´å£Šã—ãŸã€‚å»ºå¯§å››å¹´äºŒæœˆã€æ´›é™½ã§åœ°éœ‡ãŒç™ºç”Ÿã—ã€ã¾ãŸæµ·æ°´ãŒæ°¾æ¿«ã—ã€æ²¿å²¸ã®ä½æ°‘ã¯çš†å¤§æ³¢ã«å·»ãè¾¼ã¾ã‚Œã¦æµ·ä¸­ã«æ¶ˆãˆãŸã€‚å…‰å’Œå…ƒå¹´ã€é›Œé¶ãŒé›„ã«å¤‰åŒ–ã—ãŸã€‚å…­æœˆæœ”ã€é»’ã„æ°—ãŒåä½™ä¸ˆã€æ¸©å¾³æ®¿ä¸­ã«é£›ã³è¾¼ã‚“ã ã€‚ç§‹ä¸ƒæœˆã€ç‰å ‚ã«è™¹ãŒè¦‹ãˆã€äº”åŸã®å±±å²¸ã¯ã™ã¹ã¦å´©å£Šã—ãŸã€‚æ§˜ã€…ãªä¸å‰ãªå‡ºæ¥äº‹ã¯ã€ã“ã‚Œã ã‘ã§ã¯ãªã‹ã£ãŸã€‚4 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šå¸ã¯è©”ã‚’ä¸‹ã—ã€ç¾¤è‡£ã«ç½ç•°ã®åŸå› ã‚’å•ã†ãŸã€‚è­°éƒã®è”¡é‚•ã¯ä¸Šå¥ã—ã€è™¹ãŒè½ã¡ã€é¶ãŒå¤‰åŒ–ã—ãŸã®ã¯ã€å©¦äººã‚„å®¦å®˜ãŒæ”¿æ²»ã«å¹²æ¸‰ã—ãŸãŸã‚ã§ã‚ã‚‹ã¨è¿°ã¹ã€ãã®è¨€è‘‰ã¯ã‹ãªã‚Šç‡ç›´ã§ã‚ã£ãŸã€‚å¸ã¯å¥ã‚’èª­ã‚“ã§ãŸã‚æ¯ã‚’ã¤ãã€è¡£ã‚’æ›´ãˆã‚‹ãŸã‚ã«ç«‹ã¡ä¸ŠãŒã£ãŸã€‚æ›¹ç¯€ã¯å¾Œã‚ã§ç›—ã¿è¦‹ã¦ã€å·¦å³ã«ã™ã¹ã¦ã‚’å‘Šã’ãŸã€‚ãã—ã¦ã€ä»–ã®ã“ã¨ã§è”¡é‚•ã‚’ç½ªã«é™¥ã‚Œã€ç”°èˆã«å¸°ã‚‰ã›ãŸã€‚ãã®å¾Œã€å¼µè­²ã€è¶™å¿ ã€å°è«ã€æ®µåœ­ã€æ›¹ç¯€ã€å€™è¦§ã€è¹‡ç¢©ã€ç¨‹æ› ã€å¤æ½ã€éƒ­å‹ã®åäººãŒå¾’å…šã‚’çµ„ã‚“ã§æ‚ªäº‹ã‚’åƒãã€ã€Œåå¸¸ä¾ã€ã¨å‘¼ã°ã‚ŒãŸã€‚å¸ã¯å¼µè­²ã‚’æ·±ãä¿¡é ¼ã—ã€ã€Œé˜¿çˆ¶ã€ã¨å‘¼ã³ã€æœæ”¿ã¯æ—¥ã”ã¨ã«ä¹±ã‚Œã€å¤©ä¸‹ã®äººå¿ƒã¯ä¹±ã‚Œã€ç›—è³ŠãŒèœ‚èµ·ã—ãŸã€‚5 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šå½“æ™‚ã€é‰…é¹¿éƒ¡ã«ä¸‰å…„å¼ŸãŒã„ãŸã€‚ä¸€äººã¯å¼µè§’ã€ä¸€äººã¯å¼µå®ã€ä¸€äººã¯å¼µæ¢ã€‚ãã®å¼µè§’ã¯ã‚‚ã¨ã‚‚ã¨ç§‘æŒ™ã«åˆæ ¼ã—ãªã‹ã£ãŸç§€æ‰ã§ã‚ã£ãŸã€‚å±±ã«å…¥ã£ã¦è–¬è‰ã‚’æ¡ã£ã¦ã„ãŸã¨ã“ã‚ã€ç¢§çœ¼ç«¥é¡”ã§è—œæ–ã‚’æŒã£ãŸè€äººã«å‡ºä¼šã„ã€è§’ã‚’æ´çªŸã«å‘¼ã³å¯„ã›ã€å¤©æ›¸ä¸‰å·»ã‚’æˆã‘ãŸã€‚ã€Œã“ã‚Œã¯å¤ªå¹³è¦è¡“ã¨ã„ã†ã€‚æ±ã“ã‚Œã‚’å¾—ã‚Œã°ã€å¤©ã«ä»£ã‚ã£ã¦æ•™åŒ–ã‚’åºƒã‚ã€ä¸–äººã‚’æ•‘æ¸ˆã™ã‚‹ã ã‚ã†ã€‚ã‚‚ã—ç•°å¿ƒã‚’æŠ±ã‘ã°ã€å¿…ãšæ‚ªå ±ã‚’å—ã‘ã‚‹ã ã‚ã†ã€‚ã€è§’ã¯æ‹ã—ã¦å§“åã‚’å°‹ã­ãŸã€‚è€äººã¯ã€Œå¾ã¯å—è¯è€ä»™ã§ã‚ã‚‹ã€‚ã€ã¨è¨€ã„çµ‚ãˆã‚‹ã¨ã€ä¸€é™£ã®æ¸…é¢¨ã¨ãªã£ã¦å»ã£ãŸã€‚6 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šè§’ã¯ã“ã®æ›¸ã‚’å¾—ã¦ã€æ˜¼å¤œæ”»ã‚ç¿’ã„ã€é¢¨ã‚’å‘¼ã³é›¨ã‚’é™ã‚‰ã›ã‚‹ã“ã¨ãŒã§ãã€å¤ªå¹³é“äººã¨å·ã—ãŸã€‚ä¸­å¹³å…ƒå¹´æ­£æœˆã€ç–«ç—…ãŒæµè¡Œã—ã€å¼µè§’ã¯ç¬¦æ°´ã‚’æ•£å¸ƒã—ã¦äººã€…ã®ç—…æ°—ã‚’æ²»ã—ã€è‡ªã‚‰ã‚’å¤§è³¢è‰¯å¸«ã¨ç§°ã—ãŸã€‚è§’ã«ã¯äº”ç™¾ä½™äººã®å¼Ÿå­ãŒãŠã‚Šã€å››æ–¹ã‚’éŠæ­´ã—ã€çš†ç¬¦ã‚’æ›¸ãå‘ªæ–‡ã‚’å”±ãˆã‚‹ã“ã¨ãŒã§ããŸã€‚ãã®å¾Œã€å¼Ÿå­ãŒæ—¥ã”ã¨ã«å¢—ãˆã€è§’ã¯ä¸‰åå…­æ–¹ï¼ˆå¤§æ–¹ã¯ä¸€ä¸‡ä½™äººã€å°æ–¹ã¯å…­ä¸ƒåƒäººï¼‰ã‚’è¨­ã‘ã€ãã‚Œãã‚Œã«æ¸ å¸¥ã‚’ç«‹ã¦ã€å°†è»ã¨ç§°ã—ãŸã€‚æµè¨€ã‚’åºƒã‚ã¦ã€Œè’¼å¤©ã¯ã™ã§ã«æ­»ã—ã€é»„å¤©ãŒç«‹ã¤ã¹ã—ã€‚ã€ã¨è¨€ã„ã€ã¾ãŸã€Œæ­³ã¯ç”²å­ã«ã‚ã‚Šã€å¤©ä¸‹ã¯å¤§å‰ã€‚ã€ã¨è¨€ã„ã€äººã€…ã«ç™½ã„åœŸã§ã€Œç”²å­ã€ã®äºŒå­—ã‚’å®¶ã€…ã®å¤§é–€ã«æ›¸ã‹ã›ãŸã€‚é’ã€å¹½ã€å¾ã€å†€ã€èŠã€æšã€å…—ã€è±«ã®å…«å·ã®äººã€…ã¯ã€å®¶ã€…ã§å¤§è³¢è‰¯å¸«å¼µè§’ã®åã‚’ç¥€ã£ãŸã€‚è§’ã¯ãã®å…šã®é¦¬å…ƒç¾©ã‚’é£ã‚ã—ã€å¯†ã‹ã«é‡‘å¸›ã‚’æºãˆã€ä¸­æ¶“ã®å°è«ã¨çµã³ã€å†…å¿œã¨ã—ãŸã€‚å”å·ã¯çœä¸­ã«ç›´è¡Œã—ã¦å‘Šç™ºã—ãŸã€‚å¸ã¯å¤§å°†è»ã®ä½•é€²ã‚’å¬ã—ã€å…µã‚’å‹•ã‹ã—ã¦é¦¬å…ƒç¾©ã‚’æ•ã‚‰ãˆã€æ–¬ã‚‰ã›ãŸã€‚æ¬¡ã«å°è«ã‚‰ä¸€å‘³ã‚’ç„ã«ä¸‹ã—ãŸã€‚7 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šå¼µè§’ã¯äº‹ãŒéœ²è¦‹ã—ãŸã“ã¨ã‚’çŸ¥ã‚Šã€å¤œã‚’å¾¹ã—ã¦æŒ™å…µã—ã€è‡ªã‚‰ã‚’å¤©å…¬å°†è»ã¨ç§°ã—ãŸï¼ˆå¼µå®ã¯åœ°å…¬å°†è»ã€å¼µæ¢ã¯äººå…¬å°†è»ã¨ç§°ã—ãŸï¼‰ã€‚è¡†ã«ç”³ã—ã¦è¨€ã£ãŸã€‚ã€Œä»Šã€æ¼¢ã®é‹ã¯ã¾ã•ã«å°½ãã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã€‚å¤§è–äººãŒç¾ã‚Œã‚‹ã€‚æ±ã‚‰ã¯çš†ã€å¤©æ„ã«å¾“ã„ã€å¤ªå¹³ã‚’åŠ©ã‘ã‚‹ã¹ãã§ã‚ã‚‹ã€‚ã€å››æ–¹ã®æ°‘è¡†ã¯ã€é»„å·¾ã‚’é ­ã«å·»ãã€å¼µè§’ã«å¾“ã£ã¦åä¹±ã‚’èµ·ã“ã—ãŸè€…ãŒå››ã€äº”åä¸‡äººã«åŠã‚“ã ã€‚è³Šã®å‹¢ã„ã¯ç”šã ã—ãã€å®˜è»ã¯é¢¨ã‚’è¦‹ã¦é¡ã„ãŸã€‚ä½•é€²ã¯å¸ã«æ€¥ãè©”ã‚’ä¸‹ã—ã€å„åœ°ã«é˜²å‚™ã‚’å‘½ã˜ã€è³Šã‚’è¨ã¡åŠŸã‚’ç«‹ã¦ã‚‹ã‚ˆã†å¥ä¸Šã—ãŸã€‚ä¸€æ–¹ã€ä¸­éƒå°†ã®ç›§æ¤ã€çš‡ç”«åµ©ã€æœ±é›‹ã‚’é£ã‚ã—ã€ãã‚Œãã‚Œç²¾å…µã‚’ç‡ã„ã¦ä¸‰è·¯ã«åˆ†ã‹ã‚Œã¦è¨ä¼ã•ã›ãŸã€‚8 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šã•ã¦ã€å¼µè§’ã®ä¸€è»ã¯ã€å¹½å·ã®å¢ƒã‚’çŠ¯ã—ãŸã€‚å¹½å·å¤ªå®ˆã®åŠ‰ç„‰ã¯ã€æ±Ÿå¤ç«Ÿé™µã®äººã§ã€æ¼¢ã®é­¯æ­ç‹ã®å¾Œè£”ã§ã‚ã‚‹ã€‚å½“æ™‚ã€è³Šå…µãŒè¿«ã£ã¦ã„ã‚‹ã¨èãã€æ ¡å°‰ã®é„’é–ã‚’å¬ã—ã¦è¨ˆè­°ã—ãŸã€‚é–ã¯è¨€ã£ãŸã€‚ã€Œè³Šå…µã¯å¤šãã€æˆ‘å…µã¯å°‘ãªã„ã€‚æ˜å…¬ã¯é€Ÿã‚„ã‹ã«å…µã‚’å‹Ÿã‚Šã€æ•µã«å¿œã˜ã‚‹ã¹ãã§ã™ã€‚ã€åŠ‰ç„‰ã¯ãã®è¨€è‘‰ã‚’æ˜¯ã¨ã—ã€ã™ãã«æ¦œæ–‡ã‚’å‡ºã—ã¦ç¾©å…µã‚’å‹Ÿã£ãŸã€‚æ¦œæ–‡ãŒæ¶¿çœŒã«å±Šãã¨ã€æ¶¿çœŒã®ä¸­ã‹ã‚‰ä¸€äººã®è‹±é›„ãŒç¾ã‚ŒãŸã€‚9 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šãã®äººã¯ã‚ã¾ã‚Šèª­æ›¸ã‚’å¥½ã¾ãšã€æ€§æ ¼ã¯å¯›å¤§ã§ã€è¨€è‘‰å°‘ãªãã€å–œæ€’ã‚’é¡”ã«å‡ºã•ãªã‹ã£ãŸã€‚å¸¸ã«å¤§ããªå¿—ã‚’æŠ±ãã€å¤©ä¸‹ã®è±ªå‚‘ã¨äº¤ã‚ã‚‹ã“ã¨ã‚’å¥½ã‚“ã ã€‚èº«é•·ã¯ä¸ƒå°ºäº”å¯¸ã€ä¸¡è€³ã¯è‚©ã¾ã§å‚ã‚Œã€ä¸¡æ‰‹ã¯è†ã‚’è¶Šãˆã€ç›®ã¯è‡ªåˆ†ã®è€³ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã€é¡”ã¯å† ç‰ã®ã‚ˆã†ã§ã€å”‡ã¯ç´…ã‚’å¡—ã£ãŸã‚ˆã†ã§ã‚ã£ãŸã€‚ä¸­å±±é–ç‹åŠ‰å‹ã®å¾Œè£”ã§ã€æ¼¢æ™¯å¸ã®ç„å­«ã«ã‚ãŸã‚‹ã€‚å§“ã¯åŠ‰ã€åã¯å‚™ã€å­—ã¯ç„å¾³ã€‚æ˜”ã€åŠ‰å‹ã®å­åŠ‰è²ã¯ã€æ¼¢æ­¦å¸ã®æ™‚ã«æ¶¿é¹¿äº­ä¾¯ã«å°ã˜ã‚‰ã‚ŒãŸãŒã€å¾Œã«é…¬é‡‘ã§ä¾¯ã‚’å¤±ã„ã€ãã®ãŸã‚ã“ã®ä¸€æ—ãŒæ¶¿çœŒã«æ®‹ã£ãŸã€‚ç„å¾³ã®ç¥–çˆ¶ã¯åŠ‰é›„ã€çˆ¶ã¯åŠ‰å¼˜ã€‚å¼˜ã¯å­å»‰ã«æŒ™ã’ã‚‰ã‚Œã€ã¾ãŸå½¹äººã«ãªã£ãŸã“ã¨ã‚‚ã‚ã£ãŸãŒã€æ—©ãã«äº¡ããªã£ãŸã€‚ç„å¾³ã¯å¹¼ãã—ã¦å­¤å…ã¨ãªã‚Šã€æ¯ã«å­ã‚’å°½ãã—ãŸã€‚å®¶ã¯è²§ã—ãã€è‰å±¥ã‚’å£²ã£ãŸã‚Šç­µã‚’ç¹”ã£ãŸã‚Šã—ã¦ç”Ÿè¨ˆã‚’ç«‹ã¦ãŸã€‚å®¶ã¯æœ¬çœŒã®æ¥¼æ¡‘æ‘ã«ã‚ã£ãŸã€‚ãã®å®¶ã®æ±å—ã«ã¯ã€é«˜ã•äº”ä¸ˆä½™ã‚Šã®å¤§ããªæ¡‘ã®æœ¨ãŒã‚ã‚Šã€é ãã‹ã‚‰è¦‹ã‚‹ã¨ã€è»Šè“‹ã®ã‚ˆã†ã«ã“ã‚“ã‚‚ã‚Šã¨ã—ã¦ã„ãŸã€‚ç›¸è€…ã¯è¨€ã£ãŸã€‚ã€Œã“ã®å®¶ã‹ã‚‰ã¯å¿…ãšè²´äººãŒå‡ºã‚‹ã ã‚ã†ã€‚ã€10 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šç„å¾³ãŒå¹¼ã„é ƒã€æ‘ã®å­ä¾›ãŸã¡ã¨æœ¨ã®ä¸‹ã§éŠã‚“ã§ã„ãŸæ™‚ã€ã€Œç§ã¯å¤©å­ã¨ãªã‚Šã€ã“ã®è»Šè“‹ã«ä¹—ã‚‹ã ã‚ã†ã€‚ã€ã¨è¨€ã£ãŸã€‚å”çˆ¶ã®åŠ‰å…ƒèµ·ã¯ãã®è¨€è‘‰ã«é©šãã€ã€Œã“ã®å­ã¯ä¸¦ã®äººé–“ã§ã¯ãªã„ï¼ã€ã¨è¨€ã£ãŸã€‚ç„å¾³ã®å®¶ãŒè²§ã—ã„ã®ã‚’è¦‹ã¦ã€å¸¸ã«æ´åŠ©ã—ãŸã€‚åäº”æ­³ã«ãªã‚‹ã¨ã€æ¯ã«å‘½ã˜ã‚‰ã‚Œã¦éŠå­¦ã—ã€é„­ç„ã€ç›§æ¤ã«å¸«äº‹ã—ãŸã€‚å…¬å­«ç“šã‚‰ã¨å‹ã¨ãªã£ãŸã€‚åŠ‰ç„‰ãŒå…µã‚’å‹Ÿã‚‹æ¦œæ–‡ã‚’å‡ºã—ãŸæ™‚ã€ç„å¾³ã¯ã™ã§ã«äºŒåå…«æ­³ã§ã‚ã£ãŸã€‚ãã®æ—¥ã€æ¦œæ–‡ã‚’è¦‹ã¦ã€æ…¨ç„¶ã¨ãŸã‚æ¯ã‚’ã¤ã„ãŸã€‚ã™ã‚‹ã¨ã€ä¸€äººã®ç”·ãŒå³ã—ã„å£°ã§è¨€ã£ãŸã€‚ã€Œå¤§ä¸ˆå¤«ãŒå›½ã®ãŸã‚ã«å°½åŠ›ã—ãªã„ã¨ã¯ã€ãªãœãŸã‚æ¯ã‚’ã¤ãã®ã‹ï¼Ÿã€11 è¾æ›¸ã‚’é–‹ã æ¡ƒåœ’ã§å®´ä¼šã‚’å‚¬ã—ã€è±ª...ï¼šç„å¾³ã¯ãã®ç”·ã‚’æŒ¯ã‚Šè¿”ã£ãŸã€‚èº«é•·ã¯å…«å°ºã€è±¹ã®é ­ã«ç’°ã®ã‚ˆã†ãªç›®ã€ç‡•ã®é¡ã«è™ã®é«­ã€å£°ã¯å·¨é›·ã®ã‚ˆã†ã€å‹¢ã„ã¯å¥”é¦¬ã®ã‚ˆã†ã§ã‚ã£ãŸã€‚ç„å¾³ã¯ãã®å®¹è²ŒãŒå°‹å¸¸ã§ãªã„ã®ã‚’è¦‹ã¦ã€å§“åã‚’å°‹ã­ãŸã€‚ãã®ç”·ã¯è¨€ã£ãŸã€‚ã€ŒæŸã¯å¼µã¨ã„ã„ã€åã¯é£›ã€å­—ã¯ç¿¼å¾³ã€‚ä»£ã€…æ¶¿éƒ¡ã«ä½ã¿ã€ã‹ãªã‚Šã®è˜åœ’ã‚’æŒã¡ã€é…’ã‚’å£²ã‚Šè±šã‚’å± ã‚Šã€å¤©ä¸‹ã®è±ªå‚‘ã¨äº¤ã‚ã‚‹ã“ã¨ã‚’å¥½ã‚“ã§ãŠã‚Šã¾ã™ã€‚å…ˆã»ã©å…¬ãŒæ¦œæ–‡ã‚’è¦‹ã¦ãŸã‚æ¯ã‚’ã¤ã‹ã‚ŒãŸã®ã‚’è¦‹ã¦ã€å°‹ã­ãŸæ¬¡ç¬¬ã§ã™ã€‚ã€ç„å¾³ã¯è¨€ã£ãŸã€‚ã€Œç§ã¯æ¼¢å®¤ã®å®—è¦ªã§ã€å§“ã¯åŠ‰ã€åã¯... [çœç•¥]"""

def generate_content_sync():
    response = client.models.generate_content(
        model="gemini-2.5-flash-preview-05-20",
        contents=prompt + "ä¸‰å›½å¿—æ¼”ç¾©ã®ã“ã®å›ã«ç™»å ´ã™ã‚‹äººç‰©ã¯ä½•äººã§ã™ã‹ï¼Ÿ ",
    )
    print(response.usage_metadata)  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ã«cache_tokens_detailsã¨cached_content_token_countãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    return response

generate_content_sync()
```

> ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ã€`response.usage_metadata`ã¯ä»¥ä¸‹ã®æ§‹é€ ã‚’å«ã¿ã¾ã™ã€‚
>
> ```
> cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=2003)]
> cached_content_token_count=2003
> ```

**æ ¸å¿ƒçš„ãªçµè«–ï¼š**æš—é»™çš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯è‡ªå‹•ãƒ’ãƒƒãƒˆã¨ãƒ’ãƒƒãƒˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚é–‹ç™ºè€…ã¯usage_metadataã‚’é€šã˜ã¦ãƒ’ãƒƒãƒˆçŠ¶æ³ã‚’åˆ¤æ–­ã§ãã¾ã™ã€‚ã‚³ã‚¹ãƒˆå‰Šæ¸›ã¯ä¿è¨¼ã•ã‚Œãšã€å®Ÿéš›ã®çµæœã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹é€ ã¨ä½¿ç”¨ã‚·ãƒŠãƒªã‚ªã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã™ã€‚

## é–¢æ•°å‘¼ã³å‡ºã—

OpenAIäº’æ›æ–¹å¼ã§Geminiã®é–¢æ•°å‘¼ã³å‡ºã—æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£å†…ã«`tool_choice="auto"`ã‚’æ¸¡ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã†ã—ãªã„ã¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™ã€‚

<CodeGroup>

```py Python
from openai import OpenAI

# ãƒ¢ãƒ‡ãƒ«ã®é–¢æ•°å®£è¨€ã‚’å®šç¾©
schedule_meeting_function = {
    "name": "schedule_meeting",
    "description": "æŒ‡å®šã•ã‚ŒãŸå‚åŠ è€…ã¨æ—¥æ™‚ã§ä¼šè­°ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã¾ã™ã€‚",
    "parameters": {
        "type": "object",
        "properties": {
            "attendees": {
                "type": "array",
                "items": {"type": "string"},
                "description": "ä¼šè­°ã«å‚åŠ ã™ã‚‹äººã®ãƒªã‚¹ãƒˆã€‚",
            },
            "date": {
                "type": "string",
                "description": "ä¼šè­°ã®æ—¥ä»˜ï¼ˆä¾‹ï¼š'2024-07-29'ï¼‰",
            },
            "time": {
                "type": "string",
                "description": "ä¼šè­°ã®æ™‚é–“ï¼ˆä¾‹ï¼š'15:00'ï¼‰",
            },
            "topic": {
                "type": "string",
                "description": "ä¼šè­°ã®ä¸»é¡Œã¾ãŸã¯ãƒˆãƒ”ãƒƒã‚¯ã€‚",
            },
        },
        "required": ["attendees", "date", "time", "topic"],
    },
}

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¨­å®š
client = OpenAI(
    api_key="sk-***", # AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)

# OpenAIäº’æ›å½¢å¼ã§é–¢æ•°å®£è¨€ã‚’å«ã‚€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
response = client.chat.completions.create(
    model="gemini-2.0-flash",
    messages=[
        {"role": "user", "content": "Bobã¨Aliceã¨ã®ä¼šè­°ã‚’2025å¹´3æœˆ14æ—¥åˆå‰10æ™‚ã«Q3è¨ˆç”»ã«ã¤ã„ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚"}
    ],
    tools=[{"type": "function", "function": schedule_meeting_function}],
    tool_choice="auto" ## ğŸ“ ã“ã“ã«AiHubmixäº’æ›ã®ã€ã‚ˆã‚Šå®‰å®šã—ãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆæ–¹æ³•ã‚’è¿½åŠ ã—ã¾ã—ãŸ
)

# é–¢æ•°å‘¼ã³å‡ºã—ã‚’ç¢ºèª
if response.choices[0].message.tool_calls:
    tool_call = response.choices[0].message.tool_calls[0]
    function_call = tool_call.function
    print(f"å‘¼ã³å‡ºã™é–¢æ•°: {function_call.name}")
    print(f"å¼•æ•°: {function_call.arguments}")
    print(response.usage)
    # å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ã“ã“ã§é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚
    # result = schedule_meeting(**json.loads(function_call.arguments))
else:
    print("å¿œç­”ã«é–¢æ•°å‘¼ã³å‡ºã—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    print(response.choices[0].message.content)
```

</CodeGroup>

**å‡ºåŠ›çµæœã®ä¾‹ï¼š**

```bash
å‘¼ã³å‡ºã™é–¢æ•°: schedule_meeting
å¼•æ•°: {"attendees":["Bob","Alice"],"date":"2025-03-14","time":"10:00","topic":"Q3 planning"}
CompletionUsage(completion_tokens=28, prompt_tokens=111, total_tokens=139, completion_tokens_details=None, prompt_tokens_details=None)
```

## ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡è¿½è·¡

1. Geminiã¯ãƒã‚¤ãƒ†ã‚£ãƒ–APIã§`usage_metadata`ã‚’ä½¿ç”¨ã—ã¦[ä½¿ç”¨ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½è·¡](https://ai.google.dev/gemini-api/docs/tokens?lang=python)ã—ã¾ã™ã€‚ãã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

- prompt_token_count: å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°
- candidates_token_count: å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°
- thoughts_token_count: æ¨è«–ã«ä½¿ç”¨ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€‚æ€§è³ªä¸Šã€ã“ã‚Œã‚‚å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã§ã™ã€‚
- total_token_count: ç·ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ï¼ˆå…¥åŠ›+å‡ºåŠ›ï¼‰

2. OpenAIäº’æ›å½¢å¼ã®å ´åˆã€`.usage`ã‚’ä½¿ç”¨ã—ã¦è¿½è·¡ã—ã¾ã™ã€‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

- usage.completion_tokens: å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°
- usage.prompt_tokens: å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆæ¨è«–ã«ä½¿ç”¨ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å«ã‚€ï¼‰
- usage.total_tokens: ç·ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡

**ä½¿ç”¨æ–¹æ³•ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚**

<CodeGroup>

```py Gemini ãƒã‚¤ãƒ†ã‚£ãƒ–
from google import genai
from google.genai import types
import time

def generate():
    client = genai.Client(
        api_key="sk-***", # AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-03-25"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""é‡‘èåˆ†é‡ã®ã€Œ72ã®æ³•å‰‡ã€ã¯ã©ã®ã‚ˆã†ã«å°ãå‡ºã•ã‚ŒãŸã®ã§ã™ã‹ï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    final_usage_metadata = None
    
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")
        if chunk.usage_metadata:
            final_usage_metadata = chunk.usage_metadata
    
    # ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†ãŒå®Œäº†ã—ãŸå¾Œã€å®Œå…¨ãªãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³ã‚’å‡ºåŠ›
    if final_usage_metadata:
        print(f"\nUsage: {final_usage_metadata}")

if __name__ == "__main__":
    generate()
```


```py OpenAI äº’æ›
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # AiHubMixã§ç”Ÿæˆã—ãŸã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17",
    reasoning_effort="low", # "low", "medium", "high"ã‹ã‚‰é¸æŠå¯èƒ½ã§ã€ãã‚Œãã‚Œ1Kã€8Kã€24Kã®æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³äºˆç®—ã«å¯¾å¿œã—ã¾ã™ã€‚æ€è€ƒã‚’ç„¡åŠ¹ã«ã—ãŸã„å ´åˆã¯ã€reasoning_effortã‚’"none"ã«è¨­å®šã§ãã¾ã™ã€‚
    messages=[
        {
            "role": "user",
            "content": "é‡‘èåˆ†é‡ã®ã€Œ72ã®æ³•å‰‡ã€ã¯ã©ã®ã‚ˆã†ã«å°ãå‡ºã•ã‚ŒãŸã®ã§ã™ã‹ï¼Ÿ"
        }
    ],
    stream=True
)

#print(completion.choices[0].message.content)

for chunk in completion:
    print(chunk.choices[0].delta)
    # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ï¼ˆå®Œå…¨ãªä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰ã®å ´åˆã«ã®ã¿ä½¿ç”¨é‡æƒ…å ±ã‚’å‡ºåŠ›
    if chunk.usage and chunk.usage.completion_tokens > 0:
        print(f"å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {chunk.usage.completion_tokens}")
        print(f"å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {chunk.usage.prompt_tokens}")
        print(f"ç·ãƒˆãƒ¼ã‚¯ãƒ³: {chunk.usage.total_tokens}")
```

</CodeGroup>