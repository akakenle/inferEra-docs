---
title: "常见问题"
description: "高频问题请先查阅此文档"
icon: 'square-question'
---

## 为什么LLM 回答错误的模型基座信息？

### 模型幻觉：LLM 自信却错误的自我认知

在使用 GPT-4、Claude 等大语言模型时，开发者可能会遇到模型对于自身基座、来源或性能的描述明显错误。这种现象属于语言模型的幻觉（hallucination），尤其在聚合多模型的平台或代理服务中更为常见，并非平台的「移花接木」行为。

你可以通过相关可追踪的系统指标进行交叉验证，例如：

- **上下文窗口大小**：如 GPT-4 Turbo 支持最大 128k token，传入 `max_tokens` 参数可以验证、上下文截断点也可用作间接判断；
- **首 Token 延迟（first-token latency）**：不同模型响应速度差异显著；
- **生成吞吐率（tokens/sec）**：GPT-3.5 和 Claude-Haiku 明显快于 GPT-4 或 Claude-Opus；
- **系统 API 返回的 Headers 或元数据**：如 model-id、provider 字段；
- **原生调用**：OpenAI 或 Gemini 模型无法通过 Claude 原生方式请求，其他类似情况同理；
- **输出风格指纹**：Claude 系列往往更加克制含蓄，GPT 系列更逻辑导向。

通过上述信号协同观察，可辅助验证模型实际运行基座，避免将幻觉误当作系统真相。  
如果你需要追踪首 Token 延迟或吞吐率的测试脚本，可以到此[下载](https://github.com/jerlinn/inferHub/tree/main/scripts)。

### 常见幻觉场景举例

| 问题类型     | 示例问题                     | 典型幻觉回应                                       |
|--------------|------------------------------|----------------------------------------------------|
| 模型基座识别 | 你是 GPT-4 吗？           | 我是 GPT-4 Turbo，于 2024 年发布。           |
| 模型来源识别 | 你是 Claude 吗？         | 我是 Claude 3.5 Sonnet 模型，由 Anthropic 提供。 |
| 性能比较问题 | 你和 Gemini 谁更快？     | 我速度更快，参数更多。（凭空构造）              |

### 原因分析

1. **语言模型并非感知型系统**  
   模型对自身所处环境无感知能力。它只是基于上下文提示预测最可能出现的回答，而非读取系统实际信息。

2. **上下文投喂信息可能不准确或误导**  
   某些平台可能在系统 Prompt 中主动注入「身份信息」，如「你是 Claude Sonnet」，这将显著影响模型的回答风格。

3. **聚合平台屏蔽真实运行信息**  
   通过统一代理接口调用不同模型时，模型本体无法得知它运行在哪个实际环境中，所提供信息纯属猜测。

### 应对措施

#### 1. 禁止信任模型自身的基座回答

不要将模型生成的自我说明作为系统真实配置的来源。所有「我是某模型」或「我基于某平台」的说法都应被视为**上下文中的文本**，而非真实信息。

#### 2. 从系统后端传递可信信息

通过接口返回模型基座信息，而非依赖模型回答。例如：

```json
{
  "model_id": "claude-sonnet-202405",
  "provider": "Anthropic",
  "source": "official_api",
  "note": "Do not infer identity from model's own response"
}
````

该字段可在调用链中透传到前端，供用户与调试使用。

#### 3. 使用明确系统 Prompt 注入真实身份

如果确需模型自我标识，请在 `system prompt` 明确注入身份，并设置规则禁止其发挥：

```
你运行在某某平台，由后端调用 Anthropic Claude Sonnet 模型。请勿修改或猜测模型身份。
```

#### 4. 在前端标注系统识别信息

避免将模型回答直接展示为「模型信息」，应当在用户界面明确标注「由系统提供」或「由模型生成」的区分。

#### 5. 幻觉检测与可信度降权

引入幻觉检测机制，对回答中包含“我是 GPT-4”之类的内容，进行可信度打分或添加警示提示。可结合关键词识别、LLM 二次审查等方式实现。

### 总结

语言模型并不能可靠识别自己的模型基座、平台来源或能力边界。要构建可信的 AI 产品，**真实来源必须由系统提供，而非由模型口中得出**。

## 为什么我在 Claude 官网上和通过 API 调用时，使用相同的提示词和内容输入，输出结果却不同？

Claude 的网页版（Claude.ai）和移动 App 默认会在每次对话开始时加入一个系统提示（system prompt）。这个提示提供了重要的上下文信息，比如当前日期、建议使用的回答风格（如 Markdown 格式代码）、语气基调、角色指引，以及其他可能影响输出的辅助信息。

Anthropic 会定期更新这些提示，以持续优化模型行为。**这些系统提示内容是完全公开的**，你可以在 [Anthropic 官方文档](https://docs.anthropic.com/en/release-notes/system-prompts) 中查阅各模型对应的 system prompt。

相比之下，API 调用默认不会添加任何系统提示，除非你手动设置。这就意味着，即使使用相同的用户提示词，Web 与 API 的响应可能存在明显差异。

**如你希望通过 API 模拟 Claude.ai 的行为表现，建议显式添加官方公布的 system prompt。**

## 为什么 gpt-4 额度消耗这么快？
- gpt-4 的消耗速度是 gpt-3.5-turbo 的 20 到 40 倍，假设购买了 9w token，我们用 30 倍作为平均倍率，也就是 90000 / 30 = 3000 字左右，加上每次要附带上历史消息，能发的消息数将会进一步减半，在最极限的情况下，一条消息就能把 9w token 消耗完，所以请谨慎使用。   

## 使用 Next Web 时，有哪些节省 token 的小技巧？
- 点开对话框上方的设置按钮，找到里面的设置项：  
  - 携带历史消息数：数量越少，消耗 token 越少，但同时 gpt 会忘记之前的对话  
  - 历史摘要：用于记录长期话题，关闭后可以减少 token 消耗  
  - 注入系统级提示词：用于提升 ChatGPT 的回复质量，关闭后可减少 token 消耗  
- 点开左下角设置按钮，关闭自动生成标题，可以减少 token 消耗  
- 在对话时，点击对话框上方的机器人图标，可以快捷切换模型，可以优先使用 3.5 问答，如果回答不满意，再切换为 4.0 重新提问。  

## 为什么后台创建 key 没有显示已用额度
当设置成无限额度后，不会更新已用额度，修改无限额度为有限额度即可  

## 用户协议  
付款即视为同意本协议！否则请不要付款！  
1. 本服务不会以任何形式持久化存储任何用户的任何聊天信息；  
2. 本服务不知晓也无从知晓用户在本服务上传输的任何文本内容，用户使用本服务引发的任何违法犯罪后果，由使用者承担，本服务将全力配合由此可能引起的相关调查；  