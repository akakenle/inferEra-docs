---
title: "常见问题"
description: "高频问题请先查阅此文档"
icon: 'square-question'
---

## 为什么LLM 回答错误的模型基座信息？

### 模型幻觉：LLM 自信却错误的自我认知

在使用 GPT-4、Claude 等大语言模型时，开发者可能会遇到模型对于自身基座、来源或性能的描述明显错误。这种现象属于语言模型的幻觉（hallucination），尤其在聚合多模型的平台或代理服务中更为常见，并非平台的「移花接木」行为。

你可以通过相关可追踪的系统指标进行交叉验证，例如：

- **上下文窗口大小**：如 GPT-4 Turbo 支持最大 128k token，上下文截断点可间接判断；
- **首 Token 延迟（first-token latency）**：不同模型响应速度差异显著；
- **生成吞吐率（tokens/sec）**：GPT-3.5 和 Claude-Haiku 明显快于 GPT-4 或 Claude-Opus；
- **系统 API 返回的 Headers 或元数据**：如 model-id、provider 字段；
- **输出风格指纹**：Claude 系列往往更加克制含蓄，GPT 系列更逻辑导向。

通过上述信号协同观察，可辅助验证模型实际运行基座，避免将幻觉误当作系统真相。
如果你需要追踪首 Token 延迟或吞吐率的测试脚本，可以到此[下载](https://github.com/jerlinn/inferHub/tree/main/scripts)。

### 常见幻觉场景举例

| 问题类型     | 示例问题                     | 典型幻觉回应                                       |
|--------------|------------------------------|----------------------------------------------------|
| 模型基座识别 | 你是 GPT-4 吗？           | 我是 GPT-4 Turbo，于 2024 年发布。           |
| 模型来源识别 | 你是 Claude 吗？         | 我是 Claude 3.5 Sonnet 模型，由 Anthropic 提供。 |
| 性能比较问题 | 你和 Gemini 谁更快？     | 我速度更快，参数更多。（凭空构造）              |

### 原因分析

1. **语言模型并非感知型系统**  
   模型对自身所处环境无感知能力。它只是基于上下文提示预测最可能出现的回答，而非读取系统实际信息。

2. **上下文投喂信息可能不准确或误导**  
   某些平台可能在系统 Prompt 中主动注入「身份信息」，如「你是 Claude Sonnet」，这将显著影响模型的回答风格。

3. **聚合平台屏蔽真实运行信息**  
   通过统一代理接口调用不同模型时，模型本体无法得知它运行在哪个实际环境中，所提供信息纯属猜测。

### 应对措施

#### 1. 禁止信任模型自身的基座回答

不要将模型生成的自我说明作为系统真实配置的来源。所有「我是某模型」或「我基于某平台」的说法都应被视为**上下文中的文本**，而非真实信息。

#### 2. 从系统后端传递可信信息

通过接口返回模型基座信息，而非依赖模型回答。例如：

```json
{
  "model_id": "claude-sonnet-202405",
  "provider": "Anthropic",
  "source": "official_api",
  "note": "Do not infer identity from model's own response"
}
````

该字段可在调用链中透传到前端，供用户与调试使用。

#### 3. 使用明确系统 Prompt 注入真实身份

如果确需模型自我标识，请在 `system prompt` 明确注入身份，并设置规则禁止其发挥：

```
你运行在某某平台，由后端调用 Anthropic Claude Sonnet 模型。请勿修改或猜测模型身份。
```

#### 4. 在前端标注系统识别信息

避免将模型回答直接展示为「模型信息」，应当在用户界面明确标注「由系统提供」或「由模型生成」的区分。

#### 5. 幻觉检测与可信度降权

引入幻觉检测机制，对回答中包含“我是 GPT-4”之类的内容，进行可信度打分或添加警示提示。可结合关键词识别、LLM 二次审查等方式实现。

### 总结

语言模型并不能可靠识别自己的模型基座、平台来源或能力边界。要构建可信的 AI 产品，**真实来源必须由系统提供，而非由模型口中得出**。

## 为什么 gpt-4 额度消耗这么快？
- gpt-4 的消耗速度是 gpt-3.5-turbo 的 20 到 40 倍，假设购买了 9w token，我们用 30 倍作为平均倍率，也就是 90000 / 30 = 3000 字左右，加上每次要附带上历史消息，能发的消息数将会进一步减半，在最极限的情况下，一条消息就能把 9w token 消耗完，所以请谨慎使用。   

## 使用 Next Web 时，有哪些节省 token 的小技巧？
- 点开对话框上方的设置按钮，找到里面的设置项：  
  - 携带历史消息数：数量越少，消耗 token 越少，但同时 gpt 会忘记之前的对话  
  - 历史摘要：用于记录长期话题，关闭后可以减少 token 消耗  
  - 注入系统级提示词：用于提升 ChatGPT 的回复质量，关闭后可减少 token 消耗  
- 点开左下角设置按钮，关闭自动生成标题，可以减少 token 消耗  
- 在对话时，点击对话框上方的机器人图标，可以快捷切换模型，可以优先使用 3.5 问答，如果回答不满意，再切换为 4.0 重新提问。  

## 为什么 GPT4 不知道它自己是谁？
直接问 GPT4：「你是谁？」、「你是什么模型？」等问题，一般情况下 GPT4 的 API 也会回答自己是 GPT3，估计是官方预置的原因。GPT4 和 3.5 用的都是 2021 年之前的数据，那时候还没有 GPT4。  
官网和某些套壳不回答是 GPT3，是因为他们提前预设了提示词，让 GPT 认为自己是别的模型了，这个可以通过问答所消耗的总 token 看出来，预设提示词是会消耗 token 的。  
如果说你对比官网和 API 的回答，发现有所不一，那也很正常。一是因为，GPT4 对同一个问题的每次回答都是不同的；二是，官网对 GPT4 的参数进行了一定的优化。  

更多科普：[知乎](https://zhuanlan.zhihu.com/p/646500946)

## 为什么 GPT4 会给出这么弱智的回答，我还是觉得你们是假的 GPT4？
GPT4 也不是万能的，训练参数并不比 GPT3 大多少，不用因为营销号的宣传神话 GPT4。而且由于中文语料在训练中的占比很小，在回答中文问题时，不排除在某些问题上表现不佳，同样的问题用英文问可能结果完全不一样，您可以试着用英文提问试试。  
GPT4 强在推理能力，从目前大家的使用体验中来看，写代码方面会比 gpt3.5 强很多，但仍然会给出胡编的答案。  

## 如何检验 GPT3.5 还是 GPT4？
我们提供了一个简单的方法来验证您使用的是 GPT3.5 还是 GPT4。以下是一些测试问题及
其不同模型的预期回答，您可以使用这些问题来测试。
测试问题：  
•昨天的当天的明天是哪天？GPT-3.5 应答“昨天”，而 GPT-4 应答“今天”。
•树上有 9 只鸟，猎人射杀了一只，还剩下多少只？GPT-3.5 可能说“8 只”，GPT-4 会告诉你“0
只，其他的鸟都飞走了”。  
•为什么周树人要打鲁迅？GPT-3.5 可能给出一个编造的答案，而 GPT-4 会指出“鲁迅”和”周树人"是同一个人。  
## 我不信，你们就是套壳 3.5，骗人是 gpt4
平台每个月都会在 gpt 接口上支付给供应商大量的成本，如果您因为自己不懂行区分不出来底层是不是 gpt4，还非要坚信自己的判断，那只能说您不是平台的客户群体。您可以去用你"觉得"是"真"GPT4 的其他平台的服务。 

## 那 GPT4 和 GPT3.5 到底有什么差别？
从模型的角度讲，GPT3.5 最大只支持 4k，也就是大约 2000 个汉字左右，超过这个 token 数量就会报错，
无法处理。我们的 gpt-4 模型支持最大 8k（约 4000 个汉字），gpt-4-32k 模型支持最大 32k（约 16000 个汉字），这个是接口层面最大的区别，可以传入超长上下文让 GPT4 学习和处理，这个是 GPT3.5 做不到的。  
从实际效果上讲，GPT4 对于需要复杂逻辑推理的问题会体现出明显的优势，OpenAI 推出 GPT4 时，给出过一个例子，就是列出好几个人可以参会的时间，让 GPT 找出一个大家都有空的时间，GPT3 给出的答案是错误的废话，GPT4 给出的答案就是对。不过经过实际测试，只有在英文提问时才能表现出这种准确性，同样的问题翻译为中文答案就是错误的，可见 GPT4 目前并不是银弹，只是一个 GPT3.5 的进化版，还有很多不尽人意的地方。这方面网上有很多测评博主都测评过，您可以学习下他们怎么测试的。

## 为什么后台创建 key 没有显示已用额度
当设置成无限额度后，不会更新已用额度，修改无限额度为有限额度即可  

用户协议  
付款即视为同意本协议！否则请不要付款！  
1. 本服务不会以任何形式持久化存储任何用户的任何聊天信息；  
2. 本服务不知晓也无从知晓用户在本服务上传输的任何文本内容，用户使用本服务引发的任何违法犯罪后果，由使用者承担，本服务将全力配合由此可能引起的相关调查；  