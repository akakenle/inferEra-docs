---
title: "常见问题"
description: "高频问题请先查阅此文档"
icon: "square-question"
---

## 一、模型使用与安全

### 为什么 Claude 或 GPT 等官方产品与 API 返回结果不同？

模型本身是相同的，不同在于网页版进行了额外的工程优化。

- 网页版相当于精装修房，内置搜索、记忆、计算器、系统提示等功能；
- API 调用相当于毛坯房，只提供核心能力，需要开发者自行配置上下文和工具。

---

### 为什么使用 GPT-5 或 o 系列模型时可能被 AiHubmix 封号？

在使用 GPT-5 或 o 系列模型时，如果在提示词中请求模型“展示推理过程”、“显示思维链”或 “reasoning trace” 等内容，系统可能会触发安全策略，导致账号被暂时限制或封禁。

- 官方对 GPT-5 与 o 系列模型的安全策略相对严格，正常使用不会导致封禁；
- 若出现误封或异常提示，可联系客服协助处理；
- 如需查看模型的推理摘要，可通过 Response API 获取结果，而不建议在 Prompt 中直接请求模型输出推理过程，以避免触发安全策略。

---

### 为什么不推荐在翻译类工具中使用 GPT-5 系列模型？

GPT-5 系列属于推理模型，设计目标是执行复杂推理与结构化生成，不适合高频实时任务。 

**原因：**

- 调用速度较慢（推理步骤多）；
- 消耗更多 Token（系统提示和推理上下文较长）；
- 翻译插件可能误触安全策略。

翻译或对话场景推荐使用 GPT-4o mini 或 Gemini 等轻量模型，响应更快更稳定。

---

### 为什么问“你是谁”时，GPT-5 有时会回答“我是 GPT-4”？

这种现象属于语言模型的幻觉，表现为模型对自身基座、来源或能力的描述错误。  在使用 GPT-4、GPT-5、Claude 等大语言模型时，开发者可能会遇到模型自信却不准确地回答自身身份的情况。

**说明：**

- 这种现象并非平台故意修改或替换模型输出，也不是“移花接木”，属于 LLM 的正常行为；
- GPT-5 在训练阶段并未被赋予“GPT-5”这个名称，这个名字是官方在训练完成后定义的；
- 模型本身不知道自己的名称或知识库时间；如果 OpenAI 的网页版本能正确回答是因为网页内置了系统提示词；我们这边是官方的 API 版本非网页版本。
- 通过 API 直接询问模型自身身份时，回答可能随机且不准确，因为模型本身并不具备自我认知。

---

### 为什么只发了一句“你好”，却消耗了很多 Tokens？

部分第三方工具（如 Cline、Claude Code 等）在请求时会自动携带上下文或系统提示，这些隐藏内容也会计入 Token 消耗。

即使用户只输入一句“你好”，后台请求中可能包含大量历史对话或设定文本。

这些附加内容来自工具端，而非 AiHubMix 平台生成。

---

### 为什么我只调用了 GPT-4o，却也看到 4o-mini 的消耗？

在部分第三方工具或场景中，为了实现对话总结、搜索或辅助计算等功能，系统可能会额外调用轻量模型（如 4o-mini）来处理这些任务。因此，在账单或日志中可能会出现多个模型的混合消耗记录。

这种额外消耗来源于工具功能的配置，而非 AiHubMix 自动切换模型。

---

### API 并发请求的频率限制是多少？

AiHubMix 当前对并发请求没有统一限制。若遇到并发问题，请联系客服。

---

### 为什么相同提示词，每次生成结果不同？

大模型在生成文本时使用概率采样机制（如 temperature、top-p 等），每次会从多个可能的词中随机选择。

- 若希望结果更稳定，可降低 temperature 或关闭采样；
- 生成差异也可能受上下文、系统提示或网络环境影响。

---

## 二、API 调用与数据

### 有哪些可用的 API 接口？

AIHubMix 提供统一网关，兼容多种主流模型规范：

- **OpenAI 标准端点**：`https://aihubmix.com/v1`（支持 GPT 及兼容模型）
- **Gemini 专属端点**：`https://aihubmix.com/gemini`（适配 Google 原生规范）
- **Claude 自动转发端点**：`https://aihubmix.com`（兼容 Anthropic SDK 调用方式）

---

### API 使用期间会记录哪些数据？

我们仅记录必要的使用数据，包括账户信息、调用记录、使用模型、Token 消耗量及支付信息。

**隐私保障：**

- 不会保存用户输入或模型输出内容；
- 数据仅用于计费与服务优化，不会用于内容分析或向第三方共享；
- AiHubMix 自身不会保留具体请求数据，但若底层云厂商（如模型提供方或托管平台）出于安全或合规要求记录访问日志，该部分数据将受其隐私政策约束。

详情请见[《AiHubMix 隐私政策》](https://docs.aihubmix.com/cn/terms-and-privacy/Privacy)。

---

## 三、模型知识与常见现象

### 什么是 AI 幻觉（AI Hallucination）？

AI 幻觉是指大型语言模型生成与事实不符、缺乏依据或完全虚构的信息。

**可能原因：**

- 训练数据偏差或缺失；
- 模型参数过拟合；
- 生成阶段存在随机性。

幻觉是所有大语言模型的共性现象，并非系统故障。

---

## 四、使用与故障排查

### 如何监控 API 使用情况和消耗？

可通过 AiHubMix 控制台查看调用量、Token 消耗量及计费明细。

支持按模型、时间段进行分类统计，便于优化调用策略和成本管理。

---

### 调用失败或报错时该怎么办？

API 返回错误时会附带错误码与说明。

常见原因包括：

- 请求格式错误；
- 模型不可用或超出限额。

可参考[《API 手册》](https://docs.aihubmix.com/cn/api-playground/inferUsages)快速定位问题，或联系客服获取支持。

---

### 如何管理 API Key？

用户可在控制台生成、撤销或更新 API Key。

**安全建议：**

- 不要在公共环境中暴露 API Key；
- 为不同项目使用独立 Key；
- 定期更换以保障账户安全。