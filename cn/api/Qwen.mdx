---
title: "é˜¿é‡Œé€šä¹‰ç³»åˆ—"
icon: "a"
---

## Qwen 3 ç³»åˆ—

Qwen3 ç³»åˆ—æ˜¯é˜¿é‡Œæ¨å‡ºçš„æ–°ä¸€ä»£å¼€æºå¤§æ¨¡å‹ï¼Œèƒ½åŠ›å¤§å¹…è·ƒå‡ï¼šåœ¨ä»£ç ç†è§£ã€æ•°å­¦æ¨ç†ã€å¤šè¯­è¨€è¡¨è¾¾ã€å¤æ‚æ¨æ–­ä»»åŠ¡ä¸Šï¼Œæ¯”è‚©ç”šè‡³è¶…è¶Šäº†ç›®å‰å¸‚é¢ä¸Šçš„é¡¶çº§æ¨¡å‹ï¼ˆå¦‚ o1ã€DeepSeek-R1ï¼‰ã€‚**å®ƒçš„æ ¸å¿ƒçªç ´åœ¨äºå¼•å…¥äº†ã€Œæ€è€ƒæ¨¡å¼ã€ä¸ã€Œéæ€è€ƒæ¨¡å¼ã€åˆ‡æ¢æœºåˆ¶ï¼Œè®©æ¨¡å‹åœ¨é¢å¯¹ä¸åŒéš¾åº¦ä»»åŠ¡æ—¶ï¼Œè‡ªä¸»è°ƒèŠ‚æ¨ç†æ·±åº¦ï¼Œå®ç°äº†é€Ÿåº¦ä¸ç²¾åº¦çš„åŒä¼˜å¹³è¡¡ã€‚** æ——èˆ°ç‰ˆ Qwen3-235B é‡‡ç”¨ç¨€ç–æ¿€æ´»ï¼Œä»…ç”¨ 22B å‚æ•°æ¨ç†ï¼Œå…¼é¡¾æˆæœ¬å’Œå“è¶Šèƒ½åŠ›ã€‚å…¨ç³»æ¨¡å‹å…¨é¢å¼€æºï¼Œæ¶µç›–ä»è½»é‡åˆ°è¶…å¤§è§„æ¨¡éœ€æ±‚ã€‚

**1. åŸºç¡€ç”¨æ³•ï¼š** ç”¨ OpenAI å…¼å®¹æ ¼å¼è½¬å‘
**2. å·¥å…·è°ƒç”¨ï¼š** ä¸æ”¯æŒOpenAI å…¼å®¹æ ¼å¼ï¼Œéœ€è¦å…ˆè¿è¡ŒæŒ‡ä»¤å®‰è£…ä¾èµ–ï¼š

`pip install -U qwen-agent mcp`ã€‚

æ›´å¤šç»†èŠ‚å¯ä»¥å‚è€ƒ[é˜¿é‡Œå®˜æ–¹æ–‡æ¡£](https://huggingface.co/Qwen/Qwen3-235B-A22B)

<CodeGroup>

```py åŸºç¡€ç”¨æ³•
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="Qwen/Qwen3-30B-A3B",
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ],
    stream=True
)

for chunk in completion:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```


```py Tools + mcp
from qwen_agent.agents import Assistant
import os

# Define LLM
llm_cfg = {
    'model': 'Qwen/Qwen3-30B-A3B',

    # Use the endpoint provided by Alibaba Model Studio:
    # 'model_type': 'qwen_dashscope',
    # 'api_key': os.getenv('DASHSCOPE_API_KEY'),

    # Use a custom endpoint compatible with OpenAI API:
    'model_server': 'https://aihubmix.com/v1',
    'api_key': os.getenv('AIHUBMIX_API_KEY'),

    # Other parameters:
    # 'generate_cfg': {
    #         # Add: When the response content is `<think>this is the thought</think>this is the answer;
    #         # Do not add: When the response has been separated by reasoning_content and content.
    #         'thought_in_content': True,
    #     },
}

# Define Tools
tools = [
    {'mcpServers': {  # You can specify the MCP configuration file
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            "fetch": {
                "command": "uvx",
                "args": ["mcp-server-fetch"]
            }
        }
    },
  'code_interpreter',  # Built-in tools
]

# Define Agent
bot = Assistant(llm=llm_cfg, function_list=tools)

# Streaming generation
messages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]
for responses in bot.run(messages=messages):
    pass
print(responses)
```

</CodeGroup>

## Qwen 2.5 å’Œ QwQ ç³»åˆ—

ç”¨ OpenAI çš„å…¼å®¹æ ¼å¼è½¬å‘å³å¯ï¼ŒåŒºåˆ«åœ¨äºæµå¼è°ƒç”¨ï¼Œéœ€è¦æå– `chunk.choices[0].delta.content`ï¼Œå‚è€ƒå¦‚ä¸‹ã€‚

**1. Qwen 2.5 vlï¼š** å›¾ç‰‡è¯†åˆ«
**2. QwQï¼š** æ–‡æœ¬ä»»åŠ¡

<CodeGroup>

```py Qwen 2.5 vl
from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

# å›¾ç‰‡è·¯å¾„
image_path = "yourpath/file.png"

# è¯»å–å¹¶ç¼–ç å›¾ç‰‡
def encode_image(image_path):
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
    
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# è·å–å›¾ç‰‡çš„ base64 ç¼–ç 
base64_image = encode_image(image_path)

# åˆ›å»ºåŒ…å«æ–‡æœ¬å’Œå›¾åƒçš„æ¶ˆæ¯
completion = client.chat.completions.create(
    model="qwen2.5-vl-72b-instruct",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ï¼ŒåŒ…æ‹¬å›¾ç‰‡ä¸­çš„å†…å®¹ã€é£æ ¼å’Œå¯èƒ½çš„å«ä¹‰ã€‚"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{base64_image}"
                    }
                }
            ]
        }
    ],
    stream=True
)

for chunk in completion:
    # å®‰å…¨åœ°æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```


```py QwQ
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="Qwen/QVQ-72B-Preview",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "æ”¯é…å®‡å®™çš„å…ƒè§„åˆ™æ˜¯ä»€ä¹ˆï¼Ÿ"}
            ]
        }
    ],
    stream=True
)

for chunk in completion:
    # å®‰å…¨åœ°æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```

</CodeGroup>