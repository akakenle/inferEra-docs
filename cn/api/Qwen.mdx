---
title: "阿里通义系列"
icon: "a"
---

## Qwen 3 系列

Qwen3 系列是阿里推出的新一代开源大模型，能力大幅跃升：在代码理解、数学推理、多语言表达、复杂推断任务上，比肩甚至超越了目前市面上的顶级模型（如 o1、DeepSeek-R1）。**它的核心突破在于引入了「思考模式」与「非思考模式」切换机制，让模型在面对不同难度任务时，自主调节推理深度，实现了速度与精度的双优平衡。** 旗舰版 Qwen3-235B 采用稀疏激活，仅用 22B 参数推理，兼顾成本和卓越能力。全系模型全面开源，涵盖从轻量到超大规模需求。

**1. 基础用法：** 用 OpenAI 兼容格式转发
**2. 工具调用：** 不支持OpenAI 兼容格式，需要先运行指令安装依赖：

`pip install -U qwen-agent mcp`。

更多细节可以参考[阿里官方文档](https://huggingface.co/Qwen/Qwen3-235B-A22B)

<CodeGroup>

```py 基础用法
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # 🔑 换成你在 AiHubMix 生成的密钥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="Qwen/Qwen3-30B-A3B",
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ],
    stream=True
)

for chunk in completion:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```


```py Tools + mcp
from qwen_agent.agents import Assistant
import os

# Define LLM
llm_cfg = {
    'model': 'Qwen/Qwen3-30B-A3B',

    # Use the endpoint provided by Alibaba Model Studio:
    # 'model_type': 'qwen_dashscope',
    # 'api_key': os.getenv('DASHSCOPE_API_KEY'),

    # Use a custom endpoint compatible with OpenAI API:
    'model_server': 'https://aihubmix.com/v1',
    'api_key': os.getenv('AIHUBMIX_API_KEY'),

    # Other parameters:
    # 'generate_cfg': {
    #         # Add: When the response content is `<think>this is the thought</think>this is the answer;
    #         # Do not add: When the response has been separated by reasoning_content and content.
    #         'thought_in_content': True,
    #     },
}

# Define Tools
tools = [
    {'mcpServers': {  # You can specify the MCP configuration file
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            "fetch": {
                "command": "uvx",
                "args": ["mcp-server-fetch"]
            }
        }
    },
  'code_interpreter',  # Built-in tools
]

# Define Agent
bot = Assistant(llm=llm_cfg, function_list=tools)

# Streaming generation
messages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]
for responses in bot.run(messages=messages):
    pass
print(responses)
```

</CodeGroup>

## Qwen 2.5 和 QwQ 系列

用 OpenAI 的兼容格式转发即可，区别在于流式调用，需要提取 `chunk.choices[0].delta.content`，参考如下。

**1. Qwen 2.5 vl：** 图片识别
**2. QwQ：** 文本任务

<CodeGroup>

```py Qwen 2.5 vl
from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key="sk-***", # 🔑 换成你在 AiHubMix 生成的密钥
    base_url="https://aihubmix.com/v1",
)

# 图片路径
image_path = "yourpath/file.png"

# 读取并编码图片
def encode_image(image_path):
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"图片文件不存在：{image_path}")
    
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# 获取图片的 base64 编码
base64_image = encode_image(image_path)

# 创建包含文本和图像的消息
completion = client.chat.completions.create(
    model="qwen2.5-vl-72b-instruct",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "请详细描述这张图片，包括图片中的内容、风格和可能的含义。"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{base64_image}"
                    }
                }
            ]
        }
    ],
    stream=True
)

for chunk in completion:
    # 安全地检查是否有内容
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```


```py QwQ
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # 🔑 换成你在 AiHubMix 生成的密钥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="Qwen/QVQ-72B-Preview",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "支配宇宙的元规则是什么？"}
            ]
        }
    ],
    stream=True
)

for chunk in completion:
    # 安全地检查是否有内容
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```

</CodeGroup>