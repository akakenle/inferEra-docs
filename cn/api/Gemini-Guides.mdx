---
title: "Gemini æŒ‡å—"
description: "åŒå­æ˜Ÿæ¼«æ¸¸æŒ‡å—ï¼šå…³äºæœ¬ç«™çš„ Gemini è°ƒç”¨ç»†èŠ‚ï¼Œåœ¨æ­¤æ±‡æ€»ã€‚"
icon: 'google'
---

## Gemini 2.5 Flash æ”¯æŒ

æœ¬ç«™ç›®å‰ä»¥ Openai çš„å…¼å®¹æ–¹å¼æä¾› Gemini 2.5 Flash çš„ API æ”¯æŒã€‚
ç”¨äºå¿«é€Ÿä»»åŠ¡æ—¶ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç è¿›è¡Œè°ƒç”¨**å…³é—­æ€è€ƒ**çš„æ¨¡å‹ï¼š
<CodeGroup>
```py Python
from openai import OpenAI
import os

client = OpenAI(
    api_key=os.getenv("AIHUBMIX_API_KEY"),
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17-nothink",
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ]
)

print(completion.choices[0].message.content)
```

```shell Curl
curl -X POST https://aihubmix.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-***" \
  -d '{
    "model": "gemini-2.5-flash-preview-04-17-nothink",
    "messages": [
      {
        "role": "user",
        "content": "Explain the Occam'\''s Razor concept and provide an everyday example of it."
      }
    ]
  }'
```
</CodeGroup>

ç”¨äºå¤æ‚ä»»åŠ¡æ—¶ï¼Œåªéœ€è¦å°†æ¨¡å‹ id è®¾ç½®ä¸ºé»˜è®¤å¼€å¯æ€è€ƒçš„ `gemini-2.5-flash-preview-04-17` å³å¯ã€‚

<Info>
Gemini 2.5 Flash é€šè¿‡ `budget`ï¼ˆæ€è€ƒé¢„ç®—ï¼‰æ¥æ§åˆ¶æ€è€ƒçš„æ·±åº¦ï¼ŒèŒƒå›´ 0-24Kï¼Œç›®å‰è½¬å‘é‡‡ç”¨çš„æ˜¯é»˜è®¤é¢„ç®—1024ï¼Œæœ€ä½³è¾¹é™…æ•ˆæœä¸º 16Kã€‚
åç»­æˆ‘ä»¬å°†é€šè¿‡ gemini åŸç”Ÿæ”¯æŒçš„æ–¹å¼ï¼Œè®©å¼€å‘è€…å¯ä»¥ç²¾å‡†æ§åˆ¶é¢„ç®—ã€‚
</Info>

## Gemini Function calling

ä½¿ç”¨ openai å…¼å®¹æ–¹å¼è°ƒç”¨ Gemini çš„ function calling åŠŸèƒ½æ—¶ï¼Œéœ€è¦åœ¨è¯·æ±‚ä½“å†…éƒ¨ä¼ å…¥`tool_choice="auto"`ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚

<CodeGroup>
```py Python
from openai import OpenAI
import os

# Define the function declaration for the model
schedule_meeting_function = {
    "name": "schedule_meeting",
    "description": "Schedules a meeting with specified attendees at a given time and date.",
    "parameters": {
        "type": "object",
        "properties": {
            "attendees": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of people attending the meeting.",
            },
            "date": {
                "type": "string",
                "description": "Date of the meeting (e.g., '2024-07-29')",
            },
            "time": {
                "type": "string",
                "description": "Time of the meeting (e.g., '15:00')",
            },
            "topic": {
                "type": "string",
                "description": "The subject or topic of the meeting.",
            },
        },
        "required": ["attendees", "date", "time", "topic"],
    },
}

# Configure the client
client = OpenAI(
    api_key=os.getenv("AIHUBMIX_API_KEY"),
    base_url="https://aihubmix.com/v1",
)

# Send request with function declarations using OpenAI compatible format
response = client.chat.completions.create(
    model="gemini-2.0-flash",
    messages=[
        {"role": "user", "content": "Schedule a meeting with Bob and Alice for 03/14/2025 at 10:00 AM about the Q3 planning."}
    ],
    tools=[{"type": "function", "function": schedule_meeting_function}],
    tool_choice="auto" ## ğŸ“ æ­¤å¤„è¿½åŠ äº† Aihubmix å…¼å®¹ï¼Œæ›´ç¨³å®šçš„è¯·æ±‚æ–¹å¼
)

# Check for a function call
if response.choices[0].message.tool_calls:
    tool_call = response.choices[0].message.tool_calls[0]
    function_call = tool_call.function
    print(f"Function to call: {function_call.name}")
    print(f"Arguments: {function_call.arguments}")
    print(response.usage)
    #  In a real app, you would call your function here:
    #  result = schedule_meeting(**json.loads(function_call.arguments))
else:
    print("No function call found in the response.")
    print(response.choices[0].message.content)
```
</CodeGroup>

**è¾“å‡ºç»“æœç¤ºä¾‹ï¼š**
```bash
Function to call: schedule_meeting
Arguments: {"attendees":["Bob","Alice"],"date":"2025-03-14","time":"10:00","topic":"Q3 planning"}
CompletionUsage(completion_tokens=28, prompt_tokens=111, total_tokens=139, completion_tokens_details=None, prompt_tokens_details=None)
```