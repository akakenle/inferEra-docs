---
title: "Gemini æŒ‡å—"
description: "åŒå­æ˜Ÿæ¼«æ¸¸æŒ‡å—ï¼šå…³äºæœ¬ç«™çš„ Gemini è°ƒç”¨ç»†èŠ‚ï¼Œåœ¨æ­¤æ±‡æ€»ã€‚"
icon: 'google'
---

## Gemini åŸç”Ÿè½¬å‘æ–¹å¼

å¯¹äº Gemini ç³»åˆ—ï¼Œæˆ‘ä»¬æä¾›åŸç”Ÿè°ƒç”¨å’Œ Openai å…¼å®¹è¿™ 2 ç§è°ƒç”¨æ–¹å¼ã€‚  
ä½¿ç”¨å‰è¿è¡Œ `pip install google-genai` æˆ– `pip install -U google-genai`ï¼Œå®‰è£…ï¼ˆæ›´æ–°ï¼‰åŸç”Ÿä¾èµ–ã€‚

1ï¸âƒ£ å¯¹äºåŸç”Ÿè°ƒç”¨ï¼Œä¸»è¦æ˜¯åœ¨å†…éƒ¨ä¼ å…¥ AiHubMix å¯†é’¥å’Œè¯·æ±‚é“¾æ¥ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªé“¾æ¥å’Œå¸¸è§„çš„ `base_url` å†™æ³•ä¸åŒï¼Œè¯·å‚è€ƒç¤ºä¾‹ï¼š 

```py
client = genai.Client(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    http_options={"base_url": "https://aihubmix.com/gemini"},
)
```

2ï¸âƒ£ å¯¹äº Openai å…¼å®¹æ ¼å¼ï¼Œåˆ™ç»´æŒé€šç”¨çš„ `v1` ç«¯ç‚¹ï¼š

```py
client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)
```

### Gemini 2.5 ç³»åˆ—çš„ã€Œæ¨ç†ã€è¯´æ˜
1. 2.5 ç³»åˆ—éƒ½æ˜¯æ¨ç†æ¨¡å‹ã€‚
2. 2.5 flash æ˜¯æ··åˆæ¨¡å‹ï¼Œç±»ä¼¼ claude sonnet 3.7ï¼Œå¯ä»¥é€šè¿‡ç”¨ `thinking_budget` æ§åˆ¶æ¨ç†é¢„ç®—æ¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚
3. 2.5 pro æ˜¯çº¯ç²¹çš„æ¨ç†æ¨¡å‹ï¼Œå› æ­¤ä¸èƒ½å…³é—­ thinkingã€ä¹Ÿä¸æ˜¾å¼ä¼ é€’æ¨ç†é¢„ç®—ã€‚

**Python è°ƒç”¨å‚è€ƒå¦‚ä¸‹ï¼š**
<CodeGroup>
```py æ™®é€šéæµå¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.0-flash"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""å¯¹äºæ™®é€šè‚¡ç¥¨æŠ•èµ„è€…ï¼šåˆ†æè´¢æŠ¥æœ‰ç”¨çš„è¯ï¼Œè¿˜è¦è¿æ°”åšä»€ä¹ˆï¼Ÿ"""),
            ],
        ),
    ]

    print(client.models.generate_content(
        model=model,
        contents=contents,
    ))

if __name__ == "__main__":
    generate()
```

```py 2.0 ç³»åˆ—-æµå¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.0-flash"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""å¯¹äºæ™®é€šè‚¡ç¥¨æŠ•èµ„è€…ï¼šåˆ†æè´¢æŠ¥æœ‰ç”¨çš„è¯ï¼Œè¿˜è¦è¿æ°”åšä»€ä¹ˆï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()

```

```py 2.5 Flash-æµå¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-flash-preview-04-17" #gemini-2.5-pro-preview-03-25ã€gemini-2.5-flash-preview-04-17
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""å¯¹äºæ™®é€šè‚¡ç¥¨æŠ•èµ„è€…ï¼šåˆ†æè´¢æŠ¥æœ‰ç”¨çš„è¯ï¼Œè¿˜è¦è¿æ°”åšä»€ä¹ˆï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        thinking_config = types.ThinkingConfig(
            thinking_budget=2048, #èŒƒå›´ 0-24576ã€‚é»˜è®¤ 1024ï¼Œæœ€ä½³è¾¹é™…æ•ˆæœ 16000
        ),
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```

```py 2.5 Pro-æµå¼
from google import genai
from google.genai import types
import os

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-03-25"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""æ€ä¹ˆçŸ¥é“æˆ‘ä¸æ˜¯åœ¨æµªè´¹æ—¶é—´"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()

```
</CodeGroup>

## Gemini 2.5 Flash æ”¯æŒ

Openai å…¼å®¹æ–¹å¼è°ƒç”¨å‚è€ƒå¦‚ä¸‹ï¼š

<CodeGroup>
```py Python ç”¨äºå¿«é€Ÿä»»åŠ¡æ—¶ï¼Œå…³é—­æ€è€ƒ
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17-nothink",
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ]
)

print(completion.choices[0].message.content)
```

```py Python æ§åˆ¶é¢„ç®—
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17",
    reasoning_effort="low", # å¯é€‰ "low", "medium" å’Œ "high", åˆ†åˆ«å¯¹åº” 1K, 8K å’Œ 24K thinking token budgets
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ]
)

print(completion.choices[0].message.content)
```

```shell Curl
curl -X POST https://aihubmix.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-***" \
  -d '{
    "model": "gemini-2.5-flash-preview-04-17-nothink",
    "messages": [
      {
        "role": "user",
        "content": "Explain the Occam'\''s Razor concept and provide an everyday example of it."
      }
    ]
  }'
```
</CodeGroup>

ç”¨äºå¤æ‚ä»»åŠ¡æ—¶ï¼Œåªéœ€è¦å°†æ¨¡å‹ id è®¾ç½®ä¸ºé»˜è®¤å¼€å¯æ€è€ƒçš„ `gemini-2.5-flash-preview-04-17` å³å¯ã€‚

<Info>
Gemini 2.5 Flash é€šè¿‡ `budget`ï¼ˆæ€è€ƒé¢„ç®—ï¼‰æ¥æ§åˆ¶æ€è€ƒçš„æ·±åº¦ï¼ŒèŒƒå›´ 0-24Kï¼Œç›®å‰è½¬å‘é‡‡ç”¨çš„æ˜¯é»˜è®¤é¢„ç®— 1024ï¼Œæœ€ä½³è¾¹é™…æ•ˆæœä¸º 16Kã€‚
</Info>

## Gemini Function calling

ä½¿ç”¨ openai å…¼å®¹æ–¹å¼è°ƒç”¨ Gemini çš„ function calling åŠŸèƒ½æ—¶ï¼Œéœ€è¦åœ¨è¯·æ±‚ä½“å†…éƒ¨ä¼ å…¥`tool_choice="auto"`ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚

<CodeGroup>
```py Python
from openai import OpenAI

# Define the function declaration for the model
schedule_meeting_function = {
    "name": "schedule_meeting",
    "description": "Schedules a meeting with specified attendees at a given time and date.",
    "parameters": {
        "type": "object",
        "properties": {
            "attendees": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of people attending the meeting.",
            },
            "date": {
                "type": "string",
                "description": "Date of the meeting (e.g., '2024-07-29')",
            },
            "time": {
                "type": "string",
                "description": "Time of the meeting (e.g., '15:00')",
            },
            "topic": {
                "type": "string",
                "description": "The subject or topic of the meeting.",
            },
        },
        "required": ["attendees", "date", "time", "topic"],
    },
}

# Configure the client
client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

# Send request with function declarations using OpenAI compatible format
response = client.chat.completions.create(
    model="gemini-2.0-flash",
    messages=[
        {"role": "user", "content": "Schedule a meeting with Bob and Alice for 03/14/2025 at 10:00 AM about the Q3 planning."}
    ],
    tools=[{"type": "function", "function": schedule_meeting_function}],
    tool_choice="auto" ## ğŸ“ æ­¤å¤„è¿½åŠ äº† Aihubmix å…¼å®¹ï¼Œæ›´ç¨³å®šçš„è¯·æ±‚æ–¹å¼
)

# Check for a function call
if response.choices[0].message.tool_calls:
    tool_call = response.choices[0].message.tool_calls[0]
    function_call = tool_call.function
    print(f"Function to call: {function_call.name}")
    print(f"Arguments: {function_call.arguments}")
    print(response.usage)
    #  In a real app, you would call your function here:
    #  result = schedule_meeting(**json.loads(function_call.arguments))
else:
    print("No function call found in the response.")
    print(response.choices[0].message.content)
```
</CodeGroup>

**è¾“å‡ºç»“æœç¤ºä¾‹ï¼š**
```bash
Function to call: schedule_meeting
Arguments: {"attendees":["Bob","Alice"],"date":"2025-03-14","time":"10:00","topic":"Q3 planning"}
CompletionUsage(completion_tokens=28, prompt_tokens=111, total_tokens=139, completion_tokens_details=None, prompt_tokens_details=None)
```