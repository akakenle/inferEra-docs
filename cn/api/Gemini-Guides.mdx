---
title: "Gemini æŒ‡å—"
description: "åŒå­æ˜Ÿæ¼«æ¸¸æŒ‡å—ï¼šå…³äºæœ¬ç«™çš„ Gemini è°ƒç”¨ç»†èŠ‚ï¼Œåœ¨æ­¤æ±‡æ€»ã€‚"
icon: "google"
---

## Gemini è°ƒç”¨æ–¹å¼

å¯¹äº Gemini ç³»åˆ—ï¼Œæˆ‘ä»¬æä¾›åŸç”Ÿè°ƒç”¨å’Œ Openai å…¼å®¹è¿™ 2 ç§è°ƒç”¨æ–¹å¼ã€‚\
ä½¿ç”¨å‰è¿è¡Œ `pip install google-genai` æˆ– `pip install -U google-genai`ï¼Œå®‰è£…ï¼ˆæ›´æ–°ï¼‰åŸç”Ÿä¾èµ–ã€‚

1ï¸âƒ£ å¯¹äºåŸç”Ÿè°ƒç”¨ï¼Œä¸»è¦æ˜¯åœ¨å†…éƒ¨ä¼ å…¥ AiHubMix å¯†é’¥å’Œè¯·æ±‚é“¾æ¥ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªé“¾æ¥å’Œå¸¸è§„çš„ `base_url` å†™æ³•ä¸åŒï¼Œè¯·å‚è€ƒç¤ºä¾‹ï¼š

```py
client = genai.Client(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    http_options={"base_url": "https://aihubmix.com/gemini"},
)
```

2ï¸âƒ£ å¯¹äº Openai å…¼å®¹æ ¼å¼ï¼Œåˆ™ç»´æŒé€šç”¨çš„ `v1` ç«¯ç‚¹ï¼š

```py
client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)
```

3ï¸âƒ£ å¯¹äº 2.5 ç³»åˆ—ï¼Œå¦‚æœä½ éœ€è¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ 2 ç§æ–¹å¼ï¼š

1. åŸç”Ÿè°ƒç”¨ï¼šä¼ å…¥ `include_thoughts=True`
2. OpenAI å…¼å®¹æ–¹å¼ï¼šä¼ å…¥ `reasoning_effort`

ç›¸å…³çš„è¯¦ç»†è°ƒç”¨å¯ä»¥å‚è€ƒä¸‹æ–‡çš„ä»£ç ç¤ºä¾‹ã€‚

### Gemini 2.5 ç³»åˆ—çš„ã€Œæ¨ç†ã€è¯´æ˜

1. 2.5 ç³»åˆ—éƒ½æ˜¯æ¨ç†æ¨¡å‹ã€‚
2. 2.5 flash æ˜¯æ··åˆæ¨¡å‹ï¼Œç±»ä¼¼ claude sonnet 3.7ï¼Œå¯ä»¥é€šè¿‡ç”¨ `thinking_budget` æ§åˆ¶æ¨ç†é¢„ç®—æ¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚
3. 2.5 pro æ˜¯çº¯ç²¹çš„æ¨ç†æ¨¡å‹ï¼Œå› æ­¤ä¸èƒ½å…³é—­ thinkingã€ä¹Ÿä¸æ˜¾å¼ä¼ é€’æ¨ç†é¢„ç®—ã€‚

**Python è°ƒç”¨å‚è€ƒå¦‚ä¸‹ï¼š**

<CodeGroup>

```py æ™®é€šéæµå¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.0-flash"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""å¯¹äºæ™®é€šè‚¡ç¥¨æŠ•èµ„è€…ï¼šåˆ†æè´¢æŠ¥æœ‰ç”¨çš„è¯ï¼Œè¿˜è¦è¿æ°”åšä»€ä¹ˆï¼Ÿ"""),
            ],
        ),
    ]

    print(client.models.generate_content(
        model=model,
        contents=contents,
    ))

if __name__ == "__main__":
    generate()
```


```py 2.0 ç³»åˆ—-æµå¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.0-flash"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""å¯¹äºæ™®é€šè‚¡ç¥¨æŠ•èµ„è€…ï¼šåˆ†æè´¢æŠ¥æœ‰ç”¨çš„è¯ï¼Œè¿˜è¦è¿æ°”åšä»€ä¹ˆï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```


```py 2.5 Flash-æµå¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-flash-preview-04-17" #gemini-2.5-pro-preview-03-25ã€gemini-2.5-flash-preview-04-17
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""å¯¹äºæ™®é€šè‚¡ç¥¨æŠ•èµ„è€…ï¼šåˆ†æè´¢æŠ¥æœ‰ç”¨çš„è¯ï¼Œè¿˜è¦è¿æ°”åšä»€ä¹ˆï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        thinking_config = types.ThinkingConfig(
            thinking_budget=2048, #èŒƒå›´ 0-16384ã€‚é»˜è®¤ 1024ï¼Œæœ€ä½³è¾¹é™…æ•ˆæœ 16000
        ),
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```


```py 2.5 Pro-æµå¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-03-25"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""æ€ä¹ˆçŸ¥é“æˆ‘ä¸æ˜¯åœ¨æµªè´¹æ—¶é—´"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```

```py æ˜¾ç¤ºæ¨ç†å†…å®¹
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-05-06"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""é‡‘èé¢†åŸŸçš„ã€Œ72 æ³•åˆ™ã€æ˜¯å¦‚ä½•æ¨å¯¼çš„ï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
        thinking_config=types.ThinkingConfig(
            include_thoughts=True  # ğŸ§  å¯ç”¨æ€è€ƒè¿‡ç¨‹è¾“å‡º
        ),
    )

    # ç”¨äºå­˜å‚¨æœ€åä¸€ä¸ª chunk çš„ usage_metadata
    final_usage_metadata = None
    
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹éƒ¨åˆ†
        if chunk.candidates and len(chunk.candidates) > 0:
            for part in chunk.candidates[0].content.parts:
                if part.text:
                    if part.thought:
                        # æ€è€ƒè¿‡ç¨‹å†…å®¹
                        print(part.text, end="")
                    else:
                        # æœ€ç»ˆç­”æ¡ˆå†…å®¹
                        print(part.text, end="")
        
        # ä¿å­˜æœ€æ–°çš„ usage_metadataï¼Œåªæœ‰æœ€åä¸€ä¸ª chunk ä¼šåŒ…å«å®Œæ•´ä¿¡æ¯
        if chunk.usage_metadata:
            final_usage_metadata = chunk.usage_metadata
    
    # åœ¨æ‰€æœ‰ chunk å¤„ç†å®Œåï¼Œæ‰“å°å®Œæ•´çš„ token ä½¿ç”¨æƒ…å†µ
    if final_usage_metadata:
        print(f"\n\nğŸ“Š Token ä½¿ç”¨æƒ…å†µ:")
        print(f"æ€è€ƒ tokens: {getattr(final_usage_metadata, 'thoughts_token_count', 'ä¸å¯ç”¨')}")
        print(f"è¾“å‡º tokens: {getattr(final_usage_metadata, 'candidates_token_count', 'ä¸å¯ç”¨')}")
        print(f"æ€»è®¡: {final_usage_metadata}")

if __name__ == "__main__":
    generate()
```

</CodeGroup>

## Gemini 2.5 Flash æ”¯æŒ

Openai å…¼å®¹æ–¹å¼è°ƒç”¨å‚è€ƒå¦‚ä¸‹ï¼š

<CodeGroup>

```py Python ç”¨äºå¿«é€Ÿä»»åŠ¡æ—¶ï¼Œå…³é—­æ€è€ƒ
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17-nothink",
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ]
)

print(completion.choices[0].message.content)
```


```py Python æ§åˆ¶é¢„ç®—
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17",
    reasoning_effort="low", # å¯é€‰ "low", "medium" å’Œ "high", åˆ†åˆ«å¯¹åº” 1024, 8192 å’Œ 16384 æ¨ç†é¢„ç®—
    messages=[
        {
            "role": "user",
            "content": "Explain the Occam's Razor concept and provide everyday examples of it"
        }
    ]
)

print(completion.choices[0].message.content)
```


```shell Curl-åŸºç¡€è°ƒç”¨
curl -X POST https://aihubmix.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-***" \
  -d '{
    "model": "gemini-2.5-flash-preview-04-17-nothink",
    "messages": [
      {
        "role": "user",
        "content": "Explain the Occam'\''s Razor concept and provide an everyday example of it."
      }
    ]
  }'
```


```shell Curl-Thinking æ˜¾ç¤º
curl https://aihubmix.com/v1/chat/completions \
-H "Content-Type: application/json" \
-H "Authorization: Bearer sk-***" \
-d '{
  "model": "gemini-2.5-pro-preview-05-06",
  "messages": [
    {
      "role": "user",
      "content": "Explain the Occam'\''s Razor concept and provide an everyday example of it."
    }
  ],
  "reasoning_effort": "low"
}'
```

</CodeGroup>

<Tip>
  1. ç”¨äºå¤æ‚ä»»åŠ¡æ—¶ï¼Œåªéœ€è¦å°†æ¨¡å‹ id è®¾ç½®ä¸ºé»˜è®¤å¼€å¯æ€è€ƒçš„ `gemini-2.5-flash-preview-04-17` å³å¯ã€‚
  2. Gemini 2.5 Flash é€šè¿‡ `budget`ï¼ˆæ€è€ƒé¢„ç®—ï¼‰æ¥æ§åˆ¶æ€è€ƒçš„æ·±åº¦ï¼ŒèŒƒå›´ 0-16Kï¼Œç›®å‰è½¬å‘é‡‡ç”¨çš„æ˜¯é»˜è®¤é¢„ç®— 1024ï¼Œæœ€ä½³è¾¹é™…æ•ˆæœä¸º 16Kã€‚
</Tip>

## å¤šåª’ä½“æ–‡ä»¶

Aihubmix ç›®å‰åªæ”¯æŒ**å°äº 20MB** çš„å¤šåª’ä½“æ–‡ä»¶ï¼ˆå›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ï¼‰ï¼Œç”¨ `inline_data` ä¸Šä¼ ã€‚\
å¤§äº 20M çš„å¤šåª’ä½“éœ€è¦ç”¨ File APIï¼ˆå°šæœªæ”¯æŒï¼‰ï¼Œå¾…å®Œå–„çŠ¶æ€è·Ÿè¸ªï¼Œè¿”å› `upload_url`ã€‚

<CodeGroup>

```py å›¾ç‰‡
from google import genai
from google.genai import types

# è¯»å–æ–‡ä»¶ä¸ºäºŒè¿›åˆ¶æ•°æ®
file_path = "yourpath/file.jpeg"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="image/jpeg"
                )
            ),
            types.Part(
                text="Describe the image."
            )
        ]
    )
)

print(response.text)
```


```py éŸ³é¢‘
from google import genai
from google.genai import types

# è¯»å–æ–‡ä»¶ä¸ºäºŒè¿›åˆ¶æ•°æ®
file_path = "yourpath/file.m4a"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="audio/m4a"
                )
            ),
            types.Part(
                text="Transcribe the audio to text."
            )
        ]
    )
)

print(response.text)
```


```py è§†é¢‘
from google import genai
from google.genai import types

# è¯»å–æ–‡ä»¶ä¸ºäºŒè¿›åˆ¶æ•°æ®
file_path = "yourpath/file.mp4"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="video/mp4"
                )
            ),
            types.Part(
                text="Summarize this video. Then create a quiz with an answer key based on the information in this video."
            )
        ]
    )
)

print(response.text)
```


```py Youtube é“¾æ¥
from google import genai
from google.genai import types

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                file_data=types.FileData(
                    file_uri="https://www.youtube.com/watch?v=OoU7PwNyYUw"
                )
            ),
            types.Part(
                text="Please summarize the video in 3 sentences."
            )
        ]
    )
)

print(response.text)
```

</CodeGroup>

## Code Execution

è‡ªåŠ¨ä»£ç è§£æå™¨ç”¨ä¾‹å‚è€ƒï¼š

```py Python
from google import genai
from google.genai import types

# è¯»å–æ–‡ä»¶ä¸ºäºŒè¿›åˆ¶æ•°æ®
file_path = "yourpath/file.csv"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # ğŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="text/csv"
                )
            ),
            types.Part(
                text="Please analyze this CSV and summarize the key statistics. Use code execution if needed."
            )
        ]
    ),
    config=types.GenerateContentConfig(
        tools=[types.Tool(
            code_execution=types.ToolCodeExecution
        )]
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    if getattr(part, "executable_code", None) is not None:
        print("Generated code:\n", part.executable_code.code)
    if getattr(part, "code_execution_result", None) is not None:
        print("Execution result:\n", part.code_execution_result.output)
```

## Function calling

ä½¿ç”¨ openai å…¼å®¹æ–¹å¼è°ƒç”¨ Gemini çš„ function calling åŠŸèƒ½æ—¶ï¼Œéœ€è¦åœ¨è¯·æ±‚ä½“å†…éƒ¨ä¼ å…¥`tool_choice="auto"`ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚

<CodeGroup>

```py Python
from openai import OpenAI

# Define the function declaration for the model
schedule_meeting_function = {
    "name": "schedule_meeting",
    "description": "Schedules a meeting with specified attendees at a given time and date.",
    "parameters": {
        "type": "object",
        "properties": {
            "attendees": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of people attending the meeting.",
            },
            "date": {
                "type": "string",
                "description": "Date of the meeting (e.g., '2024-07-29')",
            },
            "time": {
                "type": "string",
                "description": "Time of the meeting (e.g., '15:00')",
            },
            "topic": {
                "type": "string",
                "description": "The subject or topic of the meeting.",
            },
        },
        "required": ["attendees", "date", "time", "topic"],
    },
}

# Configure the client
client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

# Send request with function declarations using OpenAI compatible format
response = client.chat.completions.create(
    model="gemini-2.0-flash",
    messages=[
        {"role": "user", "content": "Schedule a meeting with Bob and Alice for 03/14/2025 at 10:00 AM about the Q3 planning."}
    ],
    tools=[{"type": "function", "function": schedule_meeting_function}],
    tool_choice="auto" ## ğŸ“ æ­¤å¤„è¿½åŠ äº† Aihubmix å…¼å®¹ï¼Œæ›´ç¨³å®šçš„è¯·æ±‚æ–¹å¼
)

# Check for a function call
if response.choices[0].message.tool_calls:
    tool_call = response.choices[0].message.tool_calls[0]
    function_call = tool_call.function
    print(f"Function to call: {function_call.name}")
    print(f"Arguments: {function_call.arguments}")
    print(response.usage)
    #  In a real app, you would call your function here:
    #  result = schedule_meeting(**json.loads(function_call.arguments))
else:
    print("No function call found in the response.")
    print(response.choices[0].message.content)
```

</CodeGroup>

**è¾“å‡ºç»“æœç¤ºä¾‹ï¼š**

```bash
Function to call: schedule_meeting
Arguments: {"attendees":["Bob","Alice"],"date":"2025-03-14","time":"10:00","topic":"Q3 planning"}
CompletionUsage(completion_tokens=28, prompt_tokens=111, total_tokens=139, completion_tokens_details=None, prompt_tokens_details=None)
```

## Tokens ç”¨é‡è¿½è¸ª

1. Gemini åŸç”Ÿé‡‡ç”¨ `usage_metadata` æ¥[è¿½è¸ªä½¿ç”¨çš„ token](https://ai.google.dev/gemini-api/docs/tokens?lang=python)ï¼Œå…¶ä¸­çš„å­—æ®µå¯¹åº”å¦‚ä¸‹ï¼š

- prompt_token_count: è¾“å…¥ token æ•°
- candidates_token_count: è¾“å‡º token æ•°
- thoughts_token_count: æ¨ç†ä½¿ç”¨çš„ token æ•°ï¼Œæ€§è´¨ä¸Šä¹Ÿæ˜¯è¾“å‡º token
- total_token_count: æ€» token ä½¿ç”¨é‡ï¼ˆè¾“å…¥\+è¾“å‡ºï¼‰

2. å¯¹äº OpenAI å…¼å®¹æ ¼å¼ï¼Œåˆ™é‡‡ç”¨ `.usage` æ¥è¿½è¸ªï¼Œå­—æ®µå¯¹åº”å¦‚ä¸‹ï¼š

- usage.completion_tokens: è¾“å…¥ token æ•°
- usage.prompt_tokens: è¾“å‡º token æ•°ï¼ˆåŒ…å«æ¨ç†ä½¿ç”¨çš„ token æ•°ï¼‰
- usage.total_tokens:æ€» token ä½¿ç”¨é‡

**ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹:**

<CodeGroup>

```py Gemini åŸç”Ÿ
from google import genai
from google.genai import types
import time

def generate():
    client = genai.Client(
        api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-03-25"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""é‡‘èé¢†åŸŸçš„ã€Œ72 æ³•åˆ™ã€æ˜¯å¦‚ä½•æ¨å¯¼çš„ï¼Ÿ"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    final_usage_metadata = None
    
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")
        if chunk.usage_metadata:
            final_usage_metadata = chunk.usage_metadata
    
    # åœ¨æ‰€æœ‰ chunk å¤„ç†å®Œåï¼Œæ‰“å°å®Œæ•´çš„ token ä½¿ç”¨æƒ…å†µ
    if final_usage_metadata:
        print(f"\nUsage: {final_usage_metadata}")

if __name__ == "__main__":
    generate()
```


```py OpenAI å…¼å®¹
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17",
    reasoning_effort="low", #"low", "medium", and "high", which behind the scenes we map to 1K, 8K, and 24K thinking token budgets. If you want to disable thinking, you can set the reasoning effort to "none".
    messages=[
        {
            "role": "user",
            "content": "é‡‘èé¢†åŸŸçš„ã€Œ72 æ³•åˆ™ã€æ˜¯å¦‚ä½•æ¨å¯¼çš„ï¼Ÿ"
        }
    ],
    stream=True
)

#print(completion.choices[0].message.content)

for chunk in completion:
    print(chunk.choices[0].delta)
    # åªåœ¨æœ€åä¸€ä¸ª chunkï¼ˆåŒ…å«å®Œæ•´ usage æ•°æ®ï¼‰æ—¶æ‰“å° usage ä¿¡æ¯
    if chunk.usage and chunk.usage.completion_tokens > 0:
        print(f"è¾“å‡º tokens: {chunk.usage.completion_tokens}")
        print(f"è¾“å…¥ tokens: {chunk.usage.prompt_tokens}")
        print(f"æ€» tokens: {chunk.usage.total_tokens}")
```

</CodeGroup>
