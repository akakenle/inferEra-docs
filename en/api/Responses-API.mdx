---
title: "Openai Responses API Support"
icon: "o"
---

Support the Openai Responses API multi-function interface, the following functions have been launched:

- Text input: Text input
- Image input: Image input
- Streaming: Streaming
- Web search: Web search
- Deep research: For complex analysis and research tasks
- Reasoning: Reasoning depth control, supports 4 levels (minimal / low / medium /high). Only the gpt-5 series supports `minimal`.
- Verbose: Output length, gpt-5 series supports 3 levels (low / medium /high)
- Functions: Functions
- image_generation tool usage: Image drawing and generation are billed under `gpt-image-1`.
- Code Interpreter: Allow models to write and run Python to solve problems
- Remote MCP: Calling a remote MCP server
- Computer Use: Computer Use

## Usage (Python call)：

Same as the official OpenAI call method, just replace `api_key` and `base_url` for forwarding.
Mainland China can access directly.

```py
client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Replace with the key you generated in AiHubMix
    base_url="https://aihubmix.com/v1"
)
```

<Tip>
  1. For inference models, the output inference summary can be controlled using the following parameter, with the detail richness of the summary ranked as detailed \> auto \> None, where auto provides the best balance.

  ```py
  "summary": "auto"
  ```

  2. Optional deep reasoning models: ‎⁠o3-deep-research⁠ and ‎⁠o4-mini-deep-research⁠, only supported on the ‎⁠responses⁠ endpoint.
  3. The gpt-5 series focuses on stable reasoning and consistent outputs, and no longer supports the `temperature` and `top_p` parameters for controlling randomness. If you need more freedom, you can try `gpt-5-chat-latest`, which supports `temperature`.
  4. Reasoning models (o series / gpt-5 series) no longer support ‎`max_tokens`. Please use ‎`max_completion_tokens` to clearly define the output token limit.
</Tip>

<CodeGroup>

```py gpt-5 series
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # Replace with the key generated in your AIHubMix dashboard
    base_url="https://aihubmix.com/v1"
)

response = client.responses.create(
    model="gpt-5", # gpt-5, gpt-5-chat-latest, gpt-5-mini, gpt-5-nano
    input="Why is tarot divination effective? What are the underlying principles and transferable methods? Output format: Markdown", # GPT-5 does not output in Markdown format by default, so you need to explicitly specify it.
    reasoning={
        "effort": "minimal" # Reasoning depth – Controls how many reasoning tokens the model generates before producing a response. Value can be "minimal", "low", "medium" or "high". Default is "medium".
    },
    text={
        "verbosity": "low" # Output length – Verbosity determines how many output tokens are generated. Value can be "low", "medium", or "high". Models before GPT-5 defaulted to "medium" verbosity.
    },
    stream=True
)

for event in response:
  print(event)
```

```py Text input
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1"
)

response = client.responses.create(
  model="gpt-4o-mini", # codex-mini-latest AVAILABLE
  input="Tell me a three sentence bedtime story about a unicorn."
)

print(response)
```


```py Image input
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1"
)

response = client.responses.create(
    model="gpt-4o-mini", # codex-mini-latest AVAILABLE
    input=[
        {
            "role": "user",
            "content": [
                { "type": "input_text", "text": "what is in this image?" },
                {
                    "type": "input_image",
                    "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                }
            ]
        }
    ]
)

print(response)
```


```py Streaming
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1"
)

response = client.responses.create(
  model="gpt-4o-mini", # codex-mini-latest AVAILABLE
  instructions="You are a helpful assistant.",
  input="Hello!",
  stream=True
)

for event in response:
  print(event)
```


```py Web search
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1"
)

response = client.responses.create(
  model="gpt-4o-mini",
  tools=[{ "type": "web_search_preview" }],
  input="What was a positive news story from today?",
)

print(response)
```


```py Deep Research
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1",
    timeout=3600
)

input_text = """
Research the economic impact of semaglutide on global healthcare systems.
Do:
- Include specific figures, trends, statistics, and measurable outcomes.
- Prioritize reliable, up-to-date sources: peer-reviewed research, health
  organizations (e.g., WHO, CDC), regulatory agencies, or pharmaceutical
  earnings reports.
- Include inline citations and return all source metadata.

Be analytical, avoid generalities, and ensure that each section supports
data-backed reasoning that could inform healthcare policy or financial modeling.
"""

response = client.responses.create(
  model="o3-deep-research", # o4-mini-deep-research
  input=input_text,
  tools=[
    {"type": "web_search_preview"},
    {"type": "code_interpreter", "container": {"type": "auto"}},
  ],
)

print(response.output_text)
```


```py Reasoning
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1/"
)

response = client.responses.create(
    model="o4-mini", # codex-mini-latest, o4-mini, o3-mini, o3, o1
    input="How much wood would a woodchuck chuck?",
    reasoning={
        "effort": "medium", # low, medium, high
        "summary": "auto", # resoning summary
    }
)

print(response)
```


```py Functions
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1"
)

tools = [
    {
        "type": "function",
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
              "location": {
                  "type": "string",
                  "description": "The city and state, e.g. San Francisco, CA",
              },
              "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
          },
          "required": ["location", "unit"],
        }
    }
]

response = client.responses.create(
  model="gpt-4o-mini", # codex-mini-latest AVAILABLE
  tools=tools,
  input="What is the weather like in Boston today?",
  tool_choice="auto"
)

print(response)
```


```py Image Generation Tool
from openai import OpenAI
import base64

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1"
)

response = client.responses.create(
    model="gpt-4.1-mini",
    input="Generate an image of gray tabby cat hugging an otter with an orange scarf",
    tools=[
        {
            "type": "image_generation",
            "background": "opaque", 
            "quality": "high",
        }
    ],
)

# Save the image to a file
image_data = [
    output.result
    for output in response.output
    if output.type == "image_generation_call"
]

if image_data:
    image_base64 = image_data[0]
    with open("cat_and_otter.png", "wb") as f:
        f.write(base64.b64decode(image_base64))
```


```py Code Interpreter
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1"
)

instructions = """
You are a personal math tutor. When asked a math question, 
write and run code using the python tool to answer the question.
"""

resp = client.responses.create(
    model="gpt-4.1",
    tools=[
        {
            "type": "code_interpreter",
            "container": {"type": "auto"}
        }
    ],
    instructions=instructions,
    input="I need to solve the equation 3x + 11 = 14. Can you help me?",
)

print(resp.output)
```


```py Remote MCP
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Your Key "sk-***"
    base_url="https://aihubmix.com/v1"
)

resp = client.responses.create(
    model="gpt-4.1",
    tools=[{
        "type": "mcp",
        "server_label": "deepwiki",
        "server_url": "https://mcp.deepwiki.com/mcp",
        "require_approval": "never",
        "allowed_tools": ["ask_question"],
    }],
    input="What transport protocols does the 2025-03-26 version of the MCP spec (modelcontextprotocol/modelcontextprotocol) support?",
)

print(resp.output_text)
```

</CodeGroup>

**Note:**

1. The latest `codex-mini-latest` does **not** support search.
2. The **Computer use** feature requires integration with **Playwright**. It’s recommended to refer to the [official repository](https://github.com/openai/openai-cua-sample-app).

Known issues:

- Use cases are complex to invoke
- Takes many screenshots, which is time-consuming and often unreliable
- May trigger CAPTCHA or Cloudflare human verification, potentially leading to infinite loops