---
title: "Model Suffix Capability Overview"
icon: "badge-percent"
description: "By using the model suffix, some advanced capabilities of the models are pre-configured, and users can use them directly through the unified OpenAI/Chat interface."
---

## Claude Thinking Model

The Claude model does not enable thinking mode by default. To utilize its deep reasoning capabilities, it typically requires calling through the native Claude interface. To facilitate users in accessing this capability directly under the OpenAI compatible interface, we now offer the claude `-think` model, which has thinking mode pre-activated.

### Supported Models

- [claude-sonnet-4-5-think](https://aihubmix.com/model/claude-sonnet-4-5-think)
- [claude-opus-4-5-think](https://aihubmix.com/model/claude-opus-4-5-think)

### Notes

1. The thinking capability is explicitly selected through the model name.
2. The Claude thinking model uses the platform's default context and token configuration.
   - Sonnet series default `max_tokens = 32k`
   - Opus series default `max_tokens = 64k`
3. No additional parameters are needed; the calling method is the same as for regular models.

---

## GPT Thinking Model

The reasoning intensity of GPT-5.2 can only be configured through the `/responses` interface. To maintain compatibility with the unified OpenAI `/Chat` interface, the platform provides the `GPT-5.2-*` series of pre-configured models that fix different levels of reasoning intensity at the model layer, allowing users to call them directly.

### Supported Models

- [gpt-5.2-high](https://aihubmix.com/model/gpt-5.2-high)

### Notes

1. `-high` indicates high-intensity reasoning, suitable for complex problems and high accuracy requirements.
2. The reasoning intensity is determined by the model name, with no additional fields required.

---

## Google Search Enhanced Model

The Gemini model does not enable Google Search by default. To activate it, the native Gemini interface must be used. To facilitate users in accessing this capability directly under the OpenAI compatible interface, some Gemini models have integrated Google official search capability. By selecting the corresponding model name, search will be automatically enabled during generation, with no additional parameters needed.

### Supported Models

- [gemini-3-pro-preview-search](https://aihubmix.com/model/gemini-3-pro-preview-search)
- [gemini-3-flash-preview-search](https://aihubmix.com/model/gemini-3-flash-preview-search)

### Notes

1. Models with the `-search` suffix have integrated Google official search capability, suitable for scenarios requiring real-time information, external fact-checking, and the latest data reference.
2. The search capability incurs additional costs, which will be logged separately in the total expenses.
   - The current version does not display detailed logs of search costs; this will be added in future updates.
3. Only **OpenAI compatible format** calls are supported.
   - Native Gemini SDK is not supported.
   - If using the Gemini official SDK, please refer to the corresponding version's non-thinking model interface call examples.