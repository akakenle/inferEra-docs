---
title: "Fill In the Middle"
icon: "message-code"
---

### 1. Usage

In the FIM (Fill In the Middle) completion task, users input the prefix and suffix content they want to keep, and the model generates the missing part based on these prompts. This completion method is common in applications such as code auto-completion and text middle generation.

### 2. Data Format

In the chat/completions interface, simply set the `model id` to the model id on the [Model Gallery](https://aihubmix.com/models), which is available in the top right corner of the module card.

```json
{ 
    "model": "model id",
    "messages": "prompt",
    "params": "params",
    "extra_body": {"prefix":"prefix content", "suffix":"optional suffix content"}
}
```

In the completions interface

```json
{
    "model": "model info",
    "prompt": "prompt",
    "suffix": "prompt"
}
```

### 3. Example

#### 3.1 Using FIM Completion Based on OpenAI's chat.completions Interface:

<CodeGroup>

```py Python
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # Replace with the key you generated in AiHubMix
    base_url="https://aihubmix.com/v1"
)

messages = [
    {"role": "user", "content": "Please write a sum function code"},
]

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,
    extra_body={
            "prefix": f"""
def sum_numbers(numbers):
    # If the list is empty, return 0
    if not numbers:
        return 0
""",
            "suffix": f"""
# Run Test
numbers = [1, 2, 3, 4, 5]
result = sum_numbers(numbers)
print("Sum of numbers:", result)
"""
    },
    stream=True,
    max_tokens=4096
)

for chunk in response:
    if chunk.choices and len(chunk.choices) > 0 and chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end='')
```

</CodeGroup>


#### 3.2 Completion Using FIM Based on OpenAI's Completions API:
<CodeGroup>

```py Python

client = OpenAI(
    api_key="Aihubmix APIKEY", 
    base_url="https://aihubmix.com/v1"
)

response = client.completions.create(
    model="deepseek-ai/DeepSeek-V2.5",
    prompt=f"""
def quick_sort(arr):
   # Basic situation: if the array length is less than or equal to 1, return the array
    if len(arr) <= 1:
        return arr
    else:
""",
    suffix=f"""
# Test quick_sort function
arr = [3, 6, 8, 10, 1, 2, 1]
sorted_arr = quick_sort(arr)
print("Sorted array:", sorted_arr)
""",
    stream=True,
    max_tokens=4096
)

for chunk in response:
    print(chunk.choices[0].text, end='')
```

</CodeGroup>


