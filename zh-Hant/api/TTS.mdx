---
title: "TTS æ–‡å­—è½‰èªéŸ³"
description: "ä½¿ç”¨ AI æ¨¡å‹å°‡æ–‡å­—è½‰æ›ç‚ºè‡ªç„¶èªéŸ³ï¼Œæ”¯æ´å¤šç¨®èªéŸ³é¢¨æ ¼å’Œè¼¸å‡ºæ ¼å¼"
icon: "monitor-waveform"
---

## ä»‹ç´¹

æ–‡å­—è½‰èªéŸ³ï¼ˆTTSï¼‰API åŸºæ–¼å…ˆé€²çš„ç”Ÿæˆ AI æ¨¡å‹ï¼Œå¯ä»¥å°‡è¼¸å…¥çš„æ–‡å­—è½‰æ›ç‚ºé€¼çœŸçš„èªéŸ³éŸ³é »ã€‚æ”¯æ´å¤šç¨®ç”¨é€”ï¼š

- ç‚ºæ›¸é¢éƒ¨è½æ ¼æ–‡ç« é…éŸ³
- ç”Ÿæˆå¤šç¨®èªè¨€çš„èªéŸ³éŸ³é »
- æä¾›å³æ™‚éŸ³é »è¼¸å‡ºä¸²æµ

**å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼š**

- **gpt-4o-audio-preview** â€”â€” OpenAI æœ€æ–°çš„éŸ³é »ç”Ÿæˆæ¨¡å‹ï¼Œæ”¯æ´å°è©±å¼éŸ³é »ç”Ÿæˆ
- **gpt-4o-mini-tts** â€”â€” æ™ºæ…§å³æ™‚æ‡‰ç”¨çš„é¦–é¸æ¨¡å‹ï¼Œæ”¯æ´é€²éšèªéŸ³æ§åˆ¶ï¼Œå¯ä»¥é€éæç¤ºè©æ§åˆ¶å¤šç¨®èªéŸ³ç‰¹æ€§ï¼š
  - å£éŸ³ (Accent)
  - æƒ…æ„Ÿç¯„åœ (Emotional range)
  - èªèª¿ (Intonation)
  - å°è±¡/é¢¨æ ¼ (Impressions)
  - èªé€Ÿ (Speed of speech)
  - èªèª¿ (Tone)
  - è¼•è²èªªè©± (Whispering)
- **tts-1-hd** â€”â€” é«˜æ¸…éŸ³è³ªçš„ä¸Šä¸€ä»£ TTS æ¨¡å‹
- **tts-1** â€”â€” æ¨™æº– TTS æ¨¡å‹ï¼Œå¹³è¡¡å“è³ªå’Œé€Ÿåº¦

<Tip>
  **æ•ˆèƒ½å»ºè­°ï¼š** ç‚ºç²å¾—æœ€å¿«çš„éŸ¿æ‡‰æ™‚é–“ï¼Œå»ºè­°ä½¿ç”¨ `wav` æˆ– `pcm` ä½œç‚ºéŸ¿æ‡‰æ ¼å¼ã€‚å°æ–¼é«˜å“è³ªéŸ³é »ï¼Œå»ºè­°ä½¿ç”¨ `tts-1-hd`ï¼›å°æ–¼æ›´å¿«çš„ç”Ÿæˆé€Ÿåº¦ï¼Œä½¿ç”¨ `tts-1`ï¼›å°æ–¼æ™ºæ…§èªéŸ³æ‡‰ç”¨ï¼Œæ¨è–¦ä½¿ç”¨ `gpt-4o-mini-tts`ã€‚

  **éŸ³è‰²é è¦½ï¼š** ä½ å¯ä»¥åœ¨ [OpenAI.fm](https://www.openai.fm/) è©¦è½ä¸åŒéŸ³è‰²æ•ˆæœã€‚
</Tip>

## æ¨¡å‹èª¿ç”¨æ–¹å¼

### æ¨™æº– TTS æ¨¡å‹ï¼ˆtts-1, tts-1-hdï¼‰

ä½¿ç”¨ `/v1/audio/speech` ç«¯é»ï¼Œé€é `client.audio.speech.create()` æ–¹æ³•èª¿ç”¨ã€‚

### gpt-4o-mini-tts æ¨¡å‹

ä½¿ç”¨ `/v1/audio/speech` ç«¯é»ï¼Œæ”¯æ´ `instructions` åƒæ•¸é€²è¡Œé€²éšèªéŸ³æ§åˆ¶ã€‚

### gpt-4o-audio-preview æ¨¡å‹

ä½¿ç”¨ `/v1/chat/completions` ç«¯é»ï¼Œéœ€è¦è¨­å®š `modalities: ["text", "audio"]` å’Œ `audio` é…ç½®ã€‚

### è«‹æ±‚åƒæ•¸

#### æ¨™æº– TTS åƒæ•¸ï¼ˆé©ç”¨æ–¼ tts-1, tts-1-hd, gpt-4o-mini-ttsï¼‰

<ParamField body="model" type="string" required>
  è¦ä½¿ç”¨çš„æ¨¡å‹ IDã€‚å¯é¸å€¼ï¼š`tts-1`ã€`tts-1-hd`ã€`gpt-4o-mini-tts`
</ParamField>

<ParamField body="input" type="string" required>
  è¦ç”ŸæˆéŸ³é »çš„æ–‡å­—ï¼Œæœ€å¤§é•·åº¦ç‚º 4096 å€‹å­—å…ƒ
</ParamField>

<ParamField body="voice" type="string" required>
  ç”¨æ–¼åˆæˆçš„èªéŸ³ã€‚å¯é¸å€¼ï¼š`alloy`ã€`echo`ã€`fable`ã€`onyx`ã€`nova`ã€`shimmer`
</ParamField>

<ParamField body="response_format" type="string">
  éŸ³é »è¼¸å‡ºæ ¼å¼ã€‚æ”¯æ´æ ¼å¼ï¼š`mp3`ã€`opus`ã€`aac`ã€`flac`ã€`wav`ã€`pcm`ã€‚é è¨­ç‚º `mp3`
</ParamField>

<ParamField body="speed" type="number">
  ç”ŸæˆéŸ³é »çš„èªé€Ÿã€‚å–å€¼ç¯„åœ 0.25 åˆ° 4.0ã€‚é è¨­ç‚º 1.0ã€‚**`æ³¨æ„ï¼šgpt-4o-mini-tts ä¸æ”¯æ´æ­¤åƒæ•¸ï¼Œä½†ä½ å¯ä»¥é€éè‡ªç„¶èªè¨€æè¿°ä¾†æ§åˆ¶èªé€Ÿ`**
</ParamField>

<ParamField body="instructions" type="string">
  èªéŸ³ç”ŸæˆæŒ‡ä»¤ï¼ˆåƒ…é©ç”¨æ–¼ `gpt-4o-mini-tts` æ¨¡å‹ï¼‰ï¼Œå¯ä»¥è©³ç´°æŒ‡å®šèªéŸ³é¢¨æ ¼ã€èªèª¿ã€æƒ…æ„Ÿç­‰ç‰¹æ€§
</ParamField>

#### gpt-4o-audio-preview åƒæ•¸

<ParamField body="model" type="string" required>
  è¨­å®šç‚º `gpt-4o-audio-preview`
</ParamField>

<ParamField body="modalities" type="array" required>
  è¨­å®šç‚º `["text", "audio"]` å•Ÿç”¨éŸ³é »è¼¸å‡º
</ParamField>

<ParamField body="audio" type="object" required>
  éŸ³é »é…ç½®ç‰©ä»¶ï¼ŒåŒ…å« `voice` å’Œ `format` æ¬„ä½
</ParamField>

<ParamField body="messages" type="array" required>
  èŠå¤©è¨Šæ¯é™£åˆ—ï¼Œèˆ‡æ¨™æº–èŠå¤©æ ¼å¼ç›¸åŒ
</ParamField>

## ä½¿ç”¨æ–¹æ³•

<CodeGroup>

```shell Curl
curl https://aihubmix.com/v1/audio/speech \
  -H "Authorization: Bearer $AIHUBMIX_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "The quick brown ğŸ¦Š jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```


```py gpt-4o-audio-preview
import base64
from openai import OpenAI
import os

client = OpenAI(
  api_key=os.getenv("AIHUBMIX_API_KEY"),
  base_url="https://aihubmix.com/v1"
)

completion = client.chat.completions.create(
    model="gpt-4o-audio-preview",
    modalities=["text", "audio"],
    audio={"voice": "alloy", "format": "wav"},
    messages=[
        {
            "role": "user",
            "content": "The quick brown ğŸ¦Š jumped over the lazy dog."
        }
    ]
)

print(completion.choices[0])

wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)
with open("output.wav", "wb") as f:
    f.write(wav_bytes)
```


```py gpt-4o-mini-tts
from pathlib import Path
from openai import OpenAI
import os

# aihubmix è½‰ç™¼
client = OpenAI(
  api_key="sk-***", # æ›¿æ›ç‚ºä½ çš„ AiHubMix API å¯†é‘°
  base_url="https://aihubmix.com/v1"
)

speech_file_path = Path(__file__).parent / "speech.mp3"
with client.audio.speech.with_streaming_response.create(
  model="gpt-4o-mini-tts",
  voice="alloy", # æœ€ä½³å¹³è¡¡éŸ³è‰²ï¼Œç™¼éŸ³æ¸…æ™°
  instructions="""Play as a Patient Teacher""",
  input="The quick brown ğŸ¦Š jumped over the lazy dog."
) as response:
  response.stream_to_file(speech_file_path)
```


```py æ¨™æº– TTS æ¨¡å‹
from pathlib import Path
from openai import OpenAI
import os

client = OpenAI(
  api_key="sk-***", # æ›¿æ›ç‚ºä½ çš„ AiHubMix API å¯†é‘°
  base_url="https://aihubmix.com/v1"
)

speech_file_path = Path(__file__).parent / "speech.mp3"
response = client.audio.speech.create(
  model="tts-1-hd",
  voice="alloy",
  input="The quick brown ğŸ¦Š jumped over the lazy dog.",
  response_format="mp3",
  speed=1.0
)

response.stream_to_file(speech_file_path)
```

</CodeGroup>