---
title: "更新日志"
description: ""
mode: "center"
---

## 3月24日：
启用全新的三叉戟 Logo

## 3月16日：
新增了对OpenAi和Google Gemini模型的原生搜索功能的支持；未来将完善这个接口扩展支持第三方搜；

## 3月15日：
新增模型：gpt-4o-mini-search-preview和gpt-4o-search-preview

## 3月07日
o1 和 o3-mini 价格下降 10%，跟官网一致；

## 3月06日
aihubmix-DeepSeek-R1 由于微软价格上涨 7 倍因此该模型价格上涨 7 倍，推荐使用火山的 DeepSeek-R1，稳定又便宜；新增 qwen-qwq-32b 和 qwen2.5-vl-72b-instruct

## 2月28日
Claude 模型全面降价 15%；新增模型 gpt-4.5-preview；注意价格极其昂贵，调用请注意；

## 2月26日
提升 Deepseek 稳定性；来自字节的最稳定，推荐用这两个: DeepSeek-R1 和 DeepSeek-V3；

## 2月25日
增模型claude-3-7-sonnet-20250219

## 2月24日
- gpt-4o 概率性出现返回很慢的情况，次为厂商问题；建议暂时改用 gpt-4o-2024-11-20
- Perplexity api 暂时下线，Perplexity 官方的计费模式较为复杂，成本高于本平台的定价结构，我们调整价格后重新上线；
- 字节官方限时折扣结束恢复原价，DeepSeek-R1 价格已上调
- 新增模型详情页及参数信息

## 2月23日
- 字节官方限时折扣结束恢复原价，DeepSeek-V3价格已上调；预计字节的 R1 近期也会恢复原价，所以我们也会同步涨价

## 2月18日
- 新增模型：kimi-latest（官方计费根据输入内容长度 8k,32k,128k 分 3 档计费，本站不支持该计费结构，取中 32k 档为计费标准，价格敏感介意勿用）
- 优化了网站页面结构；
- 日志页面并入用量统计页；
- 公告内容移到模型广场页，
- 设置移到头像下面；

- aihubmix-DeepSeek-R1 价格下降 50% 
- 新增模型：gemini-2.0-pro-exp-02-05-search，gemini-2.0-flash-exp-search，集成了谷歌官方搜索联网功能 
- 新增模型：gemini-2.0-flash、gemini-2.0-pro-exp-02-05、gemini-2.0-flash-lite-preview-02-05 新增模型：o3-mini，o1（注这两个模型后台扣费比官方贵 10% 左右，因为这两个模型帐号帐号有限） 

## 2月4日
- o1 模型 openai 官方不支持传入参数 stream
- o3-mini 不支持传入参数 temperature，o3-mini 新增参数 Reasoning effort；可以传入"low, medium, high" 如果不传默认为 medium

## 2月1日
功能：新增 openai 声音模型输入输出的功能支持，api.aihubmix.com 服务器可用，主站服务器稳定 1 周后更新支持。总体后台扣费和官方一致，暂时日志只展示文字部分token声音费用暂时无法展示，但不影响使用

新增模型：
- o3-mini，o1；（注这两个模型后台扣费比官方贵 10% 左右，因为这两个模型帐号帐号有限）
- aihubmix-DeepSeek-R1（推荐，比较稳定）
- qwen-max-0125（即Qwen2.5-Max）、sonar-reasoning
- deepseek-ai/DeepSeek-R1-Zero和deepseek-ai/DeepSeek-R1，deepseek-r1-distill-llama-70b
- aihub-Phi-4
- Doubao-1.5-pro-256k、Doubao-1.5-pro-32k、Doubao-1.5-lite-32k、Doubao-1.5-vision-pro-32k
- sonar、sonar-pro（perplexity ai最新发布）
- gemini-2.0-flash-thinking-exp-01-21
- deepseek-reasoner（即DeepSeek-R1）
- MiniMax-Text-01 
- codestral-latest （Mistral 推出了新的code模型 - Codestral 25.01）

## 1月23日
新增模型：
- aihub-Phi-4
- Doubao-1.5-pro-256k、Doubao-1.5-pro-32k、Doubao-1.5-lite-32k、Doubao-1.5-vision-pro-32k
- sonar、sonar-pro（perplexity ai最新发布）
- gemini-2.0-flash-thinking-exp-01-21
- deepseek-reasoner（即DeepSeek-R1）

## 1月19日
- 新增Perplexity Ai API模型；仅支持api.aihubmix.com 预览版服务器调用，如果没问题我们会更新到主服务器aihubmi.com；
api.aihubmix.com 为预览版服务器，后续新功能先更新到这个服务器，通常稳定1周我们再更新到主服务器aihubmix.com

新增模型：
- MiniMax-Text-01 
- codestral-latest （Mistral 推出了新的code模型 - Codestral 25.01）
- gpt-4o-zh，输入任何语言自动翻译为英文给模型，模型输出内容自动翻译为中文返回；该功能测试阶段不支持高并发请求，仅支持 gpt-4o 模型；

## 1月6日
- 新增 gemini-2.0-flash-exp-search，支持谷歌原生联网搜索功能；官方 gemini 2.0 flash 模型的联网需要额外传入参数才支持联网功能，aihubmix 做了集成，模型名字加上 search 参数即可使用
- 新增模型 deepseek-ai/DeepSeek-V3

## 1月1日
- 新增模型广场页面代替原来的模型/价格页面

## 12月30日
- 修复 gemini-2.0-flash-thinking-exp-1219 模型只输出思考没有答案问题
- 修复余额提醒邮件收不到问题

## 12月22日
- 新增用量统计页面，新增充值记录页面
- 新增豆包系列模型：Doubao-lite-128k、Doubao-lite-32k、Doubao-lite-4k、Doubao-pro-128k、Doubao-pro-256k、Doubao-pro-32k、Doubao-pro-4k
- 新增模型：gemini-2.0-flash-thinking-exp-1219
- 新增模型：gemini-2.0-flash-exp、aihubmix-Mistral-Large-2411、aihubmix-Llama-3-3-70B-Instruct、grok-2-1212、grok-2-vision-1212
- 新增模型：gemini-exp-1206、llama-3.3-70b-versatile、learnlm-1.5-pro-experimental

## 12月14日
- 新增模型：gemini-2.0-flash-exp、aihubmix-Mistral-Large-2411、aihubmix-Llama-3-3-70B-Instruct

## 12月8日
- 新增模型：gemini-exp-1206、llama-3.3-70b-versatile、learnlm-1.5-pro-experimental
- 新增用量统计页面

## 11月21日
- 近期新增模型：gpt-4o-2024-11-20，step-2-16k，grok-vision-beta，
- 千问 2.5turbo 百万上下文模型：qwen-turbo-2024-11-01

## 11月07日
- 兼容 Claude 原生 sdk，v1/messages 接口已支持上线；
- Claude 原生接口的缓存和控制计算机功能还不支持（prompt caching和computer use）我们会在接下来的两周内继续完善。

## 11月05日
- 新增模型：claude-3-5-haiku-20241022	
- 新增马斯克 x.ai 最新模型 grok-beta

## 10月23日
- 新增模型：claude-3-5-sonnet-20241022

## 10月10日
OpenAI 最新的缓存功能现已上线。此功能目前支持以下模型：

- GPT-4o
- GPT-4o-mini
- o1-preview
- o1-mini

请注意，gpt-4o-2024-05-13 版本不在官方支持范围内。
如果请求命中缓存，您将能够在后台日志中看到相关的缓存 token 数据。
更多详细信息和使用规则，请访问 OpenAI 官方网站：[OpenAI缓存功能详情](https://openai.com/index/api-prompt-caching/)

## 10月03日
- gpt-4o 模型后台计费下降价格同步官方
- 新增模型：aihubmix-Llama-3-2-90B-Vision，aihubmix-Llama-3-70B-Instruct
- 新增 Cohere 最新模型 aihubmix-command-r-08-2024，aihubmix-command-r-plus-08-2024	

## 9月19日
- 新增模型：whisper-large-v3 和 distil-whisper-large-v3-en
- 注意：Whisper 模型实际计费是按照输入的秒数计费的，但是目前页面价格展示有问题未来会修复，后台底层计费没有问题 whisper-1 完全同步 Openai 官方扣费

## 9月13日
- **新增模型o1-mini和o1-preview；**  
注：最新这两个模型，要求传入参数有变，一些壳软件如果不更新默认传入的参数会报错;  
#### 需要注意 
经测试，o1 模型不支持以下内容，并报错：
- system 字段：400 报错
- tools 字段：400 报错
- 图片输入：400 报错
- json_object 输出：500 报错
- structured 输出：400 报错
- logprobs 输出：403 报错
- stream 输出：400报错
- o1系列：20 RPM，150,000,000 TPM，很低，随时429报错
- 其他：temperature, top_p and n 被固定为1；presence_penalty 和 frequency_penalty 被固定为 0

## 9月10日
- 新增模型：mattshumer/Reflection-Llama-3.1-70B；ps：据说 llama3.1-70b 最强微调版本
- claude-3 模型价格上调调整，为了维持 Claude 模型稳定供应，目前调用我们会比直接调用官方贵 10%，后续会逐步下调；
- 增加了 Openai 系列模型的并发能力，理论上基本支持无限并发；

## 8月11日
- 新增模型：Phi3medium128k、ahm-Phi-3-medium-4k、ahm-Phi-3-small-128k
- 增加了 Llama 相关模型的稳定性
- 进一步优化了 Claude 模型的兼容性

## 8月7日
- 新增 Openai 刚刚更新 4o 版本 gpt-4o-2024-08-06，见https://platform.openai.com/docs/guides/structured-outputs
- 新增 Google 最新模型：gemini-1.5-pro-exp-0801

## 8月4日
- 增加了在线直接支付充值
- 修复了 Claude 多轮对话格式报错问题：1、messages: roles must alternate between \"user\" and \"assistant\", but found multiple \"user\" roles in a row；
- 优化了 Claude 模型的使用 function 功能时 index 问题
- https://orisound.cn 备用服务器将在 9 月 7 日全面下线；目前在使用这个地址的请抽空改成主服务器 https://aihubmix.com 或者备用服务器 https://api.aihubmix.com

## 7月27日
- 新增支持 Mistral Large 2，模型名称：Mistral-large-2407 或者 aihubmix-Mistral-large-2407；
- 系统优化

## 7月24日
- 新增最新 llama-3.1 模型 llama-3.1-405b-instruct,llama-3.1-70b-versatile 和 llama-3.1-8b-instant，欢迎尝试；

## 7月20日  
- 已修复 gpt-4o-mini 模型在价格计算方面的问题。具体情况如下：  
文本输入价格：OpenAI 官方的gpt-4o-mini 模型输入文本的价格仅为 gpt-4o 模型价格的 1/33。  
图片输入价格：OpenAI 官方的gpt-4o-mini 模型输入图片的价格与 gpt-4o 模型价格相等。  
- 为了确保价格计算的准确性，我们在计算 gpt-4o-mini 模型输入图片的 token 数时，将其乘以 33 倍，以与官方价格对齐。  
- 详情可见 [Open AI官方价格](https://openai.com/api/pricing/)
![图片](../media/4ominijiage.png)  
![图片](../media/4ojiage.png)  

## 7月19日
- 新增支持 gpt-4o-mini 模型，后台计费同步官方

## 7月15日 公告
- 支持官方的 api 参数 include_usage，传入参数可返回 stream 模式下的 usage，详情见 [官方文档](https://platform.openai.com/docs/api-reference/chat/create#chat-create-stream_options)

## 7月14日 公告
- 新版本 nextweb 增加了支持调用非 Openai 模型 [调用本站非OpenAI模型](https://doc.aihubmix.com/%E5%A6%82%E4%BD%95%E8%B0%83%E7%94%A8%E6%9C%AC%E7%AB%99%E9%9D%9EOpenAI%E6%A8%A1%E5%9E%8B)
- 增加了阿里千问模型的后台扣费，总统调用我们的成本比调用阿里云官方贵10%左右
- 优化 azure openai 返回的输出更好的兼容了 Openai 接口
- 支持 Claude-3 的 tool Calling
- 增加了很多新模型，见设置/可用模型

## 7月3日 公告
- 整体后台界面进行了优化
- 日志每条请求记录增加了展示请求时当时的模型单价
- 增加了模型及价格页面 [模型/价格](https://doc.aihubmix.com/%E5%A6%82%E4%BD%95%E8%B0%83%E7%94%A8%E6%9C%AC%E7%AB%99%E9%9D%9EOpenAI%E6%A8%A1%E5%9E%8B)

## 6月20日 公告
- 最新 claude-3-5-sonnet-20240620 已支持，调用方法见[调用本站非open AI模型教程](https://doc.aihubmix.com/%E5%A6%82%E4%BD%95%E8%B0%83%E7%94%A8%E6%9C%AC%E7%AB%99%E9%9D%9EOpenAI%E6%A8%A1%E5%9E%8B)

## 6月18日 公告
- 后台日志页面现在开始，支持下载使用请求记录

## 6月16日 公告
- 降低了随机到 azure openai 的概率，现在几乎很小概率会随机到

## 6月13日 公告
- 下调 Claude-3 相关模型的费用（Claude 3 Haiku、Claude 3 Sonnet、Claude 3 Opus）后台扣费和官方一致；因此当前我们网站额度零售价格，使用我们的 API 的成本相当于官网 86 折；

## 6月10日 公告
- 整体服务架构升级，全部服务器和数据迁入微软 Azure；
- 未来我将基于 one api 的开源版本项目进行二次深度开发和优化（原本我们已通过赞助获得 oneapi 项目商业版授权）
- 日志部分数据量太大（超过 1 亿级的请求日志）因此暂时无法迁移，如需查询之前的老日志请联系客服
- 优化 gpt-4o 的 token 计费， tokenizer 的 cI100k_base 改为0200k_base ，之前的 gpt-4 系列用的是 cI100k_base；结果就是中文、韩文、日文的流式请求的 token 计数会比之前下降；

## 6月8日 公告
- 新增阿里最新开源模型 Qinwen2
- alibaba/Qwen2-7B-Instruct、alibaba/Qwen2-57B-A14B-Instruct、alibaba/Qwen2-72B-Instruct

## 5月20日 公告
- 新增模型 gemini-1.5-flash
- 新增模型 gpt-4o
- 江苏地区进入充值页面报错，因为充值域名被电信劫持，请先[联系客服](https://doc.aihubmix.com/%E5%85%85%E5%80%BC%E4%B8%8E%E4%BA%BA%E5%B7%A5%E5%AE%A2%E6%9C%8D)进行充值。
- 新增 llama3（llama3-70b-8192、llama3-8b-8192）gemini-1.5-pro、command-r、command-r-plus、欢迎调用尝试
- Claude-3 模型恢复供应；目前本站正在连接 Claude-3 部署在 aws 和 Google cloud 上的端点。
- 为了维持服务器费用及团队成本，Claude-3 模型和价格后台扣费比官方贵 10%
- 后续调用量增加的话，会逐步下调至 5% 左右，甚至更低，
- 目前并发有待测试和随着调用增加而去申请更高的并发调用。