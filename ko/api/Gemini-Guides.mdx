---
title: "Gemini ê°€ì´ë“œ"
description: "ìš°ë¦¬ í”Œë«í¼ì—ì„œ Gemini API í˜¸ì¶œì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì´ë“œì…ë‹ˆë‹¤."
icon: "google"
---

## Gemini ëª¨ë¸ ì „ë‹¬

Gemini ì‹œë¦¬ì¦ˆì˜ ê²½ìš° **ë‘ ê°€ì§€** í˜¸ì¶œ ë°©ë²•, ì¦‰ ë„¤ì´í‹°ë¸Œ API í˜¸ì¶œê³¼ OpenAI í˜¸í™˜ í˜¸ì¶œì„ ì œê³µí•©ë‹ˆë‹¤.\
ì‹œì‘í•˜ê¸° ì „ì— `pip install google-genai` ë˜ëŠ” `pip install -U google-genai`ë¥¼ ì‹¤í–‰í•˜ì—¬ ë„¤ì´í‹°ë¸Œ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.

1ï¸âƒ£ ë„¤ì´í‹°ë¸Œ ì „ë‹¬ì˜ ê²½ìš° ì£¼ë¡œ ë‚´ë¶€ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •ì— **AiHubMix API í‚¤**ì™€ **ìš”ì²­ URL**ì„ ì£¼ì…í•´ì•¼ í•©ë‹ˆë‹¤.\
âš¡ï¸ ì°¸ê³ : URL í˜•ì‹ì€ ê¸°ì¡´ì˜ `base_url` ì‚¬ìš©ë²•ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ì•„ë˜ ì˜ˆë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤:

```python
client = genai.Client(
    api_key="sk-***",  # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    http_options={"base_url": "https://aihubmix.com"},
)
```

2ï¸âƒ£ OpenAI í˜¸í™˜ í˜•ì‹ì˜ ê²½ìš° ë²”ìš© `v1` ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

```py
client = OpenAI(
    api_key="sk-***", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    base_url="https://aihubmix.com/v1",
)
```

3ï¸âƒ£ 2.5 ì‹œë¦¬ì¦ˆì˜ ê²½ìš° ì¶”ë¡  ê³¼ì •ì„ í‘œì‹œí•´ì•¼ í•˜ëŠ” ê²½ìš° ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤:

1. **ë„¤ì´í‹°ë¸Œ í˜¸ì¶œ:** `include_thoughts=True` ì „ë‹¬
2. **OpenAI í˜¸í™˜ ë°©ë²•:** `reasoning_effort` ì „ë‹¬

ìì„¸í•œ ì‚¬ìš©ë²•ì€ ì•„ë˜ ì½”ë“œ ì˜ˆì œë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Gemini 2.5 ì¶”ë¡  ëª¨ë¸ ì •ë³´

1. ì „ì²´ 2.5 ì‹œë¦¬ì¦ˆëŠ” **ì¶”ë¡  ëª¨ë¸**ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
2. **2.5 Flash**ëŠ” Claude Sonnet 3.7ê³¼ ìœ ì‚¬í•œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì…ë‹ˆë‹¤. ìµœì ì˜ ì œì–´ë¥¼ ìœ„í•´ `thinking_budget` ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•˜ì—¬ ì¶”ë¡  ë™ì‘ì„ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **2.5 Pro**ëŠ” ìˆœìˆ˜ ì¶”ë¡  ëª¨ë¸ì…ë‹ˆë‹¤. ì‚¬ê³ ë¥¼ ë¹„í™œì„±í™”í•  ìˆ˜ ì—†ìœ¼ë©° `thinking_budget`ì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

**Python ì‚¬ìš© ì˜ˆì œ:**

<CodeGroup>

```py StreamFalse
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.0-flash"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ì‹œê°„ì„ ë‚­ë¹„í•˜ê³  ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆìŠµë‹ˆê¹Œ?"""),
            ],
        ),
    ]

    print(client.models.generate_content(
        model=model,
        contents=contents,
    ))

if __name__ == "__main__":
    generate()
```


```py 2.0 ì‹œë¦¬ì¦ˆ-ìŠ¤íŠ¸ë¦¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.0-flash"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ì‹œê°„ì„ ë‚­ë¹„í•˜ê³  ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆìŠµë‹ˆê¹Œ?"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```


```py 2.5 Flash-ìŠ¤íŠ¸ë¦¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-flash-preview-04-17" #gemini-2.5-pro-preview-03-25ã€gemini-2.5-flash-preview-04-17
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ì‹œê°„ì„ ë‚­ë¹„í•˜ê³  ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆìŠµë‹ˆê¹Œ?"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        thinking_config = types.ThinkingConfig(
            thinking_budget=2048, #ë²”ìœ„: 0-16K. ê¸°ë³¸ê°’ 1024, ìµœìƒì˜ ì„±ëŠ¥ì„ ìœ„í•´ 16000
        ),
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```


```py 2.5 Pro-ìŠ¤íŠ¸ë¦¼
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-03-25"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ì‹œê°„ì„ ë‚­ë¹„í•˜ê³  ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆìŠµë‹ˆê¹Œ?"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")

if __name__ == "__main__":
    generate()
```


```py 2.5 ì‚¬ê³  í‘œì‹œ
from google import genai
from google.genai import types

def generate():
    client = genai.Client(
        api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-05-06"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ê¸ˆìœµì—ì„œ \"72ì˜ ë²•ì¹™\"ì€ ì–´ë–»ê²Œ íŒŒìƒë˜ì—ˆìŠµë‹ˆê¹Œ?"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
        thinking_config=types.ThinkingConfig(
            include_thoughts=True  # ì‚¬ê³  ë‚´ìš© í‘œì‹œ
        ),
    )

    final_usage_metadata = None
    
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        if chunk.candidates and len(chunk.candidates) > 0:
            for part in chunk.candidates[0].content.parts:
                if part.text:
                    if part.thought:
                        print(part.text, end="")
                    else:
                        print(part.text, end="")

        if chunk.usage_metadata:
            final_usage_metadata = chunk.usage_metadata
    
    if final_usage_metadata:
        print(f"\n\nğŸ“Š í† í° ì‚¬ìš©ëŸ‰:")
        print(f"ì‚¬ê³  í† í°: {getattr(final_usage_metadata, 'thoughts_token_count', 'ì‚¬ìš© ë¶ˆê°€')}")
        print(f"ì¶œë ¥ í† í°: {getattr(final_usage_metadata, 'candidates_token_count', 'ì‚¬ìš© ë¶ˆê°€')}")
        print(f"ì´ê³„: {final_usage_metadata}")

if __name__ == "__main__":
    generate()
```

</CodeGroup>

## Gemini 2.5 Flash: ë¹ ë¥¸ ì‘ì—… ì§€ì›

OpenAI í˜¸í™˜ í˜¸ì¶œ ì˜ˆì œ:

<CodeGroup>

```py Python ë¹ ë¥¸ ì‘ì—…ì„ ìœ„í•´ ì‚¬ê³  ë¹„í™œì„±í™”
from openai import OpenAI

client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17-nothink",
    messages=[
        {
            "role": "user",
            "content": "ì˜¤ì»´ì˜ ë©´ë„ë‚  ê°œë…ì„ ì„¤ëª…í•˜ê³  ì¼ìƒì ì¸ ì˜ˆë¥¼ ë“¤ì–´ì£¼ì„¸ìš”"
        }
    ]
)

print(completion.choices[0].message.content)
```


```py Python ì¶”ë¡  ë…¸ë ¥
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17",
    reasoning_effort="low", #"low", "medium", "high"ëŠ” 1K, 8K, 16K ì‚¬ê³  í† í° ì˜ˆì‚°ì— ë§¤í•‘ë©ë‹ˆë‹¤.
    messages=[
        {
            "role": "user",
            "content": "ì˜¤ì»´ì˜ ë©´ë„ë‚  ê°œë…ì„ ì„¤ëª…í•˜ê³  ì¼ìƒì ì¸ ì˜ˆë¥¼ ë“¤ì–´ì£¼ì„¸ìš”"
        }
    ]
)

print(completion.choices[0].message.content)
```


```shell Curl-ê¸°ë³¸
curl -X POST https://aihubmix.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-***" \
  -d '{
    "model": "gemini-2.5-flash-preview-04-17-nothink",
    "messages": [
      {
        "role": "user",
        "content": "ì˜¤ì»´ì˜ ë©´ë„ë‚  ê°œë…ì„ ì„¤ëª…í•˜ê³  ì¼ìƒì ì¸ ì˜ˆë¥¼ ë“¤ì–´ì£¼ì„¸ìš”."
      }
    ]
  }'
```


```shell Curl-ì‚¬ê³  í‘œì‹œ
curl https://aihubmix.com/v1/chat/completions \
-H "Content-Type: application/json" \
-H "Authorization: Bearer sk-***" \
-d '{
  "model": "gemini-2.5-pro-preview-05-06",
  "messages": [
    {
      "role": "user",
      "content": "ì˜¤ì»´ì˜ ë©´ë„ë‚  ê°œë…ì„ ì„¤ëª…í•˜ê³  ì¼ìƒì ì¸ ì˜ˆë¥¼ ë“¤ì–´ì£¼ì„¸ìš”."
    }
  ],
  "reasoning_effort": "low"
}'
```

</CodeGroup>

<Tip>
  1. ë³µì¡í•œ ì‘ì—…ì˜ ê²½ìš° ëª¨ë¸ IDë¥¼ ê¸°ë³¸ `gemini-2.5-flash-preview-04-17`ë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ê³ ë¥¼ í™œì„±í™”í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.
  2. Gemini 2.5 FlashëŠ” `budget` ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ê³ ì˜ ê¹Šì´ë¥¼ ì œì–´í•˜ë©°, ë²”ìœ„ëŠ” 0ì—ì„œ 16Kì…ë‹ˆë‹¤. ê¸°ë³¸ ì˜ˆì‚°ì€ 1024ì´ë©° ìµœì ì˜ í•œê³„ íš¨ê³¼ëŠ” 16Kì…ë‹ˆë‹¤.
</Tip>

## ë¯¸ë””ì–´ ì´í•´

AihubmixëŠ” í˜„ì¬ `inline_data`ë¥¼ í†µí•´ **ìµœëŒ€ 20MB**ì˜ ë©€í‹°ë¯¸ë””ì–´ íŒŒì¼(ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë° ë¹„ë””ì˜¤) ì—…ë¡œë“œë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
20MBë¥¼ ì´ˆê³¼í•˜ëŠ” íŒŒì¼ì˜ ê²½ìš° íŒŒì¼ APIê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ì•„ì§ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§„í–‰ ìƒí™© ì¶”ì  ë° upload_url ê²€ìƒ‰ì€ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤.

<CodeGroup>

```py ì´ë¯¸ì§€
from google import genai
from google.genai import types

file_path = "yourpath/file.jpeg"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="image/jpeg"
                )
            ),
            types.Part(
                text="ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ì„¸ìš”."
            )
        ]
    )
)

print(response.text)
```


```py ì˜¤ë””ì˜¤
from google import genai
from google.genai import types

file_path = "yourpath/file.m4a"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="audio/m4a"
                )
            ),
            types.Part(
                text="ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì„¸ìš”."
            )
        ]
    )
)

print(response.text)
```


```py ë¹„ë””ì˜¤
from google import genai
from google.genai import types

file_path = "yourpath/file.mp4"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="video/mp4"
                )
            ),
            types.Part(
                text="ì´ ë¹„ë””ì˜¤ë¥¼ ìš”ì•½í•˜ì„¸ìš”. ê·¸ëŸ° ë‹¤ìŒ ì´ ë¹„ë””ì˜¤ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µì•ˆì§€ê°€ ìˆëŠ” í€´ì¦ˆë¥¼ ë§Œë“œì„¸ìš”."
            )
        ]
    )
)

print(response.text)
```


```py ìœ íŠœë¸Œ URL
from google import genai
from google.genai import types

client = genai.Client(
    api_key="sk-***", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                file_data=types.FileData(
                    file_uri="https://www.youtube.com/watch?v=OoU7PwNyYUw"
                )
            ),
            types.Part(
                text="ë¹„ë””ì˜¤ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”."
            )
        ]
    )
)

print(response.text)
```

</CodeGroup>

## ì½”ë“œ ì‹¤í–‰

ì½”ë“œ ì‹¤í–‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ Python ì½”ë“œë¥¼ ìƒì„± ë° ì‹¤í–‰í•˜ê³  ìµœì¢… ì¶œë ¥ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ê²°ê³¼ë¡œë¶€í„° ë°˜ë³µì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì½”ë“œ ì‹¤í–‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ê¸°ë°˜ ì¶”ë¡ ì˜ ì´ì ì„ í™œìš©í•˜ê³  í…ìŠ¤íŠ¸ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë¹Œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë°©ì •ì‹ì„ í’€ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì½”ë“œ ì‹¤í–‰ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py Python
from google import genai
from google.genai import types

file_path = "yourpath/file.csv"
with open(file_path, "rb") as f:
    file_bytes = f.read()

client = genai.Client(
    api_key="sk-***", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    http_options={"base_url": "https://aihubmix.com/gemini"}
)

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(
                inline_data=types.Blob(
                    data=file_bytes,
                    mime_type="text/csv"
                )
            ),
            types.Part(
                text="ì´ CSVë¥¼ ë¶„ì„í•˜ê³  ì£¼ìš” í†µê³„ë¥¼ ìš”ì•½í•´ ì£¼ì„¸ìš”. í•„ìš”í•œ ê²½ìš° ì½”ë“œ ì‹¤í–‰ì„ ì‚¬ìš©í•˜ì„¸ìš”."
            )
        ]
    ),
    config=types.GenerateContentConfig(
        tools=[types.Tool(
            code_execution=types.ToolCodeExecution
        )]
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    if getattr(part, "executable_code", None) is not None:
        print("ìƒì„±ëœ ì½”ë“œ:\n", part.executable_code.code)
    if getattr(part, "code_execution_result", None) is not None:
        print("ì‹¤í–‰ ê²°ê³¼:\n", part.code_execution_result.output)
```

## ì»¨í…ìŠ¤íŠ¸ ìºì‹±

Geminiì˜ ë„¤ì´í‹°ë¸Œ APIëŠ” **ê¸°ë³¸ì ìœ¼ë¡œ ì•”ì‹œì  ì»¨í…ìŠ¤íŠ¸ ìºì‹±ì„ í™œì„±í™”**í•˜ë¯€ë¡œ ì„¤ì •ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  `generate_content` ìš”ì²­ì— ëŒ€í•´ ì‹œìŠ¤í…œì€ ìë™ìœ¼ë¡œ ì…ë ¥ ì½˜í…ì¸ ë¥¼ ìºì‹œí•©ë‹ˆë‹¤. í›„ì† ìš”ì²­ì´ ì •í™•íˆ ë™ì¼í•œ ì½˜í…ì¸ , ëª¨ë¸ ë° ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì‹œìŠ¤í…œì€ ì¦‰ì‹œ ì´ì „ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì—¬ ì‘ë‹µ ì‹œê°„ì„ í¬ê²Œ ë‹¨ì¶•í•˜ê³  ì ì¬ì ìœ¼ë¡œ ì…ë ¥ í† í° ë¹„ìš©ì„ ì ˆê°í•©ë‹ˆë‹¤.

- **ìºì‹±ì€ ìë™ì´ë©° ìˆ˜ë™ êµ¬ì„±ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
- ìºì‹œëŠ” ì½˜í…ì¸ , ëª¨ë¸ ë° ëª¨ë“  ë§¤ê°œë³€ìˆ˜ê°€ ì •í™•íˆ ë™ì¼í•  ë•Œë§Œ ì ì¤‘ë©ë‹ˆë‹¤. ì–´ë–¤ ì°¨ì´ë¼ë„ ìºì‹œ ë¯¸ìŠ¤ë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤.
- ìºì‹œ TTL(Time-To-Live)ì€ ê°œë°œìê°€ ì„¤ì •í•˜ê±°ë‚˜ ì„¤ì •í•˜ì§€ ì•Šì€ ìƒíƒœë¡œ ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤(ê¸°ë³¸ê°’ 1ì‹œê°„). Googleì—ì„œ ì ìš©í•˜ëŠ” ìµœì†Œ ë˜ëŠ” ìµœëŒ€ TTLì€ ì—†ìŠµë‹ˆë‹¤. ë¹„ìš©ì€ ìºì‹œëœ í† í° ìˆ˜ì™€ ìºì‹œ ê¸°ê°„ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.
  - Googleì€ TTLì— ì œí•œì„ ë‘ì§€ ì•Šì§€ë§Œ ì „ë‹¬ í”Œë«í¼ìœ¼ë¡œì„œ **ì œí•œëœ TTL ë²”ìœ„ë§Œ ì§€ì›í•©ë‹ˆë‹¤**. í”Œë«í¼ì˜ í•œê³„ë¥¼ ë„˜ì–´ì„œëŠ” ìš”êµ¬ ì‚¬í•­ì— ëŒ€í•´ì„œëŠ” ë¬¸ì˜í•´ ì£¼ì‹­ì‹œì˜¤.

### ì°¸ê³ 

- **ë¹„ìš© ì ˆê° ë³´ì¥ ì—†ìŒ:** ìºì‹œ í† í°ì€ í‘œì¤€ ì…ë ¥ ê°€ê²©ì˜ 25%ë¡œ ì²­êµ¬ë˜ë¯€ë¡œ ì´ë¡ ì ìœ¼ë¡œ ìºì‹±ì€ ì…ë ¥ í† í° ë¹„ìš©ì„ ìµœëŒ€ 75%ê¹Œì§€ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ [Googleì˜ ê³µì‹ ë¬¸ì„œ](https://ai.google.dev/gemini-api/docs/caching?lang=python)ëŠ” ë¹„ìš© ì ˆê°ì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹¤ì œ íš¨ê³¼ëŠ” ìºì‹œ ì ì¤‘ë¥ , í† í° ìœ í˜• ë° ì €ì¥ ê¸°ê°„ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.
- **ìºì‹œ ì ì¤‘ ì¡°ê±´:** ìºì‹œ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ë ¤ë©´ ì…ë ¥ ì‹œì‘ ë¶€ë¶„ì— ë°˜ë³µ ê°€ëŠ¥í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜í•˜ê³  ë ë¶€ë¶„ì— ë™ì  ì½˜í…ì¸ (ì˜ˆ: ì‚¬ìš©ì ì…ë ¥)ë¥¼ ë°°ì¹˜í•˜ì‹­ì‹œì˜¤.
- **ìºì‹œ ì ì¤‘ ê°ì§€ ë°©ë²•:** ì‘ë‹µì´ ìºì‹œì—ì„œ ì˜¨ ê²½ìš° `response.usage_metadata`ì— `cache_tokens_details` í•„ë“œì™€ `cached_content_token_count`ê°€ í¬í•¨ë©ë‹ˆë‹¤. ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìºì‹œ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\
  ìºì‹œ ì ì¤‘ ì‹œ ì˜ˆì œ í•„ë“œ:

  ```
  cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=2003)]
  cached_content_token_count=2003
  ```

**ì½”ë“œ ì˜ˆì œ:**

```python
from google import genai

client = genai.Client(
    http_options={"base_url": "https://aihubmix.com/gemini"},
    api_key="sk-***",  # AiHubMix API í‚¤ë¡œ êµì²´
)

prompt = """
        <ì˜¤ë§Œê³¼ í¸ê²¬ì˜ ì „ì²´ ë‚´ìš©>
"""

def generate_content_sync():
    response = client.models.generate_content(
        model="gemini-2.5-flash-preview-05-20",
        contents=prompt + "'ì˜¤ë§Œê³¼ í¸ê²¬'ì˜ ì£¼ìš” ì£¼ì œë¥¼ ë¶„ì„í•˜ì„¸ìš”.",
    )
    print(response.usage_metadata)  # ìºì‹œê°€ ì ì¤‘ë˜ë©´ cache_tokens_detailsì™€ cached_content_token_countê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
    return response

generate_content_sync()
```

> ìºì‹œê°€ ì ì¤‘ë˜ë©´ `response.usage_metadata`ì— ë‹¤ìŒì´ í¬í•¨ë©ë‹ˆë‹¤:
>
> ```
> cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=2003)]
> cached_content_token_count=2003
> ```

**í•µì‹¬ ê²°ë¡ :** ì•”ì‹œì  ìºì‹±ì€ ìë™ì´ë©° ëª…í™•í•œ ìºì‹œ ì ì¤‘ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤. ê°œë°œìëŠ” usage_metadataì—ì„œ ìºì‹œ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ë¹„ìš© ì ˆê°ì€ ë³´ì¥ë˜ì§€ ì•Šìœ¼ë©°** ì‹¤ì œ ì´ì ì€ ìš”ì²­ êµ¬ì¡°ì™€ ìºì‹œ ì ì¤‘ë¥ ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.

## í•¨ìˆ˜ í˜¸ì¶œ

openai í˜¸í™˜ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ Geminiì˜ í•¨ìˆ˜ í˜¸ì¶œì„ í˜¸ì¶œí•˜ë ¤ë©´ ìš”ì²­ ë³¸ë¬¸ì— `tool_choice="auto"`ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

<CodeGroup>

```py Python
from openai import OpenAI

# ëª¨ë¸ì— ëŒ€í•œ í•¨ìˆ˜ ì„ ì–¸ ì •ì˜
schedule_meeting_function = {
    "name": "schedule_meeting",
    "description": "ì§€ì •ëœ ì‹œê°„ì— ì§€ì •ëœ ì°¸ì„ìì™€ íšŒì˜ë¥¼ ì˜ˆì•½í•©ë‹ˆë‹¤.",
    "parameters": {
        "type": "object",
        "properties": {
            "attendees": {
                "type": "array",
                "items": {"type": "string"},
                "description": "íšŒì˜ì— ì°¸ì„í•˜ëŠ” ì‚¬ëŒë“¤ì˜ ëª©ë¡ì…ë‹ˆë‹¤.",
            },
            "date": {
                "type": "string",
                "description": "íšŒì˜ ë‚ ì§œ (ì˜ˆ: '2024-07-29')",
            },
            "time": {
                "type": "string",
                "description": "íšŒì˜ ì‹œê°„ (ì˜ˆ: '15:00')",
            },
            "topic": {
                "type": "string",
                "description": "íšŒì˜ì˜ ì£¼ì œ ë˜ëŠ” ì£¼ì œì…ë‹ˆë‹¤.",
            },
        },
        "required": ["attendees", "date", "time", "topic"],
    },
}

# í´ë¼ì´ì–¸íŠ¸ êµ¬ì„±
client = OpenAI(
    api_key="AIHUBMIX_API_KEY", # AiHubMixì—ì„œ ìƒì„±í•œ í‚¤ë¡œ êµì²´
    base_url="https://aihubmix.com/v1",
)

# OpenAI í˜¸í™˜ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ ì„ ì–¸ìœ¼ë¡œ ìš”ì²­ ë³´ë‚´ê¸°
response = client.chat.completions.create(
    model="gemini-2.0-flash",
    messages=[
        {"role": "user", "content": "ë°¥ê³¼ ì•¨ë¦¬ìŠ¤ì™€ 2025ë…„ 3ì›” 14ì¼ ì˜¤ì „ 10ì‹œì— 3ë¶„ê¸° ê³„íšì— ëŒ€í•´ íšŒì˜ë¥¼ ì˜ˆì•½í•˜ì„¸ìš”."}
    ],
    tools=[{"type": "function", "function": schedule_meeting_function}],
    tool_choice="auto" ## ğŸ“ Aihubmix í˜¸í™˜ì„± ì¶”ê°€, ë” ì•ˆì •ì ì¸ ìš”ì²­ ë°©ë²•
)

# í•¨ìˆ˜ í˜¸ì¶œ í™•ì¸
if response.choices[0].message.tool_calls:
    tool_call = response.choices[0].message.tool_calls[0]
    function_call = tool_call.function
    print(f"í˜¸ì¶œí•  í•¨ìˆ˜: {function_call.name}")
    print(f"ì¸ìˆ˜: {function_call.arguments}")
    print(response.usage)
    #  ì‹¤ì œ ì•±ì—ì„œëŠ” ì—¬ê¸°ì—ì„œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤:
    #  result = schedule_meeting(**json.loads(function_call.arguments))
else:
    print("ì‘ë‹µì—ì„œ í•¨ìˆ˜ í˜¸ì¶œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(response.choices[0].message.content)
```

</CodeGroup>

**ì¶œë ¥ ì˜ˆ:**

```bash
í˜¸ì¶œí•  í•¨ìˆ˜: schedule_meeting
ì¸ìˆ˜: {"attendees":["Bob","Alice"],"date":"2025-03-14","time":"10:00","topic":"Q3 planning"}
CompletionUsage(completion_tokens=28, prompt_tokens=111, total_tokens=139, completion_tokens_details=None, prompt_tokens_details=None)
```

## í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  ê°„ì†Œí™”

1. **Gemini**ëŠ” `usage_metadata`ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì í•©ë‹ˆë‹¤. ê° í•„ë“œì˜ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
   - `prompt_token_count`: ì…ë ¥ í† í° ìˆ˜
   - `candidates_token_count`: ì¶œë ¥ í† í° ìˆ˜
   - `thoughts_token_count`: ì¶”ë¡  ì¤‘ì— ì‚¬ìš©ëœ í† í° (ì¶œë ¥ìœ¼ë¡œë„ ê³„ì‚°ë¨)
   - `total_token_count`: ì´ ì‚¬ìš©ëœ í† í° (ì…ë ¥ + ì¶œë ¥)

   ìì„¸í•œ ë‚´ìš©ì€ [ê³µì‹ ë¬¸ì„œ](https://ai.google.dev/gemini-api/docs/tokens?lang=python)ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.
2. **OpenAI í˜¸í™˜ í˜•ì‹**ì„ ì‚¬ìš©í•˜ëŠ” APIì˜ ê²½ìš° í† í° ì‚¬ìš©ëŸ‰ì€ ë‹¤ìŒ í•„ë“œì™€ í•¨ê»˜ `.usage` ì•„ë˜ì—ì„œ ì¶”ì ë©ë‹ˆë‹¤:
   - `usage.completion_tokens`: ì…ë ¥ í† í° ìˆ˜
   - `usage.prompt_tokens`: ì¶œë ¥ í† í° ìˆ˜ (ì¶”ë¡  í¬í•¨)
   - `usage.total_tokens`: ì´ í† í° ì‚¬ìš©ëŸ‰

---

**ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:**

<CodeGroup>

```py Gemini ë„¤ì´í‹°ë¸Œ
from google import genai
from google.genai import types
import time

def generate():
    client = genai.Client(
        api_key="sk-***", # AiHubMixì˜ í‚¤ë¡œ êµì²´
        http_options={"base_url": "https://aihubmix.com/gemini"},
    )

    model = "gemini-2.5-pro-preview-03-25"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""ê¸ˆìœµê³„ì—ì„œ \"72ì˜ ë²•ì¹™\"ì€ ì–´ë–»ê²Œ íŒŒìƒë˜ì—ˆìŠµë‹ˆê¹Œ?"""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        response_mime_type="text/plain",
    )

    final_usage_metadata = None
    
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        print(chunk.text, end="")
        if chunk.usage_metadata:
            final_usage_metadata = chunk.usage_metadata
    
    # ëª¨ë“  ì²­í¬ê°€ ì²˜ë¦¬ë˜ë©´ ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ì„ ì¸ì‡„í•©ë‹ˆë‹¤.
    if final_usage_metadata:
        print(f"\nì‚¬ìš©ëŸ‰: {final_usage_metadata}")

if __name__ == "__main__":
    generate()
```


```py OpenAI í˜¸í™˜
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # AiHubMixì˜ í‚¤ë¡œ êµì²´
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17",
    reasoning_effort="low", #"low", "medium", "high"ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ 1K, 8K, 24K ì‚¬ê³  í† í° ì˜ˆì‚°ì— ë§¤í•‘ë©ë‹ˆë‹¤. ì‚¬ê³ ë¥¼ ë¹„í™œì„±í™”í•˜ë ¤ë©´ ì¶”ë¡  ë…¸ë ¥ì„ "none"ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    messages=[
        {
            "role": "user",
            "content": "ê¸ˆìœµê³„ì—ì„œ \"72ì˜ ë²•ì¹™\"ì€ ì–´ë–»ê²Œ íŒŒìƒë˜ì—ˆìŠµë‹ˆê¹Œ?"
        }
    ],
    stream=True
)

#print(completion.choices[0].message.content)

for chunk in completion:
    print(chunk.choices[0].delta)
    # ë§ˆì§€ë§‰ ì²­í¬ì—ë§Œ í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ë¥¼ ì¸ì‡„í•©ë‹ˆë‹¤ (ì „ì²´ ì‚¬ìš©ëŸ‰ ë°ì´í„° í¬í•¨)
    if chunk.usage and chunk.usage.completion_tokens > 0:
        print(f"ì¶œë ¥ í† í°: {chunk.usage.completion_tokens}")
        print(f"ì…ë ¥ í† í°: {chunk.usage.prompt_tokens}")
        print(f"ì´ í† í°: {chunk.usage.total_tokens}")
```

</CodeGroup>