---
title: "Qwen ì‹œë¦¬ì¦ˆ"
icon: "a"
---

## Qwen 3 ì‹œë¦¬ì¦ˆ

Qwen3ëŠ” ë™ì  ì‚¬ê³  ëª¨ë“œë¡œ ì˜¤í”ˆ LLMì„ ì¬ì •ì˜í•˜ë©°, ì½”ë“œ, ìˆ˜í•™, ë‹¤êµ­ì–´ ì¶”ë¡ ì—ì„œ íƒì›”í•©ë‹ˆë‹¤. í¬ì†Œí•œ 22B í™œì„± ë§¤ê°œë³€ìˆ˜ë¡œ êµ¬ë™ë˜ì–´ ë²ˆê°œê°™ì€ ì†ë„ì™€ ê¹Šì€ ì§€ëŠ¥ì˜ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤ â€” ê²½ëŸ‰ì—ì„œ 235B ê±°ëŒ€ ëª¨ë¸ê¹Œì§€ ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ì…ë‹ˆë‹¤.

**1. ê¸°ë³¸ ì‚¬ìš©:** OpenAI í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.  
**2. ë„êµ¬ í˜¸ì¶œ:** ì¼ë°˜ ë„êµ¬ëŠ” OpenAI í˜¸í™˜ í˜•ì‹ì„ ì§€ì›í•˜ë©°, MCP ë„êµ¬ëŠ” qwen-agentì— ì˜ì¡´í•˜ê³  ë¨¼ì € ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:
`pip install -U qwen-agent mcp`.
ìì„¸í•œ ë‚´ìš©ì€ [Ali ê³µì‹ ë¬¸ì„œ](https://huggingface.co/Qwen/Qwen3-235B-A22B)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”

<CodeGroup>

```py ê¸°ë³¸ ì‚¬ìš©
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´í•˜ì„¸ìš”
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="Qwen/Qwen3-30B-A3B",
    messages=[
        {
            "role": "user",
            "content": "ì˜¤ì»´ì˜ ë©´ë„ë‚  ê°œë…ì„ ì„¤ëª…í•˜ê³  ì¼ìƒìƒí™œì—ì„œì˜ ì˜ˆì‹œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”"
        }
    ],
    stream=True
)

for chunk in completion:
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```

```py ë„êµ¬
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´í•˜ì„¸ìš”
    base_url="https://aihubmix.com/v1",
)

# ë„êµ¬ ì •ì˜
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "ì§€ì •ëœ ìœ„ì¹˜ì˜ í˜„ì¬ ë‚ ì”¨ ê°€ì ¸ì˜¤ê¸°",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "ë„ì‹œ ì´ë¦„, ì˜ˆ: ì„œìš¸, ë¶€ì‚° ë“±"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "ì˜¨ë„ ë‹¨ìœ„"
                    }
                },
                "required": ["location"]
            }
        }
    }
]

# ë„êµ¬ ì •ì˜ê°€ í¬í•¨ëœ ì±„íŒ… ì™„ì„± ìš”ì²­ ìƒì„±
completion = client.chat.completions.create(
    model="Qwen/Qwen3-30B-A3B",  # 2.5ì™€ 3 ëª¨ë‘ ì§€ì›, QwQëŠ” ì§€ì›í•˜ì§€ ì•ŠìŒ
    messages=[
        {
            "role": "user",
            "content": "ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?"
        }
    ],
    tools=tools,
    tool_choice="auto",  # ëª¨ë¸ì´ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë¥¼ ê²°ì •í•˜ë„ë¡ í•¨
    stream=True
)

# ë„êµ¬ í˜¸ì¶œ ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
tool_calls = {}

# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
for chunk in completion:
    if not hasattr(chunk.choices, '__len__') or len(chunk.choices) == 0:
        continue
        
    delta = chunk.choices[0].delta
    
    # í…ìŠ¤íŠ¸ ë‚´ìš© ì²˜ë¦¬
    if hasattr(delta, 'content') and delta.content:
        print(delta.content, end="")
    
    # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
    if hasattr(delta, 'tool_calls') and delta.tool_calls:
        for tool_call in delta.tool_calls:
            if not hasattr(tool_call, 'index'):
                continue
                
            idx = tool_call.index
            if idx not in tool_calls:
                tool_calls[idx] = {"name": "", "arguments": ""}
                
            if hasattr(tool_call, 'function'):
                if hasattr(tool_call.function, 'name') and tool_call.function.name:
                    tool_calls[idx]["name"] = tool_call.function.name
                if hasattr(tool_call.function, 'arguments') and tool_call.function.arguments:
                    tool_calls[idx]["arguments"] += tool_call.function.arguments

# ì™„ë£Œ í›„ ìˆ˜ì§‘ëœ ë„êµ¬ í˜¸ì¶œ ì •ë³´ ì¶œë ¥
for idx, info in tool_calls.items():
    if info["name"]:
        print(f"\në„êµ¬ í˜¸ì¶œ: {info['name']}")
    if info["arguments"]:
        print(f"ì¸ìˆ˜: {info['arguments']}")
```

```py MCP ë„êµ¬
from qwen_agent.agents import Assistant
import os

# LLM ì •ì˜
llm_cfg = {
    'model': 'Qwen/Qwen3-30B-A3B',

    # OpenAI APIì™€ í˜¸í™˜ë˜ëŠ” ì‚¬ìš©ì ì •ì˜ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©:
    'model_server': 'https://aihubmix.com/v1',
    'api_key': os.getenv('AIHUBMIX_API_KEY'),

    # ê¸°íƒ€ ë§¤ê°œë³€ìˆ˜:
    # 'generate_cfg': {
    #         # ì¶”ê°€: ì‘ë‹µ ë‚´ìš©ì´ `<think>ì´ê²ƒì´ ìƒê°ì…ë‹ˆë‹¤</think>ì´ê²ƒì´ ë‹µë³€ì…ë‹ˆë‹¤;ì¼ ë•Œ
    #         # ì¶”ê°€í•˜ì§€ ì•ŠìŒ: ì‘ë‹µì´ reasoning_contentì™€ contentë¡œ ë¶„ë¦¬ë˜ì—ˆì„ ë•Œ.
    #         'thought_in_content': True,
    #     },
}

# ë„êµ¬ ì •ì˜
tools = [
    {'mcpServers': {  # MCP êµ¬ì„± íŒŒì¼ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Seoul']
            },
            "fetch": {
                "command": "uvx",
                "args": ["mcp-server-fetch"]
            }
        }
    },
  'code_interpreter',  # ë‚´ì¥ ë„êµ¬
]

# ì—ì´ì „íŠ¸ ì •ì˜
bot = Assistant(llm=llm_cfg, function_list=tools)

# ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
messages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Qwenì˜ ìµœì‹  ê°œë°œ ìƒí™©ì„ ì†Œê°œí•´ì£¼ì„¸ìš”'}]
for responses in bot.run(messages=messages):
    pass
print(responses)
```

</CodeGroup>

## Qwen 2.5 ë° QwQ/QvQ ì‹œë¦¬ì¦ˆ

OpenAI í˜¸í™˜ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì „ë‹¬í•˜ë©°, ì°¨ì´ì ì€ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œì—ì„œ `chunk.choices[0].delta.content`ë¥¼ ì¶”ì¶œí•´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒì„ ì°¸ì¡°í•˜ì„¸ìš”.

**1. QvQï¼ŒQwen 2.5 VL:** ì´ë¯¸ì§€ ì¸ì‹.  
**2. QwQ:** í…ìŠ¤íŠ¸ ì‘ì—….  

<CodeGroup>

```py Qwen 2.5 VL
from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´í•˜ì„¸ìš”
    base_url="https://aihubmix.com/v1",
)

image_path = "yourpath/file.png"

def encode_image(image_path):
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}")
    
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# ì´ë¯¸ì§€ì˜ base64 ì¸ì½”ë”© ê°€ì ¸ì˜¤ê¸°
base64_image = encode_image(image_path)

completion = client.chat.completions.create(
    model="qwen2.5-vl-72b-instruct", #qwen2.5-vl-72b-instruct OR Qwen/QVQ-72B-Preview
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{base64_image}"
                    }
                }
            ]
        }
    ],
    stream=True
)

for chunk in completion:
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```


```py QwQ
from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ğŸ”‘ AiHubMix í‚¤ë¡œ êµì²´í•˜ì„¸ìš”
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="Qwen/QwQ-32B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "ìš°ì£¼ë¥¼ ì§€ë°°í•˜ëŠ” ë©”íƒ€ ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€ìš”?"}
            ]
        }
    ],
    stream=True
)

for chunk in completion:
    if hasattr(chunk.choices, '__len__') and len(chunk.choices) > 0:
        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
```

</CodeGroup>