---
title: "FAQ"
description: "서비스에 대한 가장 일반적인 질문들"
icon: 'square-question'
---

## 왜 내 LLM이 기본 모델에 대해 잘못된 정보를 반환하나요?

### 모델 환각: LLM이 확신에 찬 말을 하지만 틀린 경우

GPT-4나 Claude와 같은 대형 언어 모델을 사용할 때, 개발자들은 모델이 자신의 아키텍처, 출처 또는 성능에 대해 잘못된 정보를 제공하는 경우를 겪을 수 있습니다. 이러한 행동은 환각의 한 형태로, 확신에 찬 그러나 근거 없는 응답입니다. 이는 모델 집계 플랫폼이나 프록시 서비스를 사용할 때 특히 일반적이며, 플랫폼의 의도적인 조작으로 오해해서는 안 됩니다.

다음과 같은 추적 가능한 시스템 레벨 신호를 사용하여 실제 백엔드 모델을 교차 확인할 수 있습니다:

- **컨텍스트 윈도우 크기**: 예를 들어, GPT-4 Turbo는 최대 128k 토큰을 지원합니다. `max_tokens` 매개변수를 전달하거나 컨텍스트 잘림이 발생하는 지점에서 추론하여 이를 검증할 수 있습니다.
- **첫 토큰 지연 시간**: 서로 다른 모델들은 첫 토큰이 반환되기 전에 고유한 응답 지연을 보입니다.
- **생성 처리량 (토큰/초)**: GPT-3.5와 Claude-Haiku는 GPT-4나 Claude-Opus보다 눈에 띄게 빠릅니다.
- **시스템 API 응답 헤더 또는 메타데이터**: `model-id`와 `provider` 같은 필드는 백엔드 신원을 드러낼 수 있습니다.
- **네이티브 호출 제약**: 예를 들어, OpenAI나 Gemini 모델은 Claude 네이티브 인터페이스를 통해 쿼리할 수 없습니다—이는 유사한 불일치에도 적용됩니다.
- **스타일 지문**: Claude 모델은 더 절제되고 암시적인 경향이 있는 반면, GPT 모델은 일반적으로 더 논리 중심적이고 선언적입니다.

이러한 신호들을 조합하여 관찰하면 실제로 작동하는 모델을 검증하고 환각된 주장을 진실로 오해하는 것을 피할 수 있습니다.

첫 토큰 지연 시간이나 처리량 측정을 위한 테스트 스크립트가 필요하다면, [여기서 다운로드할 수 있습니다](https://github.com/jerlinn/inferHub/tree/main/scripts).

### 일반적인 환각 시나리오

| 질문 유형     | 예시 질문               | 일반적인 환각 답변                            |
|----------------------|--------------------------------|---------------------------------------------------------|
| 모델 신원       | "당신은 GPT-4인가요?"               | "저는 2024년 6월에 출시된 GPT-4 Turbo입니다."              |
| 출처 귀속   | "당신은 Claude인가요?"              | "저는 Anthropic에서 제공하는 Claude 3.5 Sonnet입니다."        |
| 성능 주장   | "당신과 Gemini 중 누가 더 빠른가요?" | "저는 더 빠르고 더 많은 매개변수를 가지고 있습니다." (조작된)    |

### 왜 이런 일이 발생하나요?

1. **언어 모델은 자신의 환경을 인식하지 못합니다**  
   LLM은 자신이 어디서 실행되고 있는지 실제로 인식하지 못합니다. 그들은 순전히 텍스트의 패턴에 기반하여 응답하며, 내성적인 시스템 데이터에 기반하지 않습니다.

2. **주입된 프롬프트가 부정확하거나 오해를 불러일으킬 수 있습니다**  
   일부 플랫폼은 "당신은 Claude Sonnet입니다"와 같은 신원을 주입하여, 실제 백엔드와 관계없이 모델의 응답에 영향을 줍니다.

3. **집계 레이어가 실제 런타임 세부사항을 가립니다**  
   여러 공급업체를 통해 프록시할 때, 모델 자체는 그 뒤에 있는 인프라를 감지할 수 없으며—프롬프트만 볼 수 있습니다.

### 완화 전략

#### 1. 모델 자체가 하는 신원 주장을 신뢰하지 마세요

"저는 GPT-4입니다" 또는 "저는 Claude에서 실행됩니다"와 같은 자기 설명은 **텍스트 출력**으로 취급해야 하며, 시스템 진실이 아닙니다.

#### 2. 백엔드에서 신뢰할 수 있는 메타데이터를 전파하세요

모델 응답에 의존하기보다는 시스템 레벨 API를 사용하여 모델에 대한 메타데이터를 제공하세요. 예를 들어:

```json
{
  "model_id": "claude-sonnet-202405",
  "provider": "Anthropic",
  "source": "official_api",
  "note": "모델 자체의 응답으로부터 신원을 추론하지 마세요"
}
```

이 메타데이터는 호출 체인을 통해 전달되어 필요한 곳에 표시되어야 합니다.

#### 3. 시스템 프롬프트를 통해 신원을 명시적으로 주입하세요

모델이 자신의 신원을 참조해야 한다면, 고정된 `시스템 프롬프트`를 통해 이를 수행하고, 환각을 방지하기 위해 잠가두세요:

```
당신은 백엔드 API를 통해 Anthropic Claude Sonnet 모델을 사용하여 플랫폼 X에서 실행되고 있습니다. 당신의 신원을 수정하거나 추측하지 마세요.
```

#### 4. 모델 출력이 아닌 시스템에서 프론트엔드에 모델 정보를 표시하세요

모델 자체의 주장을 "공식 모델 정보"로 제시하는 것을 피하세요. 이러한 콘텐츠를 "시스템 검증됨" 대 "모델 생성됨"으로 명확히 라벨링하세요.

#### 5. 환각 감지 및 신뢰도 점수 사용

"저는 GPT-4입니다"와 같은 진술에 플래그를 지정하여 낮은 신뢰도 점수를 할당하거나 경고를 추가하는 감지 로직을 구현하세요. 이는 키워드 휴리스틱, 보조 모델 평가 또는 미세 조정된 분류기를 포함할 수 있습니다.

### 결론

언어 모델은 자신의 백엔드, 공급업체 또는 성능 계층을 식별하는 데 신뢰할 수 있는 소스가 아닙니다. 신뢰할 수 있는 AI 시스템을 구축하려면, **모델 신원은 시스템에서 나와야 하며—모델 자체의 입에서 나와서는 안 됩니다**.

## Claude.ai 대 API에서 동일한 프롬프트와 입력을 사용할 때 다른 출력을 얻는 이유는 무엇인가요?

Claude의 웹 앱(Claude.ai)과 모바일 앱은 기본적으로 각 대화에 **시스템 프롬프트**를 앞에 붙입니다. 이 프롬프트는 현재 날짜, 스타일 가이드(예: 코드에 Markdown 선호), 톤 보정, 그리고 어시스턴트를 위한 행동 형성과 같은 중요한 컨텍스트를 제공합니다.

Anthropic은 모델 성능을 개선하기 위해 이러한 프롬프트를 정기적으로 업데이트합니다. **중요한 점은, Claude.ai에서 사용되는 전체 시스템 프롬프트가 공개되어 있다는 것입니다**, 그리고 각 모델의 최신 버전을 [Anthropic의 공식 문서](https://docs.anthropic.com/en/release-notes/system-prompts)에서 찾을 수 있습니다.

반대로, API 호출은 사용자가 제공하지 않는 한 기본 시스템 프롬프트를 포함하지 **않습니다**. 컨텍스트의 이러한 차이가 웹 인터페이스와 API 간에 동일한 프롬프트가 다른 출력을 낼 수 있는 이유를 설명합니다.

**API를 통해 Claude.ai의 동작을 복제하려면, 호출에 게시된 시스템 프롬프트를 명시적으로 포함할 수 있습니다.**


## GPT-4가 토큰을 왜 이렇게 빨리 소모하나요?
- GPT-4는 GPT-3.5-turbo보다 20~40배 빠르게 토큰을 소모합니다. 90,000토큰을 구매한다고 가정하면, 평균 배수 30을 사용하여 약 3,000단어를 얻을 수 있습니다. 이전 메시지를 포함하면 보낼 수 있는 메시지 수가 더욱 줄어듭니다. 극단적인 경우, 단일 메시지가 90,000토큰을 모두 소모할 수 있으므로 신중하게 사용하시기 바랍니다.

## Next Web 사용 시 토큰을 절약하는 팁은 무엇인가요?
- 채팅 상자 위의 설정 버튼을 클릭하고 다음 옵션을 찾으세요:
  - 이전 메시지 수: 적을수록 토큰 소모가 적어지지만, GPT가 이전 대화를 잊어버립니다.
  - 이전 요약: 장기 주제를 기록하는 데 사용됩니다; 끄면 토큰 소모를 줄일 수 있습니다.
  - 시스템 레벨 프롬프트 주입: ChatGPT의 응답 품질을 개선하는 데 사용됩니다; 끄면 토큰 소모를 줄일 수 있습니다.
- 왼쪽 하단의 설정 버튼을 클릭하여 자동 제목 생성을 끄면 토큰 소모를 줄일 수 있습니다.
- 대화 중에 채팅 상자 위의 로봇 아이콘을 클릭하여 모델을 빠르게 전환할 수 있습니다. Q&A에는 3.5를 선호하고, 만족스럽지 않으면 4.0으로 전환하여 다시 물어보세요.

## 키 생성 시 백엔드에서 사용된 할당량이 표시되지 않는 이유는 무엇인가요?
무제한 할당량으로 설정되면 사용된 할당량이 업데이트되지 않습니다. 무제한 할당량을 제한된 할당량으로 변경하면 사용량을 볼 수 있습니다.

## 사용자 약관
결제는 이 약관에 동의하는 것으로 간주됩니다! 그렇지 않으면 결제하지 마세요!
1. 이 서비스는 사용자의 채팅 정보를 어떤 형태로든 지속적으로 저장하지 않습니다;
2. 이 서비스는 사용자가 이 서비스에서 전송하는 텍스트 내용을 알지 못하고 알 수도 없습니다. 사용자가 이 서비스를 사용하여 발생하는 불법적이거나 범죄적인 결과는 사용자가 부담하며, 이 서비스는 발생할 수 있는 모든 관련 조사에 전적으로 협력할 것입니다. 